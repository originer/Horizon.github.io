{"meta":{"title":"Horizon Notes","subtitle":null,"description":null,"author":"Horizon","url":"https://originer.github.io/Horizon.github.io"},"pages":[{"title":"Tags","date":"2017-10-31T08:42:04.000Z","updated":"2018-04-30T17:36:28.387Z","comments":false,"path":"tags/index.html","permalink":"https://originer.github.io/Horizon.github.io/tags/index.html","excerpt":"","text":""}],"posts":[{"title":"","slug":"Untitled","date":"2018-05-22T15:33:34.121Z","updated":"2018-05-22T16:01:02.769Z","comments":true,"path":"2018/05/22/Untitled/","link":"","permalink":"https://originer.github.io/Horizon.github.io/2018/05/22/Untitled/","excerpt":"","text":"为什么不用new Thread()每次 new Thread() 都是新建对象，性能差； 线程缺乏统一管理，可能无限制的新建线程，相互竞争，有可能占用过多的系统资源导致死机或OOM 功能少，缺少多执行、定期执行、线程中断等功能； 线程池的优势重用存在的线程，减少对象的创建，消亡的开销； 可以控制最大并发线程数，提高系统资源利用率，同时可以避免过多资源竞争，避免阻塞； 提供定期执行、单线程、并发数控制等功能； 线程池 ： ThreadPoolExecutorThreadPoolExecutor有下面几个核心参数： corePoolSize ：核心线程数； maximumPoolSize：线程池最大线程数； workQueue：阻塞队列，存储等待执行的任务； keepAliveTime:线程没有任务执行时最多保持的时间； 如果运行的线程小于corePoolSize，会直接创建线程执行任务，即使其他线程是空闲的； 如果运行线程大于corePoolSize，小于maximumPoolSize时，只有workQueue满的时候才创建新线程； 如果corePoolSize等于maximumPoolSize时创建的线程是固定的，多余的任务会被放置到workQueue中；","categories":[],"tags":[]},{"title":"","slug":"Java线程池学习","date":"2018-05-22T15:32:26.014Z","updated":"2018-05-22T15:32:26.014Z","comments":true,"path":"2018/05/22/Java线程池学习/","link":"","permalink":"https://originer.github.io/Horizon.github.io/2018/05/22/Java线程池学习/","excerpt":"","text":"","categories":[],"tags":[]},{"title":"Map的几种遍历方式","slug":"Java8之lambda","date":"2018-05-21T10:14:45.412Z","updated":"2018-05-21T10:14:45.415Z","comments":true,"path":"2018/05/21/Java8之lambda/","link":"","permalink":"https://originer.github.io/Horizon.github.io/2018/05/21/Java8之lambda/","excerpt":"","text":"在开发过程中经常会用到Map的遍历，所以对Map的几种遍历方式做一下整理； KeySet 遍历123456Iterator it = map.keySet().iterator(); while (it.hasNext()) &#123; key = it.next(); value = map.get(key); System.out.println(key + \":\" + value); &#125; EntrySet 遍历1234567Iterator it1 = map.entrySet().iterator(); while (it1.hasNext()) &#123; Map.Entry entry = (Map.Entry) it1.next(); key = entry.getKey(); value = entry.getValue(); System.out.println(key + \"=\" + value); &#125; Java8 的 lambda 遍历123map.forEach((k, v) -&gt; &#123; System.out.println(\"key=\"+k+\":\"+\"value=\"+v); &#125;); 使用 EntrySet 效率比 KeySet 高，EntrySet 相比KeySet 少了遍历table的过程。java8 下可以配合lambda直接使用 map.foreach() 实际上还是使用entrySet的方式遍历。","categories":[],"tags":[]},{"title":"Map的几种遍历方式","slug":"Map的几种遍历方式","date":"2018-05-18T09:29:36.739Z","updated":"2018-05-21T10:09:49.515Z","comments":true,"path":"2018/05/18/Map的几种遍历方式/","link":"","permalink":"https://originer.github.io/Horizon.github.io/2018/05/18/Map的几种遍历方式/","excerpt":"","text":"在开发过程中经常会用到Map的遍历，所以对Map的几种遍历方式做一下整理； KeySet 遍历123456Iterator it = map.keySet().iterator(); while (it.hasNext()) &#123; key = it.next(); value = map.get(key); System.out.println(key + \":\" + value); &#125; EntrySet 遍历1234567Iterator it1 = map.entrySet().iterator(); while (it1.hasNext()) &#123; Map.Entry entry = (Map.Entry) it1.next(); key = entry.getKey(); value = entry.getValue(); System.out.println(key + \"=\" + value); &#125; Java8 的 lambda 遍历123map.forEach((k, v) -&gt; &#123; System.out.println(\"key=\"+k+\":\"+\"value=\"+v); &#125;); 使用 EntrySet 效率比 KeySet 高，EntrySet 相比KeySet 少了遍历table的过程。java8 下可以配合lambda直接使用 map.foreach() 实际上还是使用entrySet的方式遍历。","categories":[],"tags":[]},{"title":"关于Java值传递和引用传递的思考","slug":"关于Java值传递和引用传递的思考","date":"2018-05-17T03:11:28.014Z","updated":"2018-05-18T01:40:16.517Z","comments":true,"path":"2018/05/17/关于Java值传递和引用传递的思考/","link":"","permalink":"https://originer.github.io/Horizon.github.io/2018/05/17/关于Java值传递和引用传递的思考/","excerpt":"","text":"一直以为Java方法中传递的是对象的引用，然后看了一篇文章，发现自己的理解有些偏差。 首先先写出结论： 如果参数是基本类型，传递的是基本类型的字面量值的拷贝。如果参数是引用类型，传递的是该变量所引用的对象在堆中地址值的拷贝。 基本类型和引用类型的区别在Java内存模型中把内存分为堆和栈，栈中保存的就是我们声明的变量，对象保存在堆中。栈中的引用变量指向堆中的实际对象。当一个对象没有被任何变量引用时会被垃圾回收。在jvm内存模型中，基本类型值存在变量中。引用类型的变量只是保存了那个值的引用地址，引用指向实际对象。 基本类型和引用类型在方法传参时传递了什么？1234567891011121314151617181920212223public static void main(String[] args) &#123; int num = 100; String str = \"hello\"; StringBuilder sb = new StringBuilder(\"hello\"); add(num); //1 System.out.println(num); change(str); //2 System.out.println(str); change2(sb); //3 System.out.println(sb); &#125; public static void add(int a) &#123; a = a + 1; &#125; public static void change(String a) &#123; a = a + \"tt\"; &#125; public static void change2(StringBuilder a) &#123; a = a.append(\"tt\"); &#125; 代码运行结果： 100hellohellott 由运行结果可以分析出，在方法中的参数基本类型传入的是变量的副本，也就是相当于一个新的变量，所以我们进行操作原来的变量都不会变化；引用类型传入的是‘引用的副本’，即两个引用类型的变量指向同一个堆里的对象，但是这两个引用是没有任何关系的。所以，由于String是final类型不可变对象，a=a+”tt”实际是创建了一个新对象，然后方法中的参数的引用指向了这个新变量，原来的引用指向的还是”hello”。StringBuilder是可变对象，我们可以通过引用改变引用指向的对象的值，因此原来的变量中的值也会跟着改变。但是这跟传递引用是有本质区别的。","categories":[{"name":"Java","slug":"Java","permalink":"https://originer.github.io/Horizon.github.io/categories/Java/"}],"tags":[]},{"title":"Java设计模式：适配器模式","slug":"设计模式：适配器模式","date":"2018-04-30T17:36:28.379Z","updated":"2018-04-30T17:36:28.380Z","comments":true,"path":"2018/05/01/设计模式：适配器模式/","link":"","permalink":"https://originer.github.io/Horizon.github.io/2018/05/01/设计模式：适配器模式/","excerpt":"","text":"适配器模式 模式所涉及的角色有： ● 目标(Target)角色：这就是所期待得到的接口。注意：由于这里讨论的是类适配器模式，因此目标不可以是类。 ● 源(Adapee)角色：现在需要适配的接口。 ● 适配器(Adaper)角色：适配器类是本模式的核心。适配器把源接口转换成目标接口。显然，这一角色不可以是接口，而必须是具体类。 适配器模式是一种常用的结构型模式，经常用于旧系统改造，IO流大量使用适配器模式； 适配器模式主要有两类： 1、类适配 [使用继承] 2、组合 [使用内置对象] 类适配 123456789/** * 被适配的对象 */public class Adaptee &#123; public void request() &#123; System.out.println(\"Adaptee request\"); &#125;&#125; 123456789101112/** * 适配器 * 把被适配对象与target联系起来 * 1、类适配 [使用继承] * 2、组合 [使用内置对象] */public class Adapter extends Adaptee implements Target&#123; //使用继承// public void handleReq() &#123; super.request(); &#125;&#125; 12345678910public class Client &#123; public void test(Target t) &#123; t.handleReq(); &#125; public static void main(String[] args) &#123; Client c = new Client(); c.test(new Adapter()); &#125;&#125; 组合 12345678910111213public class Adapter implements Target &#123; // 组合 private Adaptee adaptee; public Adapter(Adaptee adaptee) &#123; this.adaptee = adaptee; &#125; public void handleReq() &#123; adaptee.request(); &#125;&#125; 12345678910public class Client &#123; public void test(Target t) &#123; t.handleReq(); &#125; public static void main(String[] args) &#123; Client c = new Client(); c.test(new Adapter(new Adaptee())); &#125;&#125;","categories":[{"name":"设计模式","slug":"设计模式","permalink":"https://originer.github.io/Horizon.github.io/categories/设计模式/"}],"tags":[{"name":"设计模式","slug":"设计模式","permalink":"https://originer.github.io/Horizon.github.io/tags/设计模式/"}]},{"title":"Java设计模式：命令模式","slug":"设计模式：命令模式","date":"2018-04-30T17:36:28.374Z","updated":"2018-04-30T17:36:28.375Z","comments":true,"path":"2018/05/01/设计模式：命令模式/","link":"","permalink":"https://originer.github.io/Horizon.github.io/2018/05/01/设计模式：命令模式/","excerpt":"","text":"命令模式命令模式将“请求”封装成对象，命令模式是数据驱动设计模式，属于行为模式类别。 请求作为命令包装在一个对象下，并传递给调用器对象。 调用者对象查找可以处理此命令的适当对象，并将命令传递到执行命令的相应对象。 下面以灯泡的开关控制为例子来学习命令模式： 先定义一个Light类 12345678public class Light &#123; public void on()&#123; System.out.println(\"light on\"); &#125; public void off()&#123; System.out.println(\"light off\"); &#125;&#125; 声明一个Command接口，所有的命令都要实现这个接口 123public interface Command &#123; void execute();&#125; 实现一个控制灯泡开关的命令类，既然属于命令自然要实现Command接口 123456789101112public class LightOnCommand implements Command &#123; Light light; public LightOnCommand(Light light) &#123; this.light = light; &#125; @Override public void execute() &#123; light.on(); &#125;&#125; 接下来定义一个Controller类，可以理解为灯泡的遥控器 1234567891011public class SimpleRemoteController &#123; Command solot; public void setCommand(Command solot) &#123; this.solot = solot; &#125; public void pressWasPressed() &#123; solot.execute(); &#125;&#125; 对SimpleRemoteController做简单的测试 12345678public static void main(String[] args) &#123; SimpleRemoteController remoteController = new SimpleRemoteController(); Light light = new Light(); LightOnCommand lightOnCommand = new LightOnCommand(light); remoteController.setCommand(lightOnCommand); remoteController.pressWasPressed(); &#125; 可以成功打印出 light on 从上面的简单例子可以看出灯泡与遥控器通过命令来交互，这两个类互不相干，实现了解耦。","categories":[{"name":"设计模式","slug":"设计模式","permalink":"https://originer.github.io/Horizon.github.io/categories/设计模式/"}],"tags":[{"name":"设计模式","slug":"设计模式","permalink":"https://originer.github.io/Horizon.github.io/tags/设计模式/"}]},{"title":"Java设计模式：单例模式","slug":"设计模式：单例模式","date":"2018-04-30T17:36:28.369Z","updated":"2018-04-30T17:36:28.370Z","comments":true,"path":"2018/05/01/设计模式：单例模式/","link":"","permalink":"https://originer.github.io/Horizon.github.io/2018/05/01/设计模式：单例模式/","excerpt":"","text":"饿汉模式 12345678910111213141516public class Sigleton &#123; //饿汉模式 outInstance是私有的 private static Sigleton ourInstance = new Sigleton(); /** * 此实现是线程安全的 JVM在加载此类时，因为对于static属性的初始化只能由一个线程执行且仅执行一次 * 缺点：instance在类装载时就实例化 这时候初始化instance显然没有达到lazy loading的效果 * @return */ public static Sigleton getInstance() &#123; return ourInstance; &#125; //把构造函数声明为private 客户对象无法创建该实例 private Sigleton() &#123; &#125;&#125; 懒汉模式 123456789101112131415161718192021222324252627282930313233public class Sigleton2 &#123; //懒汉模式（需要时才实例化对象） private static Sigleton2 instance; /** * 线程不安全 原因：getInstance在高并发环境下可能会被同时调用，导致if(instance==null)判断就不靠谱 * @return */// public static Sigleton2 getInstance() &#123;// if (instance == null) &#123;// instance = new Sigleton2();// &#125;// return instance;// &#125; /** * 解决方法：添加synchornized关键字 * 缺点：性能降低 * @return */ public static synchronized Sigleton2 getInstance() &#123; if (instance == null) &#123; instance = new Sigleton2(); &#125; return instance; &#125; private Sigleton2()&#123; &#125;&#125; 双重校验锁 12345678910111213141516public class DoubleCheckSingleton &#123; //此方法需要在Java 5及以上的版本才能运行 volatile关键字在Java5引入 public volatile static DoubleCheckSingleton instance = null; private DoubleCheckSingleton()&#123;&#125; public static DoubleCheckSingleton getInstance() &#123; if (instance == null) &#123; //检查实例是否创建 如果没有把 DoubleCheckSingleton.class设置为同步 synchronized (DoubleCheckSingleton.class) &#123; if (instance == null) &#123; //double check instance = new DoubleCheckSingleton(); &#125; &#125; &#125; return instance; &#125;&#125; 静态内部类 123456789101112public class StaticSingleton &#123; private static class SingletonHolder &#123; private static final StaticSingleton INSTANCE = new StaticSingleton(); &#125; private StaticSingleton ()&#123;&#125; //这种方式同样利用了classloder的机制来保证初始化instance时只有一个线程 public static final StaticSingleton getInstance() &#123; return SingletonHolder.INSTANCE; &#125;&#125; Singleton的序列化 如果单例类实现了Serializable接口，默认情况下，每次反序列化总会创建一个新的实例对象。解决方法：重写readResolve（）方法，直接返回单例对象 12345678910111213141516171819202122232425262728package Sigleton;import java.io.Serializable;/** * Created by Zz on 2017/5/3 0003. */public class Sigleton implements Serializable&#123; private static final long serialVersionUid = -6012841243252L; //饿汉模式 outInstance是私有的 private static Sigleton ourInstance = new Sigleton(); /** * 此实现是线程安全的 JVM在加载此类时，因为对于static属性的初始化只能由一个线程执行且仅执行一次 * 缺点：instance在类装载时就实例化 这时候初始化instance显然没有达到lazy loading的效果 * @return */ public static Sigleton getInstance() &#123; return ourInstance; &#125; //把构造函数声明为private 客户对象无法创建该实例 private Sigleton() &#123; &#125; private Object readResolve()&#123; return ourInstance; &#125;&#125;","categories":[{"name":"设计模式","slug":"设计模式","permalink":"https://originer.github.io/Horizon.github.io/categories/设计模式/"}],"tags":[{"name":"设计模式","slug":"设计模式","permalink":"https://originer.github.io/Horizon.github.io/tags/设计模式/"}]},{"title":"记录一些Redis在分布式环境下的实践遇到的问题","slug":"redis问题","date":"2018-04-30T17:36:28.364Z","updated":"2018-04-30T17:36:28.364Z","comments":true,"path":"2018/05/01/redis问题/","link":"","permalink":"https://originer.github.io/Horizon.github.io/2018/05/01/redis问题/","excerpt":"","text":"利用redis实现分布式集群的单点登陆功能;session作为一般的登陆凭证，在集群环境下会遇到一些问题： 1、如果服务器分布在多个Tomcat服务器上，那么用户每次登陆都未必访问同一个服务器。 2、如果Tomcat服务器挂掉，用户也会受到影响。 所以就想出以下解决方案：使用一个Redis服务器用来解决用户的单点登陆问题。这样，无论用户被负载均衡到哪个Tomcat服务器都可以通过redis服务器验证身份； 但是又会产生一个新的问题，如果一个redis服务器不够用怎么办? 很自然的能够想到添加redis服务器的解决方案，但是在增加redis服务器时遇到 了一些疑惑，以下作为记录： ShardedJedisShardedJedis是通过一致性哈希来实现分布式缓存的，通过一定的策略把不同的key分配到不同的redis server上，达到横向扩展的目的； ShardedJedis的使用方法除了配置时有点区别，其他和Jedis基本类似，有一点要注意的是 ShardedJedis不支持多命令操作，像mget、mset、brpop等可以在redis命令后一次性操作多个key的命令，具体包括哪些，大家可以看Jedis下的 MultiKeyCommands 这个类，这里面就包含了所有的多命令操作。很贴心的是，Redis作者已经把这些命令从ShardedJedis过滤掉了; 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475/** * @author Zz **/public class RedisShardedPool &#123; public static ShardedJedisPool pool;//sharded jedis连接池 private static Integer maxTotal = Integer.parseInt(PropertiesUtil.getProperty(\"redis.max.total\", \"20\")); //最大连接数 private static Integer maxIdle = Integer.parseInt(PropertiesUtil.getProperty(\"redis.max.idle\", \"10\")); //在jedispool中最大的idle状态的（空闲的）jedis实例个数 private static Integer minIdle = Integer.parseInt(PropertiesUtil.getProperty(\"redis.min.idle\", \"2\")); //在jedispool中最小的idle状态的（空闲的）jedis实例个数 private static Boolean testOnBorrow = Boolean.parseBoolean(PropertiesUtil.getProperty(\"redis.test.borrow\", \"true\")); //在borrow一个jedis实例的时候，是否要进行验证操作，如果赋值true，则得到的jedis实例是可用的 private static Boolean testOnReturn = Boolean.parseBoolean(PropertiesUtil.getProperty(\"redis.test.return\", \"true\")); //在return一个jedis实例的时候，是否要进行验证操作，如果赋值true，则返回成功 private static String redis1Ip = PropertiesUtil.getProperty(\"redis1.ip\"); private static Integer redis1Port = Integer.parseInt(PropertiesUtil.getProperty(\"redis1.port\")); private static String redis2Ip = PropertiesUtil.getProperty(\"redis2.ip\"); private static Integer redis2Port = Integer.parseInt(PropertiesUtil.getProperty(\"redis2.port\")); private static void initPool() &#123; JedisPoolConfig config = new JedisPoolConfig(); config.setMaxIdle(maxTotal); config.setMaxIdle(maxIdle); config.setMinIdle(minIdle); config.setTestOnBorrow(testOnBorrow); config.setTestOnReturn(testOnReturn); config.setBlockWhenExhausted(true);//连接耗尽时是否阻塞，false会抛出异常，true阻塞直到超时// pool = new JedisPool(config, redisIp, redisPort, 1000 * 2); JedisShardInfo info1 = new JedisShardInfo(redis1Ip, redis1Port, 1000 * 2); JedisShardInfo info2 = new JedisShardInfo(redis2Ip, redis2Port, 1000 * 2); List&lt;JedisShardInfo&gt; jedisShardInfos = new ArrayList&lt;&gt;(2); jedisShardInfos.add(info1); jedisShardInfos.add(info2); pool = new ShardedJedisPool(config, jedisShardInfos, Hashing.MURMUR_HASH, Sharded.DEFAULT_KEY_TAG_PATTERN); &#125; //静态加载 static &#123; initPool(); &#125; public static ShardedJedis getJedis() &#123; return pool.getResource(); &#125; public static void returnResource(ShardedJedis jedis) &#123; pool.returnResource(jedis); &#125; public static void returnBrokeResource(ShardedJedis jedis) &#123; pool.returnBrokenResource(jedis); &#125; public static void main(String[] args) &#123; ShardedJedis shardedJedis = pool.getResource(); for (int i = 0; i &lt; 10; i++) &#123; shardedJedis.set(\"key\" + i, \"value\" + i); &#125; for (int i = 0; i &lt; 10; i++) &#123; System.out.println(shardedJedis.get(\"key\" + i)); &#125; returnResource(shardedJedis); &#125;&#125; 一致性哈希实现分布式缓存ShardedJedis通过一致性哈希实现的的分布式缓存。主要思路： 1、redis服务器节点划分：将每台服务器节点采用hash算法划分为160个虚拟节点(可以配置划分权重)，将划分虚拟节点采用TreeMap存储2、对每个redis服务器的物理连接采用LinkedHashMap存储3、对Key or KeyTag 采用同样的hash算法，然后从TreeMap获取大于等于键hash值得节点，取最邻近节点存储；当key的hash值大于虚拟节点hash值得最大值时，存入第一个虚拟节点 sharded采用的hash算法：MD5 和 MurmurHash两种；默认采用64位的MurmurHash算法； 我们追踪 shardedJedis.get() 进行分析： 1234public String get(String key) &#123;Jedis j = getShard(key);return j.get(key); &#125; 123 public R getShard(String key) &#123;return resources.get(getShardInfo(key)); &#125; 123 public S getShardInfo(String key) &#123;return getShardInfo(SafeEncoder.encode(getKeyTag(key))); &#125; 12345678910111213/** * 通过key 获取分片。对key 也使用algo hash 算法，从虚拟节点（nodes）中取键值大于等于key hash后的值。 * 如果没有大于等于key hash后的值，那么取第一个node。 * 如果有则取当前映射的第一个node **/public S getShardInfo(byte[] key) &#123; SortedMap&lt;Long, S&gt; tail = nodes.tailMap(algo.hash(key)); if (tail.isEmpty()) &#123; return nodes.get(nodes.firstKey()); &#125; return tail.get(tail.firstKey());&#125;","categories":[{"name":"redis","slug":"redis","permalink":"https://originer.github.io/Horizon.github.io/categories/redis/"}],"tags":[]},{"title":"JDK代理","slug":"jdk代理","date":"2018-04-30T17:36:28.359Z","updated":"2018-04-30T17:36:28.359Z","comments":true,"path":"2018/05/01/jdk代理/","link":"","permalink":"https://originer.github.io/Horizon.github.io/2018/05/01/jdk代理/","excerpt":"","text":"Java中代理的实现一般分为三种：JDK静态代理、JDK动态代理以及CGLIB动态代理。在Spring的AOP实现中，主要应用了JDK动态代理以及CGLIB动态代理。但是本文着重介绍JDK动态代理机制，CGLIB动态代理后面会接着探究。代理一般实现的模式为JDK静态代理：创建一个接口，然后创建被代理的类实现该接口并且实现该接口中的抽象方法。之后再创建一个代理类，同时使其也实现这个接口。在代理类中持有一个被代理对象的引用，而后在代理类方法中调用该对象的方法。其实就是代理类为被代理类预处理消息、过滤消息并在此之后将消息转发给被代理类，之后还能进行消息的后置处理。代理类和被代理类通常会存在关联关系(即上面提到的持有的被带离对象的引用)，代理类本身不实现服务，而是通过调用被代理类中的方法来提供服务。 JDK一般代理jdk一般代理比较简单，我们只需要 定义一个接口 A 定义实现接口的具体类 AImpl 定义 AImpl的代理类 ProxyImplA 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061//接口public interface Star &#123; void confer(); void signComtract(); void sing();&#125;//接口的具体实现public class RealStar implements Star&#123; public void confer() &#123; System.out.println(\"RealStar confer\"); &#125; public void signComtract() &#123; System.out.println(\"RealStar signComtract\"); &#125; public void sing() &#123; System.out.println(\"RealStar sing\"); &#125;&#125;//代理类public class ProxyStar implements Star &#123; private Star star; public ProxyStar(Star real) &#123; this.star = real; &#125; public void confer() &#123; System.out.println(\"ProxyStar confer\"); &#125; public void signComtract() &#123; System.out.println(\"ProxyStar signComtract\"); &#125; public void sing() &#123; star.sing(); &#125;&#125;//测试public class Client &#123; public static void main(String[] args) &#123; Star real = new RealStar(); Star proxy = new ProxyStar(real); proxy.sing(); &#125;&#125;RealStar singProxyStar conferProxyStar signComtractProcess finished with exit code 0 这种方法一般称为JDK静态代理，比较简单，但是不实用。因为静态代理有一个很明显的缺点：由于代理只能为一个类服务，如果需要代理的类很多，那么就需要编写大量的代理类，比较繁琐。 JDK动态代理使用动态代理可以解决静态代理的缺点 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061/** * 1.通过实现InvocationHandler接口来自定义自己的InvocationHandler; * &lt;p&gt; * 2.通过Proxy.getProxyClass获得动态代理类 * &lt;p&gt; * 3.通过反射机制获得代理类的构造方法，方法签名为getConstructor(InvocationHandler.class) * &lt;p&gt; * 4.通过构造函数获得代理对象并将自定义的InvocationHandler实例对象传为参数传入 * &lt;p&gt; * 5.通过代理对象调用目标方法 */public class MyProxy &#123; public interface IHello &#123; void sayHello(); &#125; static class Hello implements IHello &#123; public void sayHello() &#123; System.out.println(\"Hello world!!\"); &#125; &#125; //自定义InvocationHandler static class HWInvocationHandler implements InvocationHandler &#123; //目标对象 private Object target; public HWInvocationHandler(Object target) &#123; this.target = target; &#125; @Override public Object invoke(Object proxy, Method method, Object[] args) throws Throwable &#123; System.out.println(\"------插入前置通知代码-------------\"); //执行相应的目标方法 Object rs = method.invoke(target, args); System.out.println(\"------插入后置处理代码-------------\"); return rs; &#125; &#125; public static void main(String[] args) throws NoSuchMethodException, IllegalAccessException, InvocationTargetException, InstantiationException &#123;// //生成$Proxy0的class文件// System.getProperties().put(\"sun.misc.ProxyGenerator.saveGeneratedFiles\", \"true\");// //获取动态代理类// Class proxyClazz = Proxy.getProxyClass(IHello.class.getClassLoader(), IHello.class);// //获得代理类的构造函数，并传入参数类型InvocationHandler.class// Constructor constructor = proxyClazz.getConstructor(InvocationHandler.class);// //通过构造函数来创建动态代理对象，将自定义的InvocationHandler实例传入// IHello iHello = (IHello) constructor.newInstance(new HWInvocationHandler(new Hello()));// //通过代理对象调用目标方法// iHello.sayHello(); //生成$Proxy0的class文件 System.getProperties().put(\"sun.misc.ProxyGenerator.saveGeneratedFiles\", \"true\"); IHello ihello = (IHello) Proxy.newProxyInstance(IHello.class.getClassLoader(), //加载接口的类加载器 new Class[]&#123;IHello.class&#125;, //一组接口 new HWInvocationHandler(new Hello())); //自定义的InvocationHandler ihello.sayHello(); &#125;&#125; JDK动态代理过程JDK静态代理是通过直接编码创建的，而JDK动态代理是利用反射机制在运行时创建代理类的。 其实在动态代理中，核心是InvocationHandler。每一个代理的实例都会有一个关联的调用处理程序(InvocationHandler)。对待代理实例进行调用时，将对方法的调用进行编码并指派到它的调用处理器(InvocationHandler)的invoke方法。所以对代理对象实例方法的调用都是通过InvocationHandler中的invoke方法来完成的，而invoke方法会根据传入的代理对象、方法名称以及参数决定调用代理的哪个方法。 123456IHello hello = new Hello();InvocationHandler handler = new HWInvocationHandler(hello);IHello ihello = (IHello) Proxy.newProxyInstance(HWInvocationHandler.getClass.getClassLoader(), hello.getClass().getInterfaces(), handler);ihello.sayHello(); 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354public static Object newProxyInstance(ClassLoader loader, Class&lt;?&gt;[] interfaces, InvocationHandler h) throws IllegalArgumentException &#123; //如果h为空将抛出异常 Objects.requireNonNull(h); final Class&lt;?&gt;[] intfs = interfaces.clone();//拷贝被代理类实现的一些接口，用于后面权限方面的一些检查 final SecurityManager sm = System.getSecurityManager(); if (sm != null) &#123; //在这里对某些安全权限进行检查，确保我们有权限对预期的被代理类进行代理 checkProxyAccess(Reflection.getCallerClass(), loader, intfs); &#125; /* * 下面这个方法将产生代理类 */ Class&lt;?&gt; cl = getProxyClass0(loader, intfs); /* * 使用指定的调用处理程序获取代理类的构造函数对象 */ try &#123; if (sm != null) &#123; checkNewProxyPermission(Reflection.getCallerClass(), cl); &#125; final Constructor&lt;?&gt; cons = cl.getConstructor(constructorParams); final InvocationHandler ih = h; //假如代理类的构造函数是private的，就使用反射来set accessible if (!Modifier.isPublic(cl.getModifiers())) &#123; AccessController.doPrivileged(new PrivilegedAction&lt;Void&gt;() &#123; public Void run() &#123; cons.setAccessible(true); return null; &#125; &#125;); &#125; //根据代理类的构造函数来生成代理类的对象并返回 return cons.newInstance(new Object[]&#123;h&#125;); &#125; catch (IllegalAccessException|InstantiationException e) &#123; throw new InternalError(e.toString(), e); &#125; catch (InvocationTargetException e) &#123; Throwable t = e.getCause(); if (t instanceof RuntimeException) &#123; throw (RuntimeException) t; &#125; else &#123; throw new InternalError(t.toString(), t); &#125; &#125; catch (NoSuchMethodException e) &#123; throw new InternalError(e.toString(), e); &#125; &#125; 然后通过 Class&lt;?&gt; cl = getProxyClass0(loader, intfs); 产生具体代理类，下面是具体过程 123456789101112131415/** * 生成一个代理类，但是在调用本方法之前必须进行权限检查 */ private static Class&lt;?&gt; getProxyClass0(ClassLoader loader, Class&lt;?&gt;... interfaces) &#123; //如果接口数量大于65535，抛出非法参数错误 if (interfaces.length &gt; 65535) &#123; throw new IllegalArgumentException(\"interface limit exceeded\"); &#125; // 如果在缓存中有对应的代理类，那么直接返回 // 否则代理类将有 ProxyClassFactory 来创建 return proxyClassCache.get(loader, interfaces); &#125; ProxyClassFactory是什么？ 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101/** * 里面有一个根据给定ClassLoader和Interface来创建代理类的工厂函数 * */ private static final class ProxyClassFactory implements BiFunction&lt;ClassLoader, Class&lt;?&gt;[], Class&lt;?&gt;&gt; &#123; // 代理类的名字的前缀统一为“$Proxy” private static final String proxyClassNamePrefix = \"$Proxy\"; // 每个代理类前缀后面都会跟着一个唯一的编号，如$Proxy0、$Proxy1、$Proxy2 private static final AtomicLong nextUniqueNumber = new AtomicLong(); @Override public Class&lt;?&gt; apply(ClassLoader loader, Class&lt;?&gt;[] interfaces) &#123; Map&lt;Class&lt;?&gt;, Boolean&gt; interfaceSet = new IdentityHashMap&lt;&gt;(interfaces.length); for (Class&lt;?&gt; intf : interfaces) &#123; /* * 验证类加载器加载接口得到对象是否与由apply函数参数传入的对象相同 */ Class&lt;?&gt; interfaceClass = null; try &#123; interfaceClass = Class.forName(intf.getName(), false, loader); &#125; catch (ClassNotFoundException e) &#123; &#125; if (interfaceClass != intf) &#123; throw new IllegalArgumentException( intf + \" is not visible from class loader\"); &#125; /* * 验证这个Class对象是不是接口 */ if (!interfaceClass.isInterface()) &#123; throw new IllegalArgumentException( interfaceClass.getName() + \" is not an interface\"); &#125; /* * 验证这个接口是否重复 */ if (interfaceSet.put(interfaceClass, Boolean.TRUE) != null) &#123; throw new IllegalArgumentException( \"repeated interface: \" + interfaceClass.getName()); &#125; &#125; String proxyPkg = null; // 声明代理类所在的package int accessFlags = Modifier.PUBLIC | Modifier.FINAL; /* * 记录一个非公共代理接口的包，以便在同一个包中定义代理类。同时验证所有非公共 * 代理接口都在同一个包中 */ for (Class&lt;?&gt; intf : interfaces) &#123; int flags = intf.getModifiers(); if (!Modifier.isPublic(flags)) &#123; accessFlags = Modifier.FINAL; String name = intf.getName(); int n = name.lastIndexOf('.'); String pkg = ((n == -1) ? \"\" : name.substring(0, n + 1)); if (proxyPkg == null) &#123; proxyPkg = pkg; &#125; else if (!pkg.equals(proxyPkg)) &#123; throw new IllegalArgumentException( \"non-public interfaces from different packages\"); &#125; &#125; &#125; if (proxyPkg == null) &#123; // 如果全是公共代理接口，那么生成的代理类就在com.sun.proxy package下 proxyPkg = ReflectUtil.PROXY_PACKAGE + \".\"; &#125; /* * 为代理类生成一个name package name + 前缀+唯一编号 * 如 com.sun.proxy.$Proxy0.class */ long num = nextUniqueNumber.getAndIncrement(); String proxyName = proxyPkg + proxyClassNamePrefix + num; /* * 生成指定代理类的字节码文件 */ byte[] proxyClassFile = ProxyGenerator.generateProxyClass( proxyName, interfaces, accessFlags); try &#123; return defineClass0(loader, proxyName, proxyClassFile, 0, proxyClassFile.length); &#125; catch (ClassFormatError e) &#123; /* * A ClassFormatError here means that (barring bugs in the * proxy class generation code) there was some other * invalid aspect of the arguments supplied to the proxy * class creation (such as virtual machine limitations * exceeded). */ throw new IllegalArgumentException(e.toString()); &#125; &#125; &#125; 由上方代码byte[] proxyClassFile = ProxyGenerator.generateProxyClass(proxyName, interfaces, accessFlags);可以看到，其实生成代理类字节码文件的工作是通过 ProxyGenerate类中的generateProxyClass方法来完成的。 12345678910111213141516171819202122232425262728293031public static byte[] generateProxyClass(final String var0, Class&lt;?&gt;[] var1, int var2) &#123; ProxyGenerator var3 = new ProxyGenerator(var0, var1, var2); // 真正用来生成代理类字节码文件的方法在这里 final byte[] var4 = var3.generateClassFile(); // 保存代理类的字节码文件 if(saveGeneratedFiles) &#123; AccessController.doPrivileged(new PrivilegedAction() &#123; public Void run() &#123; try &#123; int var1 = var0.lastIndexOf(46); Path var2; if(var1 &gt; 0) &#123; Path var3 = Paths.get(var0.substring(0, var1).replace('.', File.separatorChar), new String[0]); Files.createDirectories(var3, new FileAttribute[0]); var2 = var3.resolve(var0.substring(var1 + 1, var0.length()) + \".class\"); &#125; else &#123; var2 = Paths.get(var0 + \".class\", new String[0]); &#125; Files.write(var2, var4, new OpenOption[0]); return null; &#125; catch (IOException var4x) &#123; throw new InternalError(\"I/O exception saving generated file: \" + var4x); &#125; &#125; &#125;); &#125; return var4; &#125; 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117private byte[] generateClassFile() &#123; //下面一系列的addProxyMethod方法是将接口中的方法和Object中的方法添加到代理方法中(proxyMethod) this.addProxyMethod(hashCodeMethod, Object.class); this.addProxyMethod(equalsMethod, Object.class); this.addProxyMethod(toStringMethod, Object.class); Class[] var1 = this.interfaces; int var2 = var1.length; int var3; Class var4; //获得接口中所有方法并添加到代理方法中 for(var3 = 0; var3 &lt; var2; ++var3) &#123; var4 = var1[var3]; Method[] var5 = var4.getMethods(); int var6 = var5.length; for(int var7 = 0; var7 &lt; var6; ++var7) &#123; Method var8 = var5[var7]; this.addProxyMethod(var8, var4); &#125; &#125; Iterator var11 = this.proxyMethods.values().iterator(); //验证具有相同方法签名的方法的返回类型是否一致 List var12; while(var11.hasNext()) &#123; var12 = (List)var11.next(); checkReturnTypes(var12); &#125; //后面一系列的步骤用于写代理类Class文件 Iterator var15; try &#123; //生成代理类的构造函数 this.methods.add(this.generateConstructor()); var11 = this.proxyMethods.values().iterator(); while(var11.hasNext()) &#123; var12 = (List)var11.next(); var15 = var12.iterator(); while(var15.hasNext()) &#123; ProxyGenerator.ProxyMethod var16 = (ProxyGenerator.ProxyMethod)var15.next(); //将代理类字段声明为Method，并且字段修饰符为 private static. //因为 10 是 ACC_PRIVATE和ACC_STATIC的与运算 故代理类的字段都是 private static Method *** this.fields.add(new ProxyGenerator.FieldInfo(var16.methodFieldName, \"Ljava/lang/reflect/Method;\", 10)); //生成代理类的方法 this.methods.add(var16.generateMethod()); &#125; &#125; //为代理类生成静态代码块对某些字段进行初始化 this.methods.add(this.generateStaticInitializer()); &#125; catch (IOException var10) &#123; throw new InternalError(\"unexpected I/O Exception\", var10); &#125; if(this.methods.size() &gt; '\\uffff') &#123; //代理类中的方法数量超过65535就抛异常 throw new IllegalArgumentException(\"method limit exceeded\"); &#125; else if(this.fields.size() &gt; '\\uffff') &#123;// 代理类中字段数量超过65535也抛异常 throw new IllegalArgumentException(\"field limit exceeded\"); &#125; else &#123; // 后面是对文件进行处理的过程 this.cp.getClass(dotToSlash(this.className)); this.cp.getClass(\"java/lang/reflect/Proxy\"); var1 = this.interfaces; var2 = var1.length; for(var3 = 0; var3 &lt; var2; ++var3) &#123; var4 = var1[var3]; this.cp.getClass(dotToSlash(var4.getName())); &#125; this.cp.setReadOnly(); ByteArrayOutputStream var13 = new ByteArrayOutputStream(); DataOutputStream var14 = new DataOutputStream(var13); try &#123; var14.writeInt(-889275714); var14.writeShort(0); var14.writeShort(49); this.cp.write(var14); var14.writeShort(this.accessFlags); var14.writeShort(this.cp.getClass(dotToSlash(this.className))); var14.writeShort(this.cp.getClass(\"java/lang/reflect/Proxy\")); var14.writeShort(this.interfaces.length); Class[] var17 = this.interfaces; int var18 = var17.length; for(int var19 = 0; var19 &lt; var18; ++var19) &#123; Class var22 = var17[var19]; var14.writeShort(this.cp.getClass(dotToSlash(var22.getName()))); &#125; var14.writeShort(this.fields.size()); var15 = this.fields.iterator(); while(var15.hasNext()) &#123; ProxyGenerator.FieldInfo var20 = (ProxyGenerator.FieldInfo)var15.next(); var20.write(var14); &#125; var14.writeShort(this.methods.size()); var15 = this.methods.iterator(); while(var15.hasNext()) &#123; ProxyGenerator.MethodInfo var21 = (ProxyGenerator.MethodInfo)var15.next(); var21.write(var14); &#125; var14.writeShort(0); return var13.toByteArray(); &#125; catch (IOException var9) &#123; throw new InternalError(\"unexpected I/O Exception\", var9); &#125; &#125; &#125; 下面是将接口与Object中一些方法添加到代理类中的addProxyMethod方法： 12345678910111213141516171819202122232425262728private void addProxyMethod(Method var1, Class&lt;?&gt; var2) &#123; String var3 = var1.getName();//获得方法名称 Class[] var4 = var1.getParameterTypes();//获得方法参数类型 Class var5 = var1.getReturnType();//获得方法返回类型 Class[] var6 = var1.getExceptionTypes();//异常类型 String var7 = var3 + getParameterDescriptors(var4);//获得方法签名 Object var8 = (List)this.proxyMethods.get(var7);//根据方法前面获得proxyMethod的value if(var8 != null) &#123;//处理多个代理接口中方法重复的情况 Iterator var9 = ((List)var8).iterator(); while(var9.hasNext()) &#123; ProxyGenerator.ProxyMethod var10 = (ProxyGenerator.ProxyMethod)var9.next(); if(var5 == var10.returnType) &#123; ArrayList var11 = new ArrayList(); collectCompatibleTypes(var6, var10.exceptionTypes, var11); collectCompatibleTypes(var10.exceptionTypes, var6, var11); var10.exceptionTypes = new Class[var11.size()]; var10.exceptionTypes = (Class[])var11.toArray(var10.exceptionTypes); return; &#125; &#125; &#125; else &#123; var8 = new ArrayList(3); this.proxyMethods.put(var7, var8); &#125; ((List)var8).add(new ProxyGenerator.ProxyMethod(var3, var4, var5, var6, var2, null)); &#125;","categories":[{"name":"设计模式","slug":"设计模式","permalink":"https://originer.github.io/Horizon.github.io/categories/设计模式/"}],"tags":[{"name":"设计模式","slug":"设计模式","permalink":"https://originer.github.io/Horizon.github.io/tags/设计模式/"}]},{"title":"ajax跨域问题整理","slug":"ajax跨域问题","date":"2018-04-30T17:36:28.349Z","updated":"2018-04-30T17:36:28.350Z","comments":true,"path":"2018/05/01/ajax跨域问题/","link":"","permalink":"https://originer.github.io/Horizon.github.io/2018/05/01/ajax跨域问题/","excerpt":"","text":"为什么会出现跨域跨域问题来源于JavaScript的同源策略，即只有 协议+主机名+端口号(如存在)相同，则允许相互访问。也就是说JavaScript只能访问和操作自己域下的资源，不能访问和操作其他域下的资源。跨域问题是针对JS和ajax的，html本身没有跨域问题，比如a标签、script标签、甚至form标签（可以直接跨域发送数据并接收数据）等 说白了，产生跨域的主要原因就是浏览器的限制。 如何解决跨域问题 JSONP JSONP是JSON with Padding的略称。它是一个非官方的协议，它允许在服务器端集成Script tags返回至客户端，通过javascript callback的形式实现跨域访问（这仅仅是JSONP简单的实现形式）。关于jsonp的使用方式，可以参考http://blog.csdn.net/alen1985/article/details/6365394，优缺点可以参考http://blog.csdn.net/z69183787/article/details/19191385 添加响应头，允许跨域 addHeader(‘Access-Control-Allow-Origin:*’);//允许所有来源访问 addHeader(‘Access-Control-Allow-Method:POST,GET’);//允许访问的方式 代理的方式 服务器A的test01.html页面想访问服务器B的后台action，返回“test”字符串，此时就出现跨域请求，浏览器控制台会出现报错提示，由于跨域是浏览器的同源策略造成的，对于服务器后台不存在该问题，可以在服务器A中添加一个代理action，在该action中完成对服务器B中action数据的请求，然后在返回到test01.html页面。 JSONPJSONP的最基本的原理是：动态添加一个标签，而script标签的src属性是没有跨域的限制的。这样说来，这种跨域方式其实与ajax XmlHttpRequest协议无关了。 JSONP的优点：它不像XMLHttpRequest对象实现的Ajax请求那样受到同源策略的限制；它的兼容性更好，在更加古老的浏览器中都 可以运行，不需要XMLHttpRequest或ActiveX的支持；并且在请求完毕后可以通过调用callback的方式回传结果。 JSONP的缺点：它只支持GET请求而不支持POST等其它类型的HTTP请求；它只支持跨域HTTP请求这种情况，不能解决不同域的两个页面之间如何进行JavaScript调用的问题。 Jsonp的执行过程如下： 首先在客户端注册一个callback (如:’jsoncallback’),然后把callback的名字(如:jsonp1236827957501)传给服务器。注意：服务端得到callback的数值后，要用jsonp1236827957501(……)把将要输出的json内容包括起来，此时，服务器生成 json 数据才能被客户端正确接收。 然后以 javascript 语法的方式，生成一个function， function 名字就是传递上来的参数 ‘jsoncallback’的值 jsonp1236827957501 . 最后将 json 数据直接以入参的方式，放置到 function 中，这样就生成了一段 js 语法的文档，返回给客户端。 客户端浏览器，解析script标签，并执行返回的 javascript 文档，此时javascript文档数据，作为参数，传入到了客户端预先定义好的 callback 函数(如上例中jquery $.ajax()方法封装的的success: function(json))里。 可以说jsonp的方式原理上和是一致的(qq空间就是大量采用这种方式来实现跨域数据交换的)。JSONP是一种脚本注入(Script Injection)行为，所以有一定的安全隐患。* 例如，我们通过jquery的ajax发送一个jsonp的请求： 123456789$.ajax(&#123; url: base +\"/get1\", dataType: \"jsonp\", jsonp: \"callback2\", cache:true, success: function(json)&#123; result = json; &#125;&#125;); 后台接收也要做一些修改： 12345678@ControllerAdvicepublic class JsonpAdvice extends AbstractJsonpResponseBodyAdvice &#123; public JsonpAdvice() &#123; // TODO Auto-generated constructor stub super(\"callback2\"); &#125;&#125; ​","categories":[],"tags":[]},{"title":"Netty学习笔记","slug":"Netty学习笔记(一)","date":"2018-04-30T17:36:28.344Z","updated":"2018-04-30T17:36:28.345Z","comments":true,"path":"2018/05/01/Netty学习笔记(一)/","link":"","permalink":"https://originer.github.io/Horizon.github.io/2018/05/01/Netty学习笔记(一)/","excerpt":"","text":"这是本人学习Netty过程中记录的笔记，方便以后快速回顾。","categories":[{"name":"网络编程","slug":"网络编程","permalink":"https://originer.github.io/Horizon.github.io/categories/网络编程/"}],"tags":[{"name":"网络编程","slug":"网络编程","permalink":"https://originer.github.io/Horizon.github.io/tags/网络编程/"}]},{"title":"深入浅出NIO Channel和Buffer","slug":"NIO Channel和Buffer","date":"2018-04-30T17:36:28.339Z","updated":"2018-04-30T17:36:28.340Z","comments":true,"path":"2018/05/01/NIO Channel和Buffer/","link":"","permalink":"https://originer.github.io/Horizon.github.io/2018/05/01/NIO Channel和Buffer/","excerpt":"","text":"前言Java NIO 由以下几个核心部分组成： Buffer Channel Selector 传统的IO操作面向数据流，意味着每次从流中读一个或多个字节，直至完成，数据没有被缓存在任何地方。NIO操作面向缓冲区，数据从Channel读取到Buffer缓冲区，随后在Buffer中处理数据。本文着重介绍Channel和Buffer的概念以及在文件读写方面的应用和内部实现原理。 Buffer A buffer is a linear, finite sequence of elements of a specific primitive type. 一块缓存区，内部使用字节数组存储数据，并维护几个特殊变量，实现数据的反复利用。 mark：初始值为-1，用于备份当前的position position：初始值为0。position表示当前可以写入或读取数据的位置。当写入或读取一个数据后， position向前移动到下一个位置。 limit：写模式下，limit表示最多能往Buffer里写多少数据，等于capacity值。读模式下，limit表示最多可以读取多少数据。 capacity：缓存数组大小 Buffer.png mark()：把当前的position赋值给mark 1234public final Buffer mark() &#123; mark = position; return this;&#125; reset()：把mark值还原给position 1234567public final Buffer reset() &#123; int m = mark; if (m &lt; 0) throw new InvalidMarkException(); position = m; return this;&#125; clear()：一旦读完Buffer中的数据，需要让Buffer准备好再次被写入，clear会恢复状态值，但不会擦除数据。 123456public final Buffer clear() &#123; position = 0; limit = capacity; mark = -1; return this;&#125; flip()：Buffer有两种模式，写模式和读模式，flip后Buffer从写模式变成读模式。 123456public final Buffer flip() &#123; limit = position; position = 0; mark = -1; return this;&#125; rewind()：重置position为0，从头读写数据。 12345public final Buffer rewind() &#123; position = 0; mark = -1; return this;&#125; 目前Buffer的实现类有以下几种： ByteBuffer CharBuffer DoubleBuffer FloatBuffer IntBuffer LongBuffer ShortBuffer MappedByteBuffer 其中MappedByteBuffer实现比较特殊，感兴趣的可以看看 深入浅出MappedByteBuffer Paste_Image.png ByteBuffer A byte buffer，extend from Buffer ByteBuffer的实现类包括HeapByteBuffer和DirectByteBuffer两种。 HeapByteBuffer 12345678public static ByteBuffer allocate(int capacity) &#123; if (capacity &lt; 0) throw new IllegalArgumentException(); return new HeapByteBuffer(capacity, capacity);&#125;HeapByteBuffer(int cap, int lim) &#123; super(-1, 0, lim, cap, new byte[cap], 0);&#125; HeapByteBuffer通过初始化字节数组hd，在虚拟机堆上申请内存空间。 DirectByteBuffer 123456789101112131415161718192021222324252627public static ByteBuffer allocateDirect(int capacity) &#123; return new DirectByteBuffer(capacity);&#125;DirectByteBuffer(int cap) &#123; super(-1, 0, cap, cap); boolean pa = VM.isDirectMemoryPageAligned(); int ps = Bits.pageSize(); long size = Math.max(1L, (long)cap + (pa ? ps : 0)); Bits.reserveMemory(size, cap); long base = 0; try &#123; base = unsafe.allocateMemory(size); &#125; catch (OutOfMemoryError x) &#123; Bits.unreserveMemory(size, cap); throw x; &#125; unsafe.setMemory(base, size, (byte) 0); if (pa &amp;&amp; (base % ps != 0)) &#123; // Round up to page boundary address = base + ps - (base &amp; (ps - 1)); &#125; else &#123; address = base; &#125; cleaner = Cleaner.create(this, new Deallocator(base, size, cap)); att = null;&#125; DirectByteBuffer通过unsafe.allocateMemory在物理内存中申请地址空间（非jvm堆内存），并在ByteBuffer的address变量中维护指向该内存的地址。unsafe.setMemory(base, size, (byte) 0)方法把新申请的内存数据清零。 Channel A channel represents an open connection to an entity such as a hardware device, a file, a network socket, or a program component that is capable of performing one or more distinct I/O operations, for example reading or writing. 又称“通道”，NIO把它支持的I/O对象抽象为Channel，类似于原I/O中的流（Stream），但有所区别： 流是单向的，通道是双向的，可读可写。 流读写是阻塞的，通道可以异步读写。 流中的数据可以选择性的先读到缓存中，通道的数据总是要先读到一个缓存中，或从缓存中写入，如下所示： Channel.png 目前已知Channel的实现类有： FileChannel DatagramChannel SocketChannel ServerSocketChannel FileChannel A channel for reading, writing, mapping, and manipulating a file.一个用来写、读、映射和操作文件的通道。 FileChannel的read、write和map通过其实现类FileChannelImpl实现。 read实现 1234567891011121314151617181920212223public int read(ByteBuffer dst) throws IOException &#123; ensureOpen(); if (!readable) throw new NonReadableChannelException(); synchronized (positionLock) &#123; int n = 0; int ti = -1; try &#123; begin(); ti = threads.add(); if (!isOpen()) return 0; do &#123; n = IOUtil.read(fd, dst, -1, nd); &#125; while ((n == IOStatus.INTERRUPTED) &amp;&amp; isOpen()); return IOStatus.normalize(n); &#125; finally &#123; threads.remove(ti); end(n &gt; 0); assert IOStatus.check(n); &#125; &#125;&#125; FileChannelImpl的read方法通过IOUtil的read实现： 12345678910111213141516171819static int read(FileDescriptor fd, ByteBuffer dst, long position, NativeDispatcher nd) IOException &#123; if (dst.isReadOnly()) throw new IllegalArgumentException(\"Read-only buffer\"); if (dst instanceof DirectBuffer) return readIntoNativeBuffer(fd, dst, position, nd); // Substitute a native buffer ByteBuffer bb = Util.getTemporaryDirectBuffer(dst.remaining()); try &#123; int n = readIntoNativeBuffer(fd, bb, position, nd); bb.flip(); if (n &gt; 0) dst.put(bb); return n; &#125; finally &#123; Util.offerFirstTemporaryDirectBuffer(bb); &#125;&#125; 通过上述实现可以看出，基于channel的文件数据读取步骤如下：1、申请一块和缓存同大小的DirectByteBuffer bb。2、读取数据到缓存bb，底层由NativeDispatcher的read实现。3、把bb的数据读取到dst（用户定义的缓存，在jvm中分配内存）。read方法导致数据复制了两次。 write实现 1234567891011121314151617181920212223public int write(ByteBuffer src) throws IOException &#123; ensureOpen(); if (!writable) throw new NonWritableChannelException(); synchronized (positionLock) &#123; int n = 0; int ti = -1; try &#123; begin(); ti = threads.add(); if (!isOpen()) return 0; do &#123; n = IOUtil.write(fd, src, -1, nd); &#125; while ((n == IOStatus.INTERRUPTED) &amp;&amp; isOpen()); return IOStatus.normalize(n); &#125; finally &#123; threads.remove(ti); end(n &gt; 0); assert IOStatus.check(n); &#125; &#125;&#125; 和read实现一样，FileChannelImpl的write方法通过IOUtil的write实现： 12345678910111213141516171819202122232425static int write(FileDescriptor fd, ByteBuffer src, long position, NativeDispatcher nd) throws IOException &#123; if (src instanceof DirectBuffer) return writeFromNativeBuffer(fd, src, position, nd); // Substitute a native buffer int pos = src.position(); int lim = src.limit(); assert (pos &lt;= lim); int rem = (pos &lt;= lim ? lim - pos : 0); ByteBuffer bb = Util.getTemporaryDirectBuffer(rem); try &#123; bb.put(src); bb.flip(); // Do not update src until we see how many bytes were written src.position(pos); int n = writeFromNativeBuffer(fd, bb, position, nd); if (n &gt; 0) &#123; // now update src src.position(pos + n); &#125; return n; &#125; finally &#123; Util.offerFirstTemporaryDirectBuffer(bb); &#125;&#125; 通过上述实现可以看出，基于channel的文件数据写入步骤如下：1、申请一块DirectByteBuffer，bb大小为byteBuffer中的limit - position。2、复制byteBuffer中的数据到bb中。3、把数据从bb中写入到文件，底层由NativeDispatcher的write实现，具体如下： 12345678910111213141516171819202122private static int writeFromNativeBuffer(FileDescriptor fd, ByteBuffer bb, long position, NativeDispatcher nd) throws IOException &#123; int pos = bb.position(); int lim = bb.limit(); assert (pos &lt;= lim); int rem = (pos &lt;= lim ? lim - pos : 0); int written = 0; if (rem == 0) return 0; if (position != -1) &#123; written = nd.pwrite(fd, ((DirectBuffer)bb).address() + pos, rem, position); &#125; else &#123; written = nd.write(fd, ((DirectBuffer)bb).address() + pos, rem); &#125; if (written &gt; 0) bb.position(pos + written); return written;&#125; write方法也导致了数据复制了两次 Channel和Buffer示例123456789101112131415File file = new RandomAccessFile(\"data.txt\", \"rw\");FileChannel channel = file.getChannel();ByteBuffer buffer = ByteBuffer.allocate(48);int bytesRead = channel.read(buffer);while (bytesRead != -1) &#123; System.out.println(\"Read \" + bytesRead); buffer.flip(); while(buffer.hasRemaining())&#123; System.out.print((char) buffer.get()); &#125; buffer.clear(); bytesRead = channel.read(buffer);&#125;file.close(); 注意buffer.flip() 的调用，首先将数据写入到buffer，然后变成读模式，再从buffer中读取数据。","categories":[{"name":"网络编程","slug":"网络编程","permalink":"https://originer.github.io/Horizon.github.io/categories/网络编程/"}],"tags":[{"name":"网络编程","slug":"网络编程","permalink":"https://originer.github.io/Horizon.github.io/tags/网络编程/"}]},{"title":"Java虚拟机学习笔记","slug":"Java虚拟机学习笔记","date":"2018-04-30T17:36:28.332Z","updated":"2018-04-30T17:36:28.332Z","comments":true,"path":"2018/05/01/Java虚拟机学习笔记/","link":"","permalink":"https://originer.github.io/Horizon.github.io/2018/05/01/Java虚拟机学习笔记/","excerpt":"","text":"Java内存区域与内存溢出异常运行时数据区域下图是Java运行时数据区域划分图 区域 是否线程共享 是否会内存溢出 程序计数器 否 不会 java虚拟机栈 否 会 本地方法栈 否 会 堆 是 会 方法区 是 会 1.程序计数器(线程私有) 一块较小的内存，可以看作是当前线程所执行的字节码的行号指示器； 在虚拟机概念模型（各种虚拟机实现可能不一样）中，字节码解释器工作时就是通过改变这个计数器的值来选取下一条需要执行的字节码指令； 程序计数器是属于线程私有的内存； 如果执行的是Java方法，该计数器记录的是正在执行的虚拟机字节码指令的地址；如果是Native方法则为空； 2.Java虚拟机栈（线程私有） Java虚拟机栈也是线程私有的； 描述的是Java方法执行的内存模型：每个方法在执行的同时都会创建一个栈帧（Stack Frame）用于存储局部变量表、操作数栈、动态链接、方法出口等信息。每一个方法从调用直至执行完成的过程，就对应着一个栈帧在虚拟机中入栈到出栈的过程； 局部变量表存放了编译器可知的各种基本数据类型、对象引用和returnAddress类型；其所需的内存空间在编辑期完成分配，不会再运行期改变； 可能存在两种异常：StackOverflowError(请求栈深度过大)和OutOfMemoryError（内存不够时）； 3.本地方法栈 与虚拟机栈非常相似，只不过是为虚拟机使用到的Native方法服务； 可能存在两种异常：StackOverflowError和OutOfMemoryError； 4.Java堆（线程共享） Java堆是被所有线程共享的，在虚拟机启动时创建； 此内存区域的唯一目的就是存放对象实例，几乎所有的对象实例都在这分配； 是垃圾收集器管理的主要区域，可以分为新生代和老年代； 可以物理不连续，只要逻辑上是连续的即可； 如果堆中没有内存完成实例分配也无法再扩展时，会抛出OutOfMemoryError异常； 5.方法区/元空间（永久代）（线程共享） 是线程共享的区域； 用于存储已被虚拟机加载的类信息、常量、静态变量、即时编译器编译后的代码等数据； 该区域对于垃圾收集来说条件比较苛刻，但是还是非常有必要要进行回收处理； 当无法满足内存分配需求时，将抛出OutOfMemoryError异常； 6.运行时常量池 是方法区的一部分； Class文件中除了有类的版本、字段、方法、接口等描述信息外，还有一项信息是常量池，用于存放编译器生成的各种字面量和符号引用，这部分内容将在类加载后进入方法区的运行时常量池中存放； Java虚拟机规范要求较少，通常还会把翻译出来的直接引用也存储在此； 另外一个重要特征是具备动态性，可以在运行期间将新的常量放入池中，如String的intern方法； 可能存在的异常：OutOfMemoryError； 7.直接内存 并不是虚拟机运行时数据区的一部分，也不是Java虚拟机规范中定义的内存区域； JDK 1.4的NIO引入了基于通道（Channel）和缓冲区（Buffer）的IO方法，可以使用Native函数库直接分配对外内存，然后通过一个存储在Java堆中的DirectByteBuffer对象作为这块内存的引用进行操作以提升性能； 对象的访问定位 栈上的reference类型在虚拟机规范中只规定了一个指向对象的引用，并没有定义这个引用应该通过何种方式去定位、访问堆栈对象的具体位置，目前主流的方式方式有句柄和直接指针两种。 通过句柄：Java堆中划出一块内存作为句柄池，reference中存储的就是对象的句柄地址，而句柄中包含了对象实例数据与类型数据各自的具体地址信息。其最大好处就是reference存储的是稳定的句柄地址，在对象被移动（垃圾收集时移到）只改变实例数据指针，而reference不需要修改； 通过直接指针：Java堆对象的布局中必须考虑如果放置访问类型数据的相关信息，而reference中存在的直接就是对象地址。其最大好处在于速度更快，节省了一次指针定位的时机开销。HotSpot采用该方式进行对象访问，但其他语言和框架采用句柄的也非常常见。 Java垃圾回收机器与内存分配策略程序计时器、虚拟机栈、本地方法栈：随线程而灭，栈帧随方法而进行出栈和入栈，每一个栈帧分配的内存在类结构确定就已知，因此这几个区域不需要考虑回收； 对于Java堆和方法区，只有程序运行期间才知道会创建哪些对象，内存的分配和回收都是动态的，垃圾收集器所关注的是这部分内存； 判断Java中对象存活的算法1.引用计数算法给对象添加引用计数器，当有地方引用它时就加1，引用失效就减1，为0时就认为对象不再被使用可回收。该算法失效简单，判断高效，但并不被主流虚拟机采用，主要原因是它很难解决对象之间相互循环引用的问题。 2.可达性分析算法通过一系列的称为“GC Roots”的对象作为起点，从这些节点开始向下搜索，搜索所走过的路径称为引用链（Reference Chain），如果一个对象到GC Roots没有引用链相连，则该对象是不可用的。 在Java语言中，可作为GC Roots的对象包括： 虚拟机栈（栈帧中的本地变量表）中引用的对象； 方法区中类静态属性引用的对象； 方法区中常量引用的对象； 本地方法栈中JNI（即一般说的Native方法）引用的对象； 垃圾收集算法 1.标记-清除算法(Mark-Sweep)：首先标记出所有需要回收的对象，然后统一回收所有被标记的对象；缺点是效率不高且容易产生大量不连续的内存碎片； 复制算法：将可用内存分为大小相等的两块，每次只使用其中一块；当这一块用完了，就将还活着的对象复制到另一块上，然后把已使用过的内存清理掉。在HotSpot里，考虑到大部分对象存活时间很短将内存分为Eden和两块Survivor，默认比例为8:1:1。代价是存在部分内存空间浪费，适合在新生代使用； 标记-整理算法：首先标记出所有需要回收的对象，然后让所有存活的对象都向一端移动，然后直接清理掉端边界以外的内存。适用于老年代。 ​ 分代收集算法：一般把Java堆分新生代和老年代，在新生代用复制算法，在老年代用标记-清理或标记-整理算法，是现代虚拟机通常采用的算法。 垃圾收集器 垃圾收集算法是内存回收的方法论，垃圾收集器就是内存回收的具体实现。 这里讨论JDK 1.7 Update 14之后的HotSpot虚拟机（此时G1仍处于实验状态），包含的虚拟机如下图所示（存在连线的表示可以搭配使用）： 1.Serial收集器（单线程的收集器） 最基本、发展历史最悠久，在JDK 1.3之前是新生代收集的唯一选择； 是一个单线程（并非指一个收集线程，而是会暂停所有工作线程）的收集器，采用的是复制算法; 现在依然是虚拟机运行在Client模式下的默认新生代收集器，主要就是因为它简单而高效（没有线程交互的开销）； 2.ParNew收集器（Serial收集器的多线程版本） 其实就是Serial收集器的多线程版本； ParNew收集器在单CPU环境中绝对不会有比Serial收集器更好的效果； 是许多运行在Server模式下虚拟机首选的新生代收集器，重要原因就是除了Serial收集器外，只有它能与CMS收集器配合工作； 并行（Parallel）：指多条垃圾收集线程并行工作，但此时用户线程仍处于等待状态； 并发（Concurrent）：指用户线程与垃圾收集线程同时执行，用户线程在继续执行而垃圾收集程序运行在另外一个CPU上； 3.Parallel Scavenge收集器 吞吐量=运行用户代码时间/(运行用户代码时间+垃圾收集时间) 新生代收集器，使用复制算法，并行的多线程收集器； 与CMS关注于尽可能缩短垃圾收集时用户线程停顿时间不同，PS的目标是达到一个可控制的吞吐量； 高吞吐量可以高效率利用CPU时间，适合在后台运算而不需要太多交互的任务； -XX:MaxGCPauseMillis参数可以设置最大停顿时间，而停顿时间缩短是以牺牲吞吐量和新生代空间来换取的； 另外它还支持GC自适应的调节策略； 4.Serial Old收集器 是Serial收集器的老年代版本，同样是单线程，使用标记-整理算法； 主要是给Client模式下的虚拟机使用的； 在Server模式下主要是给JDK 1.5及之前配合Parallel Scavenge使用或作为CMS收集器的后备预案； 5.Parallel Old收集器 是Parallel Scavenge的老年代版本，使用多线程和标记-整理算法； 6.CMS收集器 是一种以获取最短回收停顿时间为目标的收集器，特别适合互联网站或者B/S的服务端； 它是基于标记-清除 算法实现的，主要包括4个步骤：初始标记（STW-stop the world，只是初始标记一下GC Roots能直接关联到的对象，速度很快）、并发标记（非STW，执行GC RootsTracing，耗时比较长）、重新标记（STW，修正并发标记期间因用户程序继续导致变动的那一部分对象标记）和并发清除（非STW，耗时较长）； 还有3个明显的缺点：CMS收集器对CPU非常敏感（占用部分线程及CPU资源，影响总吞吐量）、无法处理浮动垃圾（默认达到92%就触发垃圾回收）、大量内存碎片产生（可以通过参数启动压缩）； 7.G1收集器 一款面向服务端应用的垃圾收集器，后续会替换掉CMS垃圾收集器； 特点：并行与并发（充分利用多核多CPU缩短Stop-The-World时间）、分代收集（独立管理整个Java堆，但针对不同年龄的对象采取不同的策略）、空间整合（基于标记-整理）、可预测的停顿（将堆分为大小相等的独立区域，避免全区域的垃圾收集）； 关于Region：新生代和老年代不再物理隔离，只是部分Region的集合；G1跟踪各个Region垃圾堆积的价值大小，在后台维护一个优先列表，根据允许的收集时间优先回收价值最大的Region；Region之间的对象引用以及其他收集器中的新生代与老年代之间的对象引用，采用Remembered Set来避免全堆扫描； 分为几个步骤：1.初始标记（标记一下GC Roots能直接关联的对象并修改TAMS值，需要STW但耗时很短）、2.并发标记（从GC Root从堆中对象进行可达性分析找存活的对象，耗时较长但可以与用户线程并发执行）、3.最终标记（为了修正并发标记期间产生变动的那一部分标记记录，这一期间的变化记录在Remembered Set Log里，然后合并到Remembered Set里，该阶段需要STW但是可并行执行）、4.筛选回收（对各个Region回收价值排序，根据用户期望的GC停顿时间制定回收计划来回收）； 理解GC日志 最前面的数字代表GC发生的时间（虚拟机启动以后的秒杀）； “[GC”和“[Full GC”说明停顿类型，有Full代表的是Stop-The-World的； “[DefNew”、“[Tenured”和“[Perm”表示GC发生的区域； 方括号内部的“3324K -&gt; 152K(3712K)” 含义是 “GC前该内存已使用容量 -&gt; GC后该内存区域已使用容量(该区域总容量)”; 方括号之外的“3324K -&gt; 152K(11904)” 含义是 “GC前Java堆已使用容量 -&gt; GC后Java堆已使用容量(Java堆总容量)”; 再往后“0.0025925 secs”表示该内存区域GC所占用的时间； 内存分配与回收策略 对象优先在新生代分配 大对象直接进入老年代 长期存活的对象将进入老年代 动态对象年龄判断：如果在Survivor空间中相同年龄所有对象大小总和大于Survivor空间的一半，大于或等于该年龄的对象直接进入老年代； 空间分配担保：发生Minor GC前，虚拟机会先检查老年代最大可用连续空间是否大于新生代所有对象总空间，如果不成立，虚拟机会查看HandlePromotionFailure设置值是否允许担保失败，如果允许继续检查老年代最大可用的连续空间是否大于历次晋升到老年代的平均大小，如果大于会尝试进行一次Minor GC；如果小于或者不允许冒险，会进行一次Full GC； 虚拟机类加载机制概述 虚拟机把描述类的数据从Class文件加载到内存，并对数据进行校验、转换解析和初始化，最终形成可以被虚拟机直接使用的Java类型，这就是虚拟机的类加载机制。 在Java语言里面，类型的加载、连接和初始化过程都是在程序运行期间完成，这虽然增量一些性能开销，但是会为Java应用程序提供高度的灵活性。 类加载的时机 类的整个生命周期：加载、验证、准备、解析、初始化、使用和卸载；其中验证、准备和解析统称为连接； 虚拟机规范没有强制约束类加载的时机，但严格规定了有且只有5种情况必须立即对类进行初始化：遇到new、getstatic、putstatic和invokestatic指令；对类进行反射调用时如果类没有进行过初始化；初始化时发现父类还没有进行初始化；虚拟机启动指定的主类；动态语言中MethodHandle实例最后解析结果REF_getStatic等的方法句柄对应的类没有初始化时； 类加载的过程1.加载 通过一个类的全限定名来获取定义此类的二进制字节流； 将这个字节流所代表的静态存储结构转化为方法区的运行时数据结构； 在内存中生成一个代表这个类的java.lang.Class对象，作为方法区这个类的各种数据的访问入口； 2.验证 验证是连接阶段的第一步，其目的是确保Class文件的字节流中包含的信息符合当前虚拟机的要求，并且不会危害虚拟机自身的安全； 验证阶段是非常重要的，这个阶段是否严谨决定了Java虚拟机是否能承受恶意代码的攻击； 校验动作：文件格式验证（基于二进制字节流）、元数据验证（对类的元数据语义分析）、字节码验证（对方法体语义分析）、符号引用验证（对类自身以外的信息进行匹配性校验）； 3.准备 正式为变量分配内存并设置类变量初始值的阶段，这些变量所使用的内存都将在这个方法区中进行分配； 需要强调两点：这时候内存分配的仅包括类变量，而不包括类实例变量；这里所说的初始化通常情况下是数据类型的零值，真正的赋值是在初始化阶段，如果是static final的则是直接赋值； 4.解析 解析阶段是虚拟机将常量池内的符号引用（如CONSTANT_Class_info、CONSTANT_Fieldref_info、CONSTANT_Methodref_info等7种）替换为直接引用的过程； 符号引用可以是任何形式的字面量，与虚拟机实现的内存布局无关，引用的目标并不一定已经加载到内存中；而直接引用是直接指向目标的指针、相对偏移量或是一个能间接定位到目标的句柄，它和虚拟机实现的内存布局相关，引用的目标必定以及在内存中存在； 对同一个符号引用进行多次解析请求是很常见的事情，虚拟机实现可以对第一次解析的结果进行缓存； 5.初始化 是类加载过程的最后一步，真正开始执行类中定义的Java程序代码（或者说是字节码）； 初始化阶段是执行类构造器方法的过程，该方法是由编译器自动收集类中的所有类变量的赋值动作和静态语句块中的语句合并产生的； 方法与类的构造函数（或者说是实例构造器方法）不同，它不需要显式地调用父类构造器，虚拟机会保证在子类的方法执行之前，父类的方法已执行完毕； 执行接口的方法不需要先执行父接口的方法，只有当父接口中定义的变量使用时父接口才会初始化，接口的实现类在初始化时也一样不会执行接口的方法； 方法初始化是加锁阻塞等待的，应当避免在方法中有耗时很长的操作； 类加载器 虚拟机设计团队把类加载阶段的“通过一个类的全限定名来获取描述此类的二进制字节流”这个动作放到虚拟机外部去实现，实现这个动作的代码模块称为类加载器； 这是Java语言的一项创新，也是Java语言流行的重要原因，在类层次划分、OSGI、热部署、代码加密等领域大放异彩 类与类加载器 对于任意一个类，都需要由加载它的类加载器和这个类本身一同确立其在Java虚拟机的唯一性，每一个类加载器都拥有一个独立的类名称空间； 比较两个类是否相等（如Class对象的equals方法、isAssignableFrom方法、isInstance方法），只有在这两个类是由同一个类加载器加载的前提下才有意义； 双亲委派模型 关于双亲委派模型，这篇文章写得简单易懂:http://www.jianshu.com/p/acc7595f1b9d 三种系统提供的类加载器：启动类加载器（Bootstrap ClassLoader）、扩展类加载器（Extension ClassLoader）、应用程序类加载器（Application ClassLoader）； 双亲委派模型要求除了顶层的启动类加载器外，其他的类加载器都应当有自己的父类加载器，这里一般不会以继承的关系来实现，而是使用组合的关系来复用父加载器的代码； 其工作过程是：如果一个类加载器收到了类加载的请求，它首先不会自己去尝试加载这个类，而是把这个请求委派给父类加载器去完成，只有父类加载器反馈自己无法完成这个加载请求时（它的搜索范围中没有找到所需的类），子加载器才会尝试自己去加载； 这样的好处是Java类随着它的类加载器具备了一种带有优先级的层次关系，对保证Java程序的稳定运作很重要； 实现双亲委派的代码都集中在java.lang.ClassLoader的loadClass方法中，逻辑清晰易懂；","categories":[{"name":"JVM","slug":"JVM","permalink":"https://originer.github.io/Horizon.github.io/categories/JVM/"}],"tags":[]},{"title":"Java容器","slug":"Java容器","date":"2018-04-30T17:36:28.327Z","updated":"2018-04-30T17:36:28.328Z","comments":true,"path":"2018/05/01/Java容器/","link":"","permalink":"https://originer.github.io/Horizon.github.io/2018/05/01/Java容器/","excerpt":"","text":"Java容器里只能放对象，对于基本类型（int, long, float, double等），需要将其包装成对象类型后（Integer, Long, Float, Double等）才能放到容器里。很多时候拆包装和解包装能够自动完成。这虽然会导致额外的性能和空间开销，但简化了设计和编程。 泛型Java容器能够容纳任何类型的对象，这一点表面上是通过泛型机制完成，Java泛型不是什么神奇的东西，只是编译器为我们提供的一个“语法糖”，泛型本身并不需要Java虚拟机的支持，只需要在编译阶段做一下简单的字符串替换即可。实质上Java的单继承机制才是保证这一特性的根本，因为所有的对象都是Object的子类，容器里只要能够存放Object对象就行了。事实上，所有容器的内部存放的都是Object对象，泛型机制只是简化了编程，由编译器自动帮我们完成了强制类型转换而已。JDK 1.4以及之前版本不支持泛型，类型转换需要程序员显式完成。 123456789//JDK 1.4 or beforeArrayArrayList list = new ArrayList();list.add(new String(\"Monday\"));list.add(new String(\"Tuesday\"));list.add(new String(\"Wensday\"));for(int i = 0; i &lt; list.size(); i++)&#123; String weekday = (String)list.get(i);//显式类型转换 System.out.println(weekday.toUpperCase());&#125; 123456789//JDK 1.5 or latterArrayList&lt;String&gt; list = new ArrayList&lt;String&gt;();//参数化类型list.add(new String(\"Monday\"));list.add(new String(\"Tuesday\"));list.add(new String(\"Wensday\"));for(int i = 0; i &lt; list.size(); i++)&#123; String weekday = list.get(i);//隐式类型转换，编译器自动完成 System.out.println(weekday.toUpperCase());&#125; 内存管理跟C++复杂的内存管理机制不同，Java GC自动包揽了一切，Java程序并不需要处理令人头疼的内存问题，因此JCF并不像C++ STL那样需要专门的空间适配器（alloctor）。另外，由于Java里对象都在堆上，且对象只能通过引用（reference，跟C++中的引用不是同一个概念，可以理解成经过包装后的指针）访问，容器里放的其实是对象的引用而不是对象本身，也就不存在C++容器的复制拷贝问题。 接口和实现（Interfaces and Implementations）接口为了规范容器的行为，统一设计，JCF定义了14种容器接口（collection interfaces），它们的关系如下图所示： Map接口没有继承自Collection接口，因为Map表示的是关联式容器而不是集合。但Java为我们提供了从Map转换到Collection的方法，可以方便的将Map切换到集合视图。上图中提供了Queue接口，却没有Stack，这是因为Stack的功能已被JDK 1.6引入的Deque取代。 迭代器跟C++ STL一样，JCF的迭代器（Iterator）为我们提供了遍历容器中元素的方法。只有容器本身清楚容器里元素的组织方式，因此迭代器只能通过容器本身得到。每个容器都会通过内部类的形式实现自己的迭代器。相比STL的迭代器，JCF的迭代器更容易使用。 12345678ArrayList&lt;String&gt; list = new ArrayList&lt;String&gt;();list.add(new String(\"Monday\"));list.add(new String(\"Tuesday\"));list.add(new String(\"Wensday\"));Iterator&lt;String&gt; it = list.iterator();//得到迭代器while(it.hasNext())&#123; String weekday = it.next();//访问元素 System.out.println(weekday.toUpperCase());&#125; JDK 1.5 引入了增强的for循环，简化了迭代容器时的写法。 //使用增强for迭代 123456ArrayList&lt;String&gt; list = new ArrayList&lt;String&gt;();list.add(new String(\"Monday\"));list.add(new String(\"Tuesday\"));list.add(new String(\"Wensday\"));for(String weekday : list)&#123;//enhanced for statement System.out.println(weekday.toUpperCase());","categories":[{"name":"Java集合框架","slug":"Java集合框架","permalink":"https://originer.github.io/Horizon.github.io/categories/Java集合框架/"}],"tags":[{"name":"Java集合框架","slug":"Java集合框架","permalink":"https://originer.github.io/Horizon.github.io/tags/Java集合框架/"}]},{"title":"总结使用 IDEA 部署web工程到 Tomcat 遇到的一些问题","slug":"IDEA部署tomcat","date":"2018-04-30T17:36:28.322Z","updated":"2018-04-30T17:36:28.322Z","comments":true,"path":"2018/05/01/IDEA部署tomcat/","link":"","permalink":"https://originer.github.io/Horizon.github.io/2018/05/01/IDEA部署tomcat/","excerpt":"","text":"war 和 war exploded的区别 war模式：将WEB工程以包的形式上传到服务器 ;war exploded模式：将WEB工程以当前文件夹的位置关系上传到服务器 ; （1）war模式这种可以称之为是发布模式，看名字也知道，这是先打成war包，再发布； （2）war exploded模式是直接把文件夹、jsp页面 、classes等等移到Tomcat 部署文件夹里面，进行加载部署。因此这种方式支持热部署，一般在开发的时候也是用这种方式。 （3）在平时开发的时候，使用热部署的话，应该对Tomcat进行相应的设置，这样的话修改的jsp界面什么的东西才可以及时的显示出来。 注意： String contextPath = request.getSession().getServletContext().getRealPath(“/“); war模式下获取的是Tomcat所在的位置; war exploded模式下获取的是项目target的位置; 热加载问题war 模式部署: on ‘update‘ action：当用户主动执行更新的时候更新 快捷键:Ctrl + F9 on frame deactication:在编辑窗口失去焦点的时候更新 war exploeded 模式部署:如果你的工程中没有 Update classes and resources 这个选项，在这种情况下你更新后只能更新classes文件中的变动，并不能更新静态文件中的变动。 总结：在开发模式中一般选择war exploeded模式部署,但是要注意动态获取静态资源路径的问题 为何Tomcat路径下找不到部署的war包首先，需要了解一下IDEA启动Tomcat的过程： 1234567[2018-01-13 02:20:44,325] Artifact mmall:war: Waiting for server connection to start artifact deployment...Using CATALINA_2_BASE: &quot;G:\\tomcat2&quot;Using CATALINA_2_HOME: &quot;G:\\tomcat2&quot;Using CATALINA_TMPDIR: &quot;G:\\tomcat2\\temp&quot;Using JRE_HOME: &quot;F:\\jdk1.7.0_80&quot;Using CLASSPATH: &quot;G:\\tomcat2\\bin\\bootstrap.jar;G:\\tomcat2\\bin\\tomcat-juli.jar&quot;Connected to the target VM, address: &apos;127.0.0.1:12217&apos;, transport: &apos;socket&apos; 配置 CATALINA_BASE 启动 Tomcat idea 在启动 tomcat 的时候通过 CATALINA_BASE 修改了logs、conf和work的配置，webapps没动，如果没配置子域名就会自动覆盖原有的ROOT项目 总结: CATALINA_HOME就是你的Tomcat安装的位置，CATALINA_BASE就是你的这个实例的位置，默认的话这两个值是一样的。 IDEA启动时改变了CATALINA_BASE的设置,所以跑起来的实例的位置就不在Tomcat的路径下了,但是启动的其实还是原来的Tomcat;","categories":[{"name":"工具","slug":"工具","permalink":"https://originer.github.io/Horizon.github.io/categories/工具/"}],"tags":[]},{"title":"HashSet和HashMap","slug":"HashSet和HashMap","date":"2018-04-30T17:36:28.317Z","updated":"2018-04-30T17:36:28.318Z","comments":true,"path":"2018/05/01/HashSet和HashMap/","link":"","permalink":"https://originer.github.io/Horizon.github.io/2018/05/01/HashSet和HashMap/","excerpt":"","text":"HashSet and HashMap总体介绍原文github地址 之所以把HashSet和HashMap放在一起讲解，是因为二者在Java里有着相同的实现，前者仅仅是对后者做了一层包装，也就是说HashSet里面有一个HashMap（适配器模式）*。因此本文将重点分析HashMap*。 HashMap实现了Map接口，即允许放入key为null的元素，也允许插入value为null的元素；除该类未实现同步外，其余跟Hashtable大致相同；跟TreeMap不同，该容器不保证元素顺序，根据需要该容器可能会对元素重新哈希，元素的顺序也会被重新打散，因此不同时间迭代同一个HashMap的顺序可能会不同。根据对冲突的处理方式不同，哈希表有两种实现方式，一种开放地址方式（Open addressing），另一种是冲突链表方式（Separate chaining with linked lists）。Java HashMap采用的是冲突链表方式。 从上图容易看出，如果选择合适的哈希函数，put()和get()方法可以在常数时间内完成。但在对HashMap进行迭代时，需要遍历整个table以及后面跟的冲突链表。因此对于迭代比较频繁的场景，不宜将HashMap的初始大小设的过大。 有两个参数可以影响HashMap的性能：初始容量（inital capacity）和负载系数（load factor）。初始容量指定了初始table的大小，负载系数用来指定自动扩容的临界值。当entry的数量超过capacity*load_factor时，容器将自动扩容并重新哈希。对于插入元素较多的场景，将初始容量设大可以减少重新哈希的次数。 将对象放入到HashMap或HashSet中时，有两个方法需要特别关心：hashCode()和equals()。hashCode()方法决定了对象会被放到哪个bucket里，当多个对象的哈希值冲突时，equals()方法决定了这些对象是否是“同一个对象”。所以，如果要将自定义的对象放入到HashMap或HashSet中，需要@OverridehashCode()和equals()方法。 方法剖析get()get(Object key)方法根据指定的key值返回对应的value，该方法调用了getEntry(Object key)得到相应的entry，然后返回entry.getValue()。因此getEntry()是算法的核心。算法思想是首先通过hash()函数得到对应bucket的下标，然后依次遍历冲突链表，通过key.equals(k)方法来判断是否是要找的那个entry。上图中hash(k)&amp;(table.length-1)等价于hash(k)%table.length，原因是HashMap要求table.length必须是2的指数，因此table.length-1就是二进制低位全是1，跟hash(k)相与会将哈希值的高位全抹掉，剩下的就是余数了。 1234567891011121314//getEntry()方法final Entry&lt;K,V&gt; getEntry(Object key) &#123; ...... int hash = (key == null) ? 0 : hash(key); for (Entry&lt;K,V&gt; e = table[hash&amp;(table.length-1)];//得到冲突链表 e != null; e = e.next) &#123;//依次遍历冲突链表中的每个entry Object k; //依据equals()方法判断是否相等 if (e.hash == hash &amp;&amp; ((k = e.key) == key || (key != null &amp;&amp; key.equals(k)))) return e; &#125; return null;&#125; put()put(K key, V value)方法是将指定的key, value对添加到map里。该方法首先会对map做一次查找，看是否包含该元组，如果已经包含则直接返回，查找过程类似于getEntry()方法；如果没有找到，则会通过addEntry(int hash, K key, V value, int bucketIndex)方法插入新的entry，插入方式为头插法。 123456789101112//addEntry()void addEntry(int hash, K key, V value, int bucketIndex) &#123; if ((size &gt;= threshold) &amp;&amp; (null != table[bucketIndex])) &#123; resize(2 * table.length);//自动扩容，并重新哈希 hash = (null != key) ? hash(key) : 0; bucketIndex = hash &amp; (table.length-1);//hash%table.length &#125; //在冲突链表头部插入新的entry Entry&lt;K,V&gt; e = table[bucketIndex]; table[bucketIndex] = new Entry&lt;&gt;(hash, key, value, e); size++;&#125; remove()remove(Object key)的作用是删除key值对应的entry，该方法的具体逻辑是在removeEntryForKey(Object key)里实现的。removeEntryForKey()方法会首先找到key值对应的entry，然后删除该entry（修改链表的相应引用）。查找过程跟getEntry()过程类似。 123456789101112131415161718192021//removeEntryForKey()final Entry&lt;K,V&gt; removeEntryForKey(Object key) &#123; ...... int hash = (key == null) ? 0 : hash(key); int i = indexFor(hash, table.length);//hash&amp;(table.length-1) Entry&lt;K,V&gt; prev = table[i];//得到冲突链表 Entry&lt;K,V&gt; e = prev; while (e != null) &#123;//遍历冲突链表 Entry&lt;K,V&gt; next = e.next; Object k; if (e.hash == hash &amp;&amp; ((k = e.key) == key || (key != null &amp;&amp; key.equals(k)))) &#123;//找到要删除的entry modCount++; size--; if (prev == e) table[i] = next;//删除的是冲突链表的第一个entry else prev.next = next; return e; &#125; prev = e; e = next; &#125; return e;&#125; HashSet前面已经说过HashSet是对HashMap的简单包装，对HashSet的函数调用都会转换成合适的HashMap方法，因此HashSet的实现非常简单，只有不到300行代码。这里不再赘述。 12345678910111213141516//HashSet是对HashMap的简单包装public class HashSet&lt;E&gt;&#123; ...... private transient HashMap&lt;E,Object&gt; map;//HashSet里面有一个HashMap // Dummy value to associate with an Object in the backing Map private static final Object PRESENT = new Object(); public HashSet() &#123; map = new HashMap&lt;&gt;(); &#125; ...... public boolean add(E e) &#123;//简单的方法转换 return map.put(e, PRESENT)==null; &#125; ......&#125;","categories":[{"name":"Java集合框架","slug":"Java集合框架","permalink":"https://originer.github.io/Horizon.github.io/categories/Java集合框架/"}],"tags":[{"name":"Java集合框架","slug":"Java集合框架","permalink":"https://originer.github.io/Horizon.github.io/tags/Java集合框架/"}]},{"title":"HTTP协议相关笔记","slug":"HTTP协议相关笔记","date":"2018-04-30T17:36:28.311Z","updated":"2018-04-30T17:36:28.312Z","comments":true,"path":"2018/05/01/HTTP协议相关笔记/","link":"","permalink":"https://originer.github.io/Horizon.github.io/2018/05/01/HTTP协议相关笔记/","excerpt":"","text":"什么是HTTP协议协议是指计算机通信网络中两台计算机之间进行通信所必须共同遵守的规定或规则，超文本传输协议(HTTP)是一种通信协议，它允许将超文本标记语言(HTML)文档从Web服务器传送到客户端的浏览器 URL详解 URL(Uniform Resource Locator) 地址用于描述一个网络上的资源, 基本格式如下 1schema://host[:port#]/path/.../[?query-string][#anchor] scheme 指定低层使用的协议(例如：http, https, ftp) host HTTP服务器的IP地址或者域名 port# HTTP服务器的默认端口是80，这种情况下端口号可以省略。如果使用了别的端口，必须指明，例如 http://www.cnblogs.com:8080/ path 访问资源的路径 query-string 发送给http服务器的数据 anchor- 锚 HTTP协议是无状态的http协议是无状态的，同一个客户端的这次请求和上次请求是没有对应关系，对http服务器来说，它并不知道这两个请求来自同一个客户端。 为了解决这个问题， Web程序引入了Cookie机制来维护状态. 打开一个网页需要浏览器发送很多次Request\\1. 当你在浏览器输入URL http://www.cnblogs.com 的时候，浏览器发送一个Request去获取 http://www.cnblogs.com 的html. 服务器把Response发送回给浏览器. \\2. 浏览器分析Response中的 HTML，发现其中引用了很多其他文件，比如图片，CSS文件，JS文件。 \\3. 浏览器会自动再次发送Request去获取图片，CSS文件，或者JS文件。 \\4. 等所有的文件都下载成功后。 网页就被显示出来了。 Get和Post方法的区别Http协议定义了很多与服务器交互的方法，最基本的有4种，分别是GET,POST,PUT,DELETE. 一个URL地址用于描述一个网络上的资源，而HTTP中的GET, POST, PUT, DELETE就对应着对这个资源的查，改，增，删4个操作。 我们最常见的就是GET和POST了。GET一般用于获取/查询资源信息，而POST一般用于更新资源信息. 我们看看GET和POST的区别 \\1. GET提交的数据会放在URL之后，以?分割URL和传输数据，参数之间以&amp;相连，如EditPosts.aspx?name=test1&amp;id=123456. POST方法是把提交的数据放在HTTP包的Body中. \\2. GET提交的数据大小有限制（因为浏览器对URL的长度有限制），而POST方法提交的数据没有限制. \\3. GET方式需要使用Request.QueryString来取得变量的值，而POST方式通过Request.Form来获取变量的值。 \\4. GET方式提交数据，会带来安全问题，比如一个登录页面，通过GET方式提交数据时，用户名和密码将出现在URL上，如果页面可以被缓存或者其他人可以访问这台机器，就可以从历史记录获得该用户的账号和密码. 状态码Response 消息中的第一行叫做状态行，由HTTP协议版本号， 状态码， 状态消息 三部分组成。 状态码用来告诉HTTP客户端,HTTP服务器是否产生了预期的Response. HTTP/1.1中定义了5类状态码， 状态码由三位数字组成，第一个数字定义了响应的类别 1XX 提示信息 - 表示请求已被成功接收，继续处理 2XX 成功 - 表示请求已被成功接收，理解，接受 3XX 重定向 - 要完成请求必须进行更进一步的处理 4XX 客户端错误 - 请求有语法错误或请求无法实现 5XX 服务器端错误 - 服务器未能实现合法的请求 HTTP协议是无状态的和Connection: keep-alive的区别无状态是指协议对于事务处理没有记忆能力，服务器不知道客户端是什么状态。从另一方面讲，打开一个服务器上的网页和你之前打开这个服务器上的网页之间没有任何联系 HTTP是一个无状态的面向连接的协议，无状态不代表HTTP不能保持TCP连接，更不能代表HTTP使用的是UDP协议（无连接） 从HTTP/1.1起，默认都开启了Keep-Alive，保持连接特性，简单地说，当一个网页打开完成后，客户端和服务器之间用于传输HTTP数据的TCP连接不会关闭，如果客户端再次访问这个服务器上的网页，会继续使用这一条已经建立的连接 Keep-Alive不会永久保持连接，它有一个保持时间，可以在不同的服务器软件（如Apache）中设定这个时间 http和https的区别超文本传输协议HTTP协议被用于在Web浏览器和网站服务器之间传递信息，HTTP协议以明文方式发送内容，不提供任何方式的数据加密，如果攻击者截取了Web浏览器和网站服务器之间的传输报文，就可以直接读懂其中的信息，因此，HTTP协议不适合传输一些敏感信息，比如：信用卡号、密码等支付信息。为了解决HTTP协议的这一缺陷，需要使用另一种协议：安全套接字层超文本传输协议HTTPS，为了数据传输的安全，HTTPS在HTTP的基础上加入了SSL协议，SSL依靠证书来验证服务器的身份，并为浏览器和服务器之间的通信加密。 一、HTTP和HTTPS的基本概念HTTP：是互联网上应用最为广泛的一种网络协议，是一个客户端和服务器端请求和应答的标准（TCP），用于从WWW服务器传输超文本到本地浏览器的传输协议，它可以使浏览器更加高效，使网络传输减少。HTTPS：是以安全为目标的HTTP通道，简单讲是HTTP的安全版，即HTTP下加入SSL层，HTTPS的安全基础是SSL，因此加密的详细内容就需要SSL。HTTPS协议的主要作用可以分为两种：一种是建立一个信息安全通道，来保证数据传输的安全；另一种就是确认网站的真实性。 二、HTTP与HTTPS有什么区别？1、https协议需要到ca申请证书，一般免费证书较少，因而需要一定费用。 2、http是超文本传输协议，信息是明文传输，https则是具有安全性的ssl加密传输协议。 3、http和https使用的是完全不同的连接方式，用的端口也不一样，前者是80，后者是443。 4、http的连接很简单，是无状态的；HTTPS协议是由SSL+HTTP协议构建的可进行加密传输、身份认证的网络协议，比http协议安全。 三、HTTPS的工作原理我们都知道HTTPS能够加密信息，以免敏感信息被第三方获取，所以很多银行网站或电子邮箱等等安全级别较高的服务都会采用HTTPS协议。 1、客户端发起HTTPS请求这个没什么好说的，就是用户在浏览器里输入一个https网址，然后连接到server的443端口。 2、服务端的配置采用HTTPS协议的服务器必须要有一套数字证书，可以自己制作，也可以向组织申请，区别就是自己颁发的证书需要客户端验证通过，才可以继续访问，而使用受信任的公司申请的证书则不会弹出提示页面(startssl就是个不错的选择，有1年的免费服务)。这套证书其实就是一对公钥和私钥，如果对公钥和私钥不太理解，可以想象成一把钥匙和一个锁头，只是全世界只有你一个人有这把钥匙，你可以把锁头给别人，别人可以用这个锁把重要的东西锁起来，然后发给你，因为只有你一个人有这把钥匙，所以只有你才能看到被这把锁锁起来的东西。 3、传送证书这个证书其实就是公钥，只是包含了很多信息，如证书的颁发机构，过期时间等等。 4、客户端解析证书这部分工作是有客户端的TLS来完成的，首先会验证公钥是否有效，比如颁发机构，过期时间等等，如果发现异常，则会弹出一个警告框，提示证书存在问题。如果证书没有问题，那么就生成一个随机值，然后用证书对该随机值进行加密，就好像上面说的，把随机值用锁头锁起来，这样除非有钥匙，不然看不到被锁住的内容。 5、传送加密信息这部分传送的是用证书加密后的随机值，目的就是让服务端得到这个随机值，以后客户端和服务端的通信就可以通过这个随机值来进行加密解密了。 6、服务段解密信息服务端用私钥解密后，得到了客户端传过来的随机值(私钥)，然后把内容通过该值进行对称加密，所谓对称加密就是，将信息和私钥通过某种算法混合在一起，这样除非知道私钥，不然无法获取内容，而正好客户端和服务端都知道这个私钥，所以只要加密算法够彪悍，私钥够复杂，数据就够安全。 7、传输加密后的信息这部分信息是服务段用私钥加密后的信息，可以在客户端被还原。 8、客户端解密信息客户端用之前生成的私钥解密服务段传过来的信息，于是获取了解密后的内容，整个过程第三方即使监听到了数据，也束手无策。 HTTP1.0 HTTP 1.1主要区别长连接HTTP 1.0需要使用keep-alive参数来告知服务器端要建立一个长连接，而HTTP1.1默认支持长连接。HTTP是基于TCP/IP协议的，创建一个TCP连接是需要经过三次握手的,有一定的开销，如果每次通讯都要重新建立连接的话，对性能有影响。因此最好能维持一个长连接，可以用个长连接来发多个请求。 节约带宽HTTP 1.1支持只发送header信息(不带任何body信息)，如果服务器认为客户端有权限请求服务器，则返回100，否则返回401。客户端如果接受到100，才开始把请求body发送到服务器。这样当服务器返回401的时候，客户端就可以不用发送请求body了，节约了带宽。另外HTTP还支持传送内容的一部分。这样当客户端已经有一部分的资源后，只需要跟服务器请求另外的部分资源即可。这是支持文件断点续传的基础。 HOST域现在可以web server例如tomat，设置虚拟站点是非常常见的，也即是说，web server上的多个虚拟站点可以共享同一个ip和端口。HTTP1.0是没有host域的，HTTP1.1才支持这个参数。 HTTP1.1 HTTP 2.0主要区别多路复用HTTP2.0使用了多路复用的技术，做到同一个连接并发处理多个请求，而且并发请求的数量比HTTP1.1大了好几个数量级。当然HTTP1.1也可以多建立几个TCP连接，来支持处理更多并发的请求，但是创建TCP连接本身也是有开销的。TCP连接有一个预热和保护的过程，先检查数据是否传送成功，一旦成功过，则慢慢加大传输速度。因此对应瞬时并发的连接，服务器的响应就会变慢。所以最好能使用一个建立好的连接，并且这个连接可以支持瞬时并发的请求。 数据压缩HTTP1.1不支持header数据的压缩，HTTP2.0使用HPACK算法对header的数据进行压缩，这样数据体积小了，在网络上传输就会更快。 服务器推送意思是说，当我们对支持HTTP2.0的web server请求数据的时候，服务器会顺便把一些客户端需要的资源一起推送到客户端，免得客户端再次创建连接发送请求到服务器端获取。这种方式非常合适加载静态资源。服务器端推送的这些资源其实存在客户端的某处地方，客户端直接从本地加载这些资源就可以了，不用走网络，速度自然是快很多的。 cookie 和session 的区别 cookie 是一种发送到客户浏览器的文本串句柄，并保存在客户机硬盘上，可以用来在某个WEB站点会话间持久的保持数据。 session其实指的就是访问者从到达某个特定主页到离开为止的那段时间。 Session其实是利用Cookie进行信息处理的，当用户首先进行了请求后，服务端就在用户浏览器上创建了一个Cookie，当这个Session结束时，其实就是意味着这个Cookie就过期了。注：为这个用户创建的Cookie的名称是aspsessionid。这个Cookie的唯一目的就是为每一个用户提供不同的身份认证。 cookie和session的共同之处在于：cookie和session都是用来跟踪浏览器用户身份的会话方式。 cookie 和session的区别是：cookie数据保存在客户端，session数据保存在服务器端。 如果web服务器端使用的是session，那么所有的数据都保存在服务器上，客户端每次请求服务器的时候会发送当前会话的sessionid，服务器根据当前sessionid判断相应的用户数据标志，以确定用户是否登录或具有某种权限。由于数据是存储在服务器上面，所以你不能伪造，但是如果你能够获取某个登录用户的 sessionid，用特殊的浏览器伪造该用户的请求也是能够成功的。sessionid是服务器和客户端链接时候随机分配的，一般来说是不会有重复，但如果有大量的并发请求，也不是没有重复的可能性. 如果浏览器使用的是cookie，那么所有的数据都保存在浏览器端，比如你登录以后，服务器设置了cookie用户名，那么当你再次请求服务器的时候，浏览器会将用户名一块发送给服务器，这些变量有一定的特殊标记。服务器会解释为cookie变量，所以只要不关闭浏览器，那么cookie变量一直是有效的，所以能够保证长时间不掉线。如果你能够截获某个用户的 cookie变量，然后伪造一个数据包发送过去，那么服务器还是认为你是合法的。所以，使用 cookie被攻击的可能性比较大。如果设置了的有效时间，那么它会将 cookie保存在客户端的硬盘上，下次再访问该网站的时候，浏览器先检查有没有 cookie，如果有的话，就读取该 cookie，然后发送给服务器。如果你在机器上面保存了某个论坛 cookie，有效期是一年，如果有人入侵你的机器，将你的 cookie拷走，然后放在他的浏览器的目录下面，那么他登录该网站的时候就是用你的的身份登录的。所以 cookie是可以伪造的。当然，伪造的时候需要主意，直接copy cookie文件到 cookie目录，浏览器是不认的，他有一个index.dat文件，存储了 cookie文件的建立时间，以及是否有修改，所以你必须先要有该网站的 cookie文件，并且要从保证时间上骗过浏览器 1、cookie数据存放在客户的浏览器上，session数据放在服务器上。 2、cookie不是很安全，别人可以分析存放在本地的COOKIE并进行COOKIE欺骗 考虑到安全应当使用session。 3、session会在一定时间内保存在服务器上。当访问增多，会比较占用你服务器的性能 考虑到减轻服务器性能方面，应当使用COOKIE。 4、单个cookie保存的数据不能超过4K，很多浏览器都限制一个站点最多保存20个cookie。5、所以个人建议： 将登陆信息等重要信息存放为SESSION 其他信息如果需要保留，可以放在COOKIE中","categories":[{"name":"HTTP","slug":"HTTP","permalink":"https://originer.github.io/Horizon.github.io/categories/HTTP/"}],"tags":[{"name":"HTTP","slug":"HTTP","permalink":"https://originer.github.io/Horizon.github.io/tags/HTTP/"}]},{"title":"CopyOnWriteArrayList详解","slug":"CopyOnWriteArrayList详解","date":"2018-04-30T17:36:28.306Z","updated":"2018-04-30T17:36:28.307Z","comments":true,"path":"2018/05/01/CopyOnWriteArrayList详解/","link":"","permalink":"https://originer.github.io/Horizon.github.io/2018/05/01/CopyOnWriteArrayList详解/","excerpt":"","text":"CopyOnWriteArrayList与JMM一 CopyOnWriteArrayList与JMM说明：本文代码均以JDK1.8的源码为准。 1 什么是CopyOnWriteArrayList关于CopyOnWriteArrayList是什么以及基本用法，在这里不多说，网上可以搜到大量这方面的文章。在这里只做简要说明：CopyOnWriteArrayList相当于线程安全的ArrayList，是一个可变数组。它具有如下特性： 是线程安全的 写操作会复制整个基础数组，因此写操作开销很大 适用于如下情况：数组大小较小，并且读操作比写操作多很多的情形 2 CopyOnWriteArrayList的设计原理与JMM下面我们分析CopyOnWriteArrayList的设计原理，结合JMM的基础知识，分析CopyOnWriteArrayList是如何保证线程安全的。 首先看用来实际保存数据的数组： 12/** The array, accessed only via getArray/setArray. */private transient volatile Object[] array; 可以看到array数组前面使用了volatile变量来修饰。volatile主要用来解决内存可见性问题。关于volatile的详细实现原理可以参考《深入理解java内存模型.pdf》以及Java并发编程：volatile关键字解析-博客园-海子。 2.1 CopyOnWriteArrayList的读方法读方法比较简单，直接从array中获取对应索引的值。 123456789101112131415161718192021/** * &#123;@inheritDoc&#125; * * @throws IndexOutOfBoundsException &#123;@inheritDoc&#125; */public E get(int index) &#123; return get(getArray(), index);&#125;@SuppressWarnings(\"unchecked\")private E get(Object[] a, int index) &#123; return (E) a[index];&#125;/** * Gets the array. Non-private so as to also be accessible * from CopyOnWriteArraySet class. */final Object[] getArray() &#123; return array;&#125; 2.2 CopyOnWriteArrayList的写方法 set方法源码如下： 12345678910111213141516171819202122232425262728293031323334/** * Replaces the element at the specified position in this list with the * specified element. * * @throws IndexOutOfBoundsException &#123;@inheritDoc&#125; */public E set(int index, E element) &#123; final ReentrantLock lock = this.lock; lock.lock(); try &#123; Object[] elements = getArray(); E oldValue = get(elements, index); if (oldValue != element) &#123; int len = elements.length; Object[] newElements = Arrays.copyOf(elements, len); newElements[index] = element; setArray(newElements); &#125; else &#123; // Not quite a no-op; ensures volatile write semantics setArray(elements); &#125; return oldValue; &#125; finally &#123; lock.unlock(); &#125;&#125;/** * Sets the array. */final void setArray(Object[] a) &#123; array = a;&#125; set方法的功能是将对应索引的元素置为一个新值。执行流程： （1）加锁 （2）获取对应索引已有的值 （3）比较已有的值和新值，如果不相等，转4，否则转5 （4）创建新的数组，复制原数组的元素，并将对应索引置为新值。然后将新数组赋给array（setArray） （5）setArray-将array赋给array 这里有一个比较奇怪的点，为什么已有的值和新值相等的时候，还要执行setArray呢？本质上setArray也没有做什么事情。 这段代码混合使用了锁以及volatile。锁的用法比较容易理解，它在使用同一个锁的不同线程之间保证内存顺序性，代码结尾的释放锁的操作提供了本线程和其他欲获取相同的锁的线程之间的happens-before语义。但是CopyOnWriteArrayList类中其他代码，不一定会使用到这把锁，因此，前面所述的锁带来的内存模型含义对这部分代码执行是不适用的。 其他没用到这把锁的代码，读写是volatile读和volatile写（因为array前面使用volatile关键字修饰）。由volatile来保证happens-before语义。 volatile的特性及原理 volatile 变量自身具有下列特性:（1）可见性。对一个volatile 变量的读,总是能看到(任意线程)对这个volatile变量最后的写入。（2）原子性:对任意单个volatile 变量的读/写具有原子性,但类似于volatile++这种复合操作不具有原子性。 volatile 写和锁的释放有相同的内存语义。 为了实现 volatile 的内存语义,编译器在生成字节码时,会在指令序列中插入内存屏障来禁止特定类型的处理器重排序。 这里调用setArray的原因是，确保set方法对array执行的永远是volatile写。这就和其他对array执行volatile读的线程之间建立了happens-before语义。非常重要的一点：volatile读/写语义针对的是读写操作，而不是使用volatile修饰的变量本身。这样说更直白一点：在一个volatile写操作之前的对其他非volatile变量的写，happens-before于同一个volatile变量读操作之后的对其他变量的读。这句话比较绕，看下面一个例子就比较易懂了。 12345678910111213// initial conditionsint nonVolatileField = 0;CopyOnWriteArrayList&lt;String&gt; list = /* a single String */// Thread 1nonVolatileField = 1; // (1)list.set(0, \"x\"); // (2)// Thread 2String s = list.get(0); // (3)if (s == \"x\") &#123; int localVar = nonVolatileField; // (4)&#125; 现在假设原始数组中无元素“x”，这样(2)成功设置了元素”x”，(3)处可以成功获取到元素”x”。这种情况下，(4)一定会读取到(1)处设置的值1.因为(2)处的volatile写以及在此之前的任何写操作都happens-before(3)处的读以及之后的所有读。 但是，假设一开始数组中就有了元素”x”，如果else不调用setArray，那么(2)处的写就不是volatile写，(4)处的读就不一定能读到(1)处设置的值！ 很显然我们不想让内存可见性依赖于list中已有的值，为了确保任何情况下的内存可见性，set方法必须永远都是一个volatile写，这就是为何要在else代码块中调用setArray的原因。 其他写方法（add、remove）比较易懂，在此不详述。 3 参考资料 Java多线程系列–“JUC集合”02之 CopyOnWriteArrayList Why setArray() method call required in CopyOnWriteArrayList 深入理解java内存模型.pdf Java并发编程：volatile关键字解析-博客园-海子 二 为什么Java HashMap、CopyOnWriteArrayList等集合自己实现readObject和writeObject方法PS:本文源码参考的是JDK 1.8. 1 readObject、writeObject方法是什么？作用是什么？当一个class实现了Serializable接口，那么意味着这个类可以被序列化。如果类不实现readObject、writeObject方法，那么会执行默认的序列化和反序列化逻辑，否则执行自定义的序列化和反序列化逻辑，即readObject、writeObject方法的逻辑。 JDK提供的对于Java对象序列化操作的类是ObjectOutputStream，反序列化的类是ObjectInputStream。下面我们来看序列化的实现（ObjectOutputStream.writeObject）。 1234567891011121314151617181920212223242526272829303132333435/** * Write the specified object to the ObjectOutputStream. The class of the * object, the signature of the class, and the values of the non-transient * and non-static fields of the class and all of its supertypes are * written. Default serialization for a class can be overridden using the * writeObject and the readObject methods. Objects referenced by this * object are written transitively so that a complete equivalent graph of * objects can be reconstructed by an ObjectInputStream. * * &lt;p&gt;Exceptions are thrown for problems with the OutputStream and for * classes that should not be serialized. All exceptions are fatal to the * OutputStream, which is left in an indeterminate state, and it is up to * the caller to ignore or recover the stream state. * * @throws InvalidClassException Something is wrong with a class used by * serialization. * @throws NotSerializableException Some object to be serialized does not * implement the java.io.Serializable interface. * @throws IOException Any exception thrown by the underlying * OutputStream. */public final void writeObject(Object obj) throws IOException &#123; if (enableOverride) &#123; writeObjectOverride(obj); return; &#125; try &#123; writeObject0(obj, false); &#125; catch (IOException ex) &#123; if (depth == 0) &#123; writeFatalException(ex); &#125; throw ex; &#125;&#125; 从方法注释可以看到，此方法正是执行了将对象序列化的操作。并且默认的序列化机制可以通过重写readObject、writeObject方法实现。实际调用的方法writeObject0最终会调到writeSerialData： 123456789101112131415161718192021222324252627282930313233343536373839404142/** * Writes instance data for each serializable class of given object, from * superclass to subclass. */private void writeSerialData(Object obj, ObjectStreamClass desc) throws IOException&#123; ObjectStreamClass.ClassDataSlot[] slots = desc.getClassDataLayout(); for (int i = 0; i &lt; slots.length; i++) &#123; ObjectStreamClass slotDesc = slots[i].desc; //如果类重写了writeObject方法 if (slotDesc.hasWriteObjectMethod()) &#123; PutFieldImpl oldPut = curPut; curPut = null; SerialCallbackContext oldContext = curContext; if (extendedDebugInfo) &#123; debugInfoStack.push( &quot;custom writeObject data (class \\&quot;&quot; + slotDesc.getName() + &quot;\\&quot;)&quot;); &#125; try &#123; curContext = new SerialCallbackContext(obj, slotDesc); bout.setBlockDataMode(true); //调用实现类自己的writeobject方法 slotDesc.invokeWriteObject(obj, this); bout.setBlockDataMode(false); bout.writeByte(TC_ENDBLOCKDATA); &#125; finally &#123; curContext.setUsed(); curContext = oldContext; if (extendedDebugInfo) &#123; debugInfoStack.pop(); &#125; &#125; curPut = oldPut; &#125; else &#123; defaultWriteFields(obj, slotDesc); &#125; &#125;&#125; 2 为什么是private方法？javadoc上没有明确说明声明为private的原因，一个可能的原因是，除了子类以外没有其他类会使用它，这样不会被滥用。 另一个原因是，不希望这些方法被子类override。每个类都可以有自己的writeObject方法，序列化引擎会逐一调用。readObject相同。 3 HashMap中对readObject、writeObject方法的实现3.1 为什么HashMap要自定义序列化逻辑下文是摘自《Effective Java》： For example, consider the case of a hash table. The physical representation is a sequence of hash buckets containing key-value entries. The bucket that an entry resides in is a function of the hash code of its key, which is not, in general, guaranteed to be the same from JVM implementation to JVM implementation. In fact, it isn’t even guaranteed to be the same from run to run. Therefore, accepting the default serialized form for a hash table would constitute a serious bug. Serializing and deserializing the hash table could yield an object whose invariants were seriously corrupt. 大概意思是：对于同一个key，在不同的JVM平台上计算出来的hash值可能不同，导致的结果就是，同一个hashmap反序列化之后和序列化之前不同，导致同一个key取出来的值不同。 3.2 HashMap是如何解决的 将可能造成数据不一致的元素使用transient修饰，在序列化的时候忽略这些元素：Entry[] tablesizemodCount HashMap中对writeObject的实现： 123456789101112131415161718192021222324252627282930313233/** * Save the state of the &lt;tt&gt;HashMap&lt;/tt&gt; instance to a stream (i.e., * serialize it). * * @serialData The &lt;i&gt;capacity&lt;/i&gt; of the HashMap (the length of the * bucket array) is emitted (int), followed by the * &lt;i&gt;size&lt;/i&gt; (an int, the number of key-value * mappings), followed by the key (Object) and value (Object) * for each key-value mapping. The key-value mappings are * emitted in no particular order. */private void writeObject(java.io.ObjectOutputStream s) throws IOException &#123; int buckets = capacity(); // Write out the threshold, loadfactor, and any hidden stuff s.defaultWriteObject(); s.writeInt(buckets); s.writeInt(size); internalWriteEntries(s);&#125;// Called only from writeObject, to ensure compatible ordering.void internalWriteEntries(java.io.ObjectOutputStream s) throws IOException &#123; Node&lt;K,V&gt;[] tab; if (size &gt; 0 &amp;&amp; (tab = table) != null) &#123; for (int i = 0; i &lt; tab.length; ++i) &#123; for (Node&lt;K,V&gt; e = tab[i]; e != null; e = e.next) &#123; s.writeObject(e.key); s.writeObject(e.value); &#125; &#125; &#125;&#125; HashMap不会将保存数据的数组序列化，而是将元素个数以及每个元素的key、value序列化。而在反序列化的时候，重新计算，填充hashmap： readObject的实现： 1234567891011121314151617181920212223242526272829303132333435363738394041424344/** * Reconstitute the &#123;@code HashMap&#125; instance from a stream (i.e., * deserialize it). */private void readObject(java.io.ObjectInputStream s) throws IOException, ClassNotFoundException &#123; // Read in the threshold (ignored), loadfactor, and any hidden stuff s.defaultReadObject(); reinitialize(); if (loadFactor &lt;= 0 || Float.isNaN(loadFactor)) throw new InvalidObjectException(\"Illegal load factor: \" + loadFactor); s.readInt(); // Read and ignore number of buckets int mappings = s.readInt(); // Read number of mappings (size) if (mappings &lt; 0) throw new InvalidObjectException(\"Illegal mappings count: \" + mappings); else if (mappings &gt; 0) &#123; // (if zero, use defaults) // Size the table using given load factor only if within // range of 0.25...4.0 float lf = Math.min(Math.max(0.25f, loadFactor), 4.0f); float fc = (float)mappings / lf + 1.0f; int cap = ((fc &lt; DEFAULT_INITIAL_CAPACITY) ? DEFAULT_INITIAL_CAPACITY : (fc &gt;= MAXIMUM_CAPACITY) ? MAXIMUM_CAPACITY : tableSizeFor((int)fc)); float ft = (float)cap * lf; threshold = ((cap &lt; MAXIMUM_CAPACITY &amp;&amp; ft &lt; MAXIMUM_CAPACITY) ? (int)ft : Integer.MAX_VALUE); @SuppressWarnings(&#123;\"rawtypes\",\"unchecked\"&#125;) Node&lt;K,V&gt;[] tab = (Node&lt;K,V&gt;[])new Node[cap]; table = tab; // Read the keys and values, and put the mappings in the HashMap for (int i = 0; i &lt; mappings; i++) &#123; @SuppressWarnings(\"unchecked\") K key = (K) s.readObject(); @SuppressWarnings(\"unchecked\") V value = (V) s.readObject(); putVal(hash(key), key, value, false, false); &#125; &#125;&#125; 这样就避免了反序列化之后根据Key获取到的元素与序列化之前获取到的元素不同。 4 为什么CopyOnWriteArrayList也需要自定义序列化逻辑？writeObject、readObject实现： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647/** * Saves this list to a stream (that is, serializes it). * * @param s the stream * @throws java.io.IOException if an I/O error occurs * @serialData The length of the array backing the list is emitted * (int), followed by all of its elements (each an Object) * in the proper order. */ private void writeObject(java.io.ObjectOutputStream s) throws java.io.IOException &#123; s.defaultWriteObject(); Object[] elements = getArray(); // Write out array length s.writeInt(elements.length); // Write out all elements in the proper order. for (Object element : elements) s.writeObject(element); &#125; /** * Reconstitutes this list from a stream (that is, deserializes it). * @param s the stream * @throws ClassNotFoundException if the class of a serialized object * could not be found * @throws java.io.IOException if an I/O error occurs */ private void readObject(java.io.ObjectInputStream s) throws java.io.IOException, ClassNotFoundException &#123; s.defaultReadObject(); // bind to new lock resetLock(); // Read in array length and allocate array int len = s.readInt(); Object[] elements = new Object[len]; // Read in all elements in the proper order. for (int i = 0; i &lt; len; i++) elements[i] = s.readObject(); setArray(elements); &#125; 而数组被声明为transient： 12/** The array, accessed only via getArray/setArray. */private transient volatile Object[] array; 可以看出其逻辑和ArrayList相同：是将数组长度以及所有元素序列化，在反序列化的时候新建数组，填充元素。 如果采用默认的序列化机制会有如下问题：存储数据的数组实际上是动态数组，每次在放满以后自动增长设定的长度值，如果数组自动增长长度设为100，而实际只放了一个元素，那就会序列化很多null元素，所以ArrayList把元素数组设置为transient。","categories":[],"tags":[]},{"title":"CGLIB动态代理","slug":"CGlib动态代理","date":"2018-04-30T17:36:28.299Z","updated":"2018-04-30T17:36:28.300Z","comments":true,"path":"2018/05/01/CGlib动态代理/","link":"","permalink":"https://originer.github.io/Horizon.github.io/2018/05/01/CGlib动态代理/","excerpt":"","text":"cglib is a powerful, high performance and quality Code Generation Library, It is used to extend JAVA classes and implements interfaces at runtime.在Spring AOP中，通常会用它来生成AopProxy对象。不仅如此，在Hibernate中PO(Persistant Object 持久化对象)字节码的生成工作也要靠它来完成。 CGLIB动态代理示例被代理类 123456public class HelloServiceImpl implements HelloService&#123; @Override public String hello(String name) &#123; return \"Hello! \" + name; &#125;&#125; 123456789101112131415161718192021222324252627@Slf4jpublic class CGlibTest &#123; /** * 实现MethodInterceptor接口生成方法拦截器 */ static class HelloMethodInterceptor implements MethodInterceptor &#123; @Override public Object intercept(Object o, Method method, Object[] objects, MethodProxy methodProxy) throws Throwable &#123; log.info(\"Before: &#123;&#125;\",method.getName()); Object object = methodProxy.invokeSuper(o,objects); log.info(\"After: &#123;&#125;\",method.getName()); return object; &#125; &#125; @Test public void testProxy()&#123; Enhancer enhancer = new Enhancer(); enhancer.setSuperclass(HelloServiceImpl.class); //继承被代理类 enhancer.setCallback(new HelloMethodInterceptor()); //设置回调 HelloServiceImpl helloService = (HelloServiceImpl) enhancer.create(); //生成代理类对象 String s = helloService.hello(\"123\"); System.out.println(s); &#125;&#125; JDK代理要求被代理的类必须实现接口，有很强的局限性。而CGLIB动态代理则没有此类强制性要求。简单的说，CGLIB会让生成的代理类继承被代理类，并在代理类中对代理方法进行强化处理(前置处理、后置处理等)。在CGLIB底层，其实是借助了ASM这个非常强大的Java字节码生成框架。 生成代理对象从示例中可以看出，代理类对象是由 Enhancer 类创建的，Enhancer是CGLIB的字节码增强器，可以很方便的对类进行拓展。 创建代理对象的几个步骤: 生成代理类的二进制字节码文件； 加载二进制字节码，生成Class对象( 例如使用Class.forName()方法 )； 通过反射机制获得实例构造，并创建代理类对象 对委托类进行代理生成的代理类HelloServiceImpl$$EnhancerByCGLIB$$82ef2d06继承被代理类HelloServiceImpl。在这里我们需要注意一点：如果委托类被final修饰，那么它不可被继承，即不可被代理；同样，如果委托类中存在final修饰的方法，那么该方法也不可被代理； 代理类会为委托方法生成两个方法，一个是重写的sayHello方法，另一个是CGLIB$sayHello$0方法，我们可以看到它是直接调用父类的sayHello方法； 当执行代理对象的sayHello方法时，会首先判断一下是否存在实现了MethodInterceptor接口的CGLIB$CALLBACK_0;，如果存在，则将调用MethodInterceptor中的intercept方法。","categories":[{"name":"设计模式","slug":"设计模式","permalink":"https://originer.github.io/Horizon.github.io/categories/设计模式/"}],"tags":[]}]}