{"pages":[{"title":"分类","date":"2018-11-21T08:39:20.000Z","updated":"2018-11-21T08:54:59.000Z","comments":true,"path":"categories/index.html","permalink":"https://originer.github.io/Horizon.github.io/categories/index.html","excerpt":"","text":""},{"title":"标签","date":"2018-11-21T08:45:42.000Z","updated":"2018-11-21T08:55:04.000Z","comments":true,"path":"tags/index.html","permalink":"https://originer.github.io/Horizon.github.io/tags/index.html","excerpt":"","text":""}],"posts":[{"title":"Spring相关问题记录","slug":"Spring相关问题整理","date":"2019-03-14T03:42:04.251Z","updated":"2019-03-25T02:55:08.384Z","comments":true,"path":"2019/03/14/Spring相关问题整理/","link":"","permalink":"https://originer.github.io/Horizon.github.io/2019/03/14/Spring相关问题整理/","excerpt":"","text":"问题描述：有配置具体的bean，且可以被扫描到，但是无法注入,报错：No bean named ‘financeDao’ is defined原因：dao的interface注入问题，由于使用了mybaties，需要在mybaties的xml配置中添加该接口的路径，配置路径可以使用,;\\t\\n进行分隔； 问题描述：SpringMVC使用@Value无法获取application.properties中的数据原因：在项目中，spring的配置和springmvc是分离的，需要在springmvc的配置文件中加入 1&lt;context:property-placeholder ignore-resource-not-found=\"false\" location=\"classpath*:application.properties\"/&gt; 问题描述：mybatie 在使用 in (#{id}) 时的问题原因：mybatie自动生成的字段 #{}是带引号的，会自己包装一层。${}是把原本的字符串拼接到sql中，所以一般推荐使用#{}防止sql注入。 在使用 in 语法时推荐使用进行拼接。","categories":[{"name":"spring","slug":"spring","permalink":"https://originer.github.io/Horizon.github.io/categories/spring/"}],"tags":[]},{"title":"浅谈SPI机制","slug":"SPI机制","date":"2019-03-13T03:58:24.574Z","updated":"2019-03-28T14:41:02.819Z","comments":true,"path":"2019/03/13/SPI机制/","link":"","permalink":"https://originer.github.io/Horizon.github.io/2019/03/13/SPI机制/","excerpt":"","text":"SPI机制SPI 全称为 (Service Provider Interface) ，是JDK内置的一种服务提供发现机制。SPI是一种动态替换发现的机制， 比如有个接口，想运行时动态的给它添加实现，你只需要添加一个实现。我们经常遇到的就是java.sql.Driver接口，其他不同厂商可以针对同一接口做出不同的实现，mysql和postgresql都有不同的实现提供给用户，而Java的SPI机制可以为某个接口寻找服务实现。 JDK内置的SPIDubbo增强的SPI","categories":[{"name":"java","slug":"java","permalink":"https://originer.github.io/Horizon.github.io/categories/java/"}],"tags":[]},{"title":"redis学习笔记","slug":"redis学习笔记","date":"2019-02-27T16:24:37.244Z","updated":"2019-03-29T04:13:48.946Z","comments":true,"path":"2019/02/28/redis学习笔记/","link":"","permalink":"https://originer.github.io/Horizon.github.io/2019/02/28/redis学习笔记/","excerpt":"","text":"底层数据结构简单字符串sds，类似StringBuilder对比常规字符串的优势： 本身记录长度，获取长度的复杂度为O(1) 杜绝缓冲区溢出，即可以自动扩容。 使用空间预分配和惰性空间释放来优化内存分配，避免频繁分配内存带来的性能开销。 二进制安全，可以保存任意格式的二进制数据。 链表用处：列表、发布与订阅、慢查询、监视器等 字典redis的字典采用哈希表作为底层实现 跳表关于跳表：http://blog.jobbole.com/111731/ 持久化redis持久化有rdb和aof两种方式 rdbrdb类似内存快照，即把内存中的数据生成一份二进制的数据文件，可以还原到内存。rdb可以通过手动save命令保存，此过程会导致redis阻塞，也可以定义一系列的策略来自动生成rdb文件。bgsave的过程是fork一个当前线程，然后进行写文件。读文件没有相应的指令，服务器检测到rdb文件会自动载入，另外aof文件的优先级比rdb文件高，redis一般会优先执行aof文件。在rdb文件载入时，redis会处于阻塞状态。 aofaof保存的不是具体的数据，而是一系列的命令。 事件文件事件文件事件处理器使用的是单线程，通过IO多路复用的网络模型来同时监听多个socket，可以参考netty的网络模型。 redis实现了多套底层的IO多路复用API，在编译时会根据系统自动选择性能最高的。 时间事件redis底层把时间事件保存在一个无序链表中，每次时间事件执行时都需要遍历整个链表。 同步sync、psyncsync是旧版的同步，sync对初次同步的支持效果还可以，但是对于断线重连的情况处理的比较低效，需要主服务器进行bgsave产生rdb文件并发送给从服务器，非常消耗资源，并且所有命令都需要同步，包括很多无效的指令。 redis2.7之后添加了psync，psync新增了部分同步模式，用于处理断线重连。执行psync主服务器只会发送断线期间产生的写指令，不需要在发送rdb文件，相比sync高效了很多。 psync部分重同步的实现机制主从服务器会维护一个偏移量，通过对比偏移量就可以看主从服务器是否是一致的。同时主服务器还会维护一个复制积压缓冲区，这是一个FIFO队列，默认大小为1MB。主服务器在向从服务器发送同步的指令时会同时把指令发送给缓冲区，这样从服务器在断线重同步时，如果通过偏移量发现从服务器丢失的数据仍存在于缓冲区中，就会触发部分重同步，否则就执行完整重同步。 事务redis主要通过 multi``exec``watch来实现事务 multi将执行命令的redis客户端切换成事务状态。在事务状态下，除了exec、watch、discard、multi之外的指令都会被放到一个队列里。 exec执行事务，把事务队列中的指令执行完，然后清空队列，切换成非事务状态。 watch检测某个键是否被更改过，在检测期间更改检测key的值的客户端的标识REDIS_DIRTY_CAS会被打开。此标志会影响exec命令的执行。所以watch相当于一个乐观锁。","categories":[{"name":"redis","slug":"redis","permalink":"https://originer.github.io/Horizon.github.io/categories/redis/"}],"tags":[]},{"title":"redis集群相关的知识","slug":"redis集群相关","date":"2019-02-17T15:56:09.707Z","updated":"2019-04-01T16:44:30.950Z","comments":true,"path":"2019/02/17/redis集群相关/","link":"","permalink":"https://originer.github.io/Horizon.github.io/2019/02/17/redis集群相关/","excerpt":"redis主从复制 sentinel redis-cluster集群 一般主从搭配集群使用，可以保证redis集群的高可用性","text":"redis主从复制 sentinel redis-cluster集群 一般主从搭配集群使用，可以保证redis集群的高可用性 redis-clusterredis数据分区一致性hash算法 集群限制只支持相同slot值的key批量操作 不支持跨节点的事务操作 key是数据分区的最小粒度 不支持多数据空间，集群下只能使用db0 复制结构只支持一层，即从节点只能复制主节点 搭建集群 准备节点一般至少需要6个节点才能搭建高可用集群 节点握手redis节点间通讯采用Gossip协议，使用meet、ping、pong消息进行通讯。在任意一个节点使用cluster meet命令增加节点，握手状态就会在就会在集群内传播，最后其他节点都会与新加入的节点建立握手。 分配槽集群建立握手后并不能直接使用，此时所有节点都是下线状态，数据读写都是被禁止的，只有所有的槽分配完成后集群才会进入在线状态。首次启动被分配槽的都是主节点，其余的都是从节点。 创建集群redis-trip.rb 配置模板 创建六份配置文件，命名为redis-7000.conf…reids-7005.conf，然后每个配置文件中修改以下内容 12345port 7000cluster-enabled yescluster-config-file nodes-7000.confcluster-node-timeout 15000appendonly yes 分别启动redis实例 123456nohup redis-server /redis-cluster/redis-7000.conf &amp;nohup redis-server /redis-cluster/redis-7001.conf &amp;nohup redis-server /redis-cluster/redis-7002.conf &amp;nohup redis-server /redis-cluster/redis-7003.conf &amp;nohup redis-server /redis-cluster/redis-7004.conf &amp;nohup redis-server /redis-cluster/redis-7005.conf &amp; 使用redis-cli创建集群 123redis-cli --cluster create 127.0.0.1:7000 127.0.0.1:7001 \\127.0.0.1:7002 127.0.0.1:7003 127.0.0.1:7004 127.0.0.1:7005 \\--cluster-replicas 1 使用redis-trip.rb创建集群 12./redis-trib.rb create --replicas 1 127.0.0.1:7000 127.0.0.1:7001 \\127.0.0.1:7002 127.0.0.1:7003 127.0.0.1:7004 127.0.0.1:7005 如果槽全部分配成功说明集群创建成功 1[OK] All 16384 slots covered ​ 推荐使用redis-cli —cluster的命令，ruby脚本已经不再维护。 测试redis集群可以使用 debug populate 50000来添加测试数据； redis集群会根据key值hash分配一个slot，然后重定向到包含那个slot的节点。 1234redis-cli -c -h 127.0.0.1 -p 7000127.0.0.1:7000&gt; set k1 13-&gt; Redirected to slot [12706] located at 127.0.0.1:7002OK image-20190218164933104 jedis-cluster 命令执行流程image-20190218172856333 添加主节点和从节点12345#将7379作为主节点加入到7000集群中,没有分配hash槽redis-cli -h 127.0.0.1 -p 7379 -c --cluster add-node 127.0.0.1:7379 127.0.0.1:7000 #添加从节点redis-cli -h 192.168.26.137 -p 7006 -c --cluster add-node 192.168.26.137:7010 192.168.26.137:7006 --cluster-slave --cluster-master-id 78a6892d261c4756603d09a6062d6e6a48b39a27 槽分配123456789101112$ redis-cli -h 192.168.26.137 -p 7009 -c --cluster reshard 192.168.26.137:7008How many slots do you want to move (from 1 to 16384)?1000（输入要划分出来的slots）What is the receiving node ID?78a6892d261c4756603d09a6062d6e6a48b39a27（要接收slots的master节点id）Please enter all the source node IDs. Type 'all' to use all the nodes as source nodes for the hash slots. Type 'done' once you entered all the source nodes IDs.Source node #1:(这里可以添加从多个原master节点ID，最后输入done；也可以输入all，意思是平均从其他master节点处分片出来，凑齐1000slots)Do you want to proceed with the proposed reshard plan (yes/no)? yes (确认划分)#自动rehash命令redis-cli reshard &lt;host&gt;:&lt;port&gt; --cluster-from &lt;node-id&gt; --cluster-to &lt;node-id&gt; --cluster-slots &lt;number of slots&gt; --cluster-yes Redis dump数据迁移单实例 -&gt; 集群 1.备份数据 redis-dump -u 127.0.0.1:6371 &gt; db_full.json 2.load数据到集群 &lt; db_full.json redis-load -u 127.0.0.1:7001 -n doc：http://delanotes.com/redis-dump/ 其他activedefrag yes redis4.0以上支持内存碎片清理 jedis 2.9.0 以上支持集群密码 为什么使用集群单实例在高并发写入的情况下，会频繁触发持久化。redis rdb模式的持久化会fork一个进程用于磁盘读写，造成cpu占用率飙升，使用集群可以负载这些请求到不同的机器上。","categories":[{"name":"redis","slug":"redis","permalink":"https://originer.github.io/Horizon.github.io/categories/redis/"}],"tags":[]},{"title":"双亲委派机制","slug":"双亲委派机制","date":"2019-02-11T16:28:28.287Z","updated":"2019-03-25T03:06:55.027Z","comments":true,"path":"2019/02/12/双亲委派机制/","link":"","permalink":"https://originer.github.io/Horizon.github.io/2019/02/12/双亲委派机制/","excerpt":"","text":"先引出一个面试的问题，loadClass与forName的区别：loadClass只是获取ClassLoader，并没有实际装载。forName会对类进行装载，即会初始化类。 类加载器什么是类加载器类加载器（ClassLoader）就是在系统运行过程中动态的将字节码文件加载到 JVM 中的工具，基于这个工具的整套类加载流程，我们称作类加载机制。我们在 IDE 中编写的都是源代码文件，以后缀名 .java 的文件形式存在于磁盘上，通过编译后生成后缀名 .class 的字节码文件，ClassLoader 加载的就是这些字节码文件。 类加载器的类型Java 默认提供了三个 ClassLoader，分别是 AppClassLoader、ExtClassLoader、BootStrapClassLoader，依次后者分别是前者的「父加载器」。 启动类加载器(Bootstrap ClassLoader)启动类加载器负责将存放在\\lib目录中的，或者被-Xbootclasspath参数所指定的路径中的，并且是虚拟机识别的类库加载到虚拟机内存中。启动类加载器无法被Java程序直接引用。 扩展类加载器(Extension ClassLoader)扩展类加载器由sun.misc.Launcher$ExtClassLoader实现，它负责加载\\lib\\ext目录中，或者被java.ext.dirs系统变量所指定的路径中的所有类库，开发者可以直接使用扩展类加载器。 应用程序类加载器(Application Classloader)应用程序类加载器由sun.misc.Launcher$App-ClassLoader实现。应用程序类加载器也称之为系统类加载器。它负责加载用户类路径(ClassPath)上所指定的类库。应用程序中如果没有自定义类加载器，那一般情况下应用程序类加载器就是程序中默认的类加载器。","categories":[{"name":"Java","slug":"Java","permalink":"https://originer.github.io/Horizon.github.io/categories/Java/"}],"tags":[]},{"title":"3DES加密中文乱码问题","slug":"记一个3DES加密中文乱码的问题","date":"2019-01-28T02:47:48.577Z","updated":"2019-02-11T09:52:39.171Z","comments":true,"path":"2019/01/28/记一个3DES加密中文乱码的问题/","link":"","permalink":"https://originer.github.io/Horizon.github.io/2019/01/28/记一个3DES加密中文乱码的问题/","excerpt":"","text":"Java的String.getBytes()的编码与操作系统平台有关，本方法将返回该操作系统默认的编码格式的字节数组。在中文操作系统中，getBytes方法返回的是一个GBK或者GB2312的中文编码的字节数组，其中中文字符，各占两个字节。而在英文平台中，一般的默认编码是“ISO-8859-1”，每个字符都只取一个字节（而不管是否非拉丁字符）。 Tomcat环境下可能也与操作系统编码会有区别，所以在使用getBytes的时候需要显示指定编码格式，一般使用UTF-8。","categories":[{"name":"记录","slug":"记录","permalink":"https://originer.github.io/Horizon.github.io/categories/记录/"}],"tags":[]},{"title":"linux常用命令整理","slug":"linux常用指令","date":"2019-01-07T09:48:29.241Z","updated":"2019-02-11T10:00:30.127Z","comments":true,"path":"2019/01/07/linux常用指令/","link":"","permalink":"https://originer.github.io/Horizon.github.io/2019/01/07/linux常用指令/","excerpt":"文件查找： find ~ -name “xx.txt” 查找~路径下的xx.txt文件 -iname 忽略大小写，支持通配符匹配 检索文件内容 grep -i ‘xxx’ log.log 检索单行 | 管道命令，把上一个命令的输出流传递给下一个命令的输入流。不支持输入流的命令会把数据抛弃 awk -F “,” ‘{print $1}’ log.log 以逗号作为分隔符，打印分割后第一个变量","text":"文件查找： find ~ -name “xx.txt” 查找~路径下的xx.txt文件 -iname 忽略大小写，支持通配符匹配 检索文件内容 grep -i ‘xxx’ log.log 检索单行 | 管道命令，把上一个命令的输出流传递给下一个命令的输入流。不支持输入流的命令会把数据抛弃 awk -F “,” ‘{print $1}’ log.log 以逗号作为分隔符，打印分割后第一个变量 清理冗余PATH export PATH=$(echo $PATH | tr : “\\n”| sort | uniq | tr “\\n” :)","categories":[{"name":"工具","slug":"工具","permalink":"https://originer.github.io/Horizon.github.io/categories/工具/"}],"tags":[]},{"title":"2018年终","slug":"2018总结","date":"2018-12-31T08:10:17.219Z","updated":"2019-02-20T02:26:13.579Z","comments":true,"path":"2018/12/31/2018总结/","link":"","permalink":"https://originer.github.io/Horizon.github.io/2018/12/31/2018总结/","excerpt":"","text":"工作相关 [ ] 掌握RocketMQ [ ] 读5本技术类的书籍 [ ] 读5本其他书籍 [ ] github弄一个小项目 坚持每个月一篇博客 生活相关","categories":[{"name":"随笔","slug":"随笔","permalink":"https://originer.github.io/Horizon.github.io/categories/随笔/"}],"tags":[{"name":"随笔","slug":"随笔","permalink":"https://originer.github.io/Horizon.github.io/tags/随笔/"}]},{"title":"记录一个Java资源文件读取的小坑","slug":"记录一个关于Java文件读写的坑","date":"2018-12-26T12:09:06.471Z","updated":"2019-02-11T09:53:46.018Z","comments":true,"path":"2018/12/26/记录一个关于Java文件读写的坑/","link":"","permalink":"https://originer.github.io/Horizon.github.io/2018/12/26/记录一个关于Java文件读写的坑/","excerpt":"问题：java读取resource中的文件，在打成jar包后路径变化，导致文件读取失败。 原因：使用这种方法可以正常读取到文件，但是打成jar包后路径就产生了变化，所以读取失败。 12URL url = TEST.class.getResource(path);Files.lines(Paths.get(url.toURI()), 解决方法：采用getResourceAsStream读取文件 123456InputStream is = this.getClass().getResourceAsStream(path);BufferedReader br = new BufferedReader(new InputStreamReader(is));String s = \"\";br.lines().forEach(str -&gt; &#123; ... &#125;);","text":"问题：java读取resource中的文件，在打成jar包后路径变化，导致文件读取失败。 原因：使用这种方法可以正常读取到文件，但是打成jar包后路径就产生了变化，所以读取失败。 12URL url = TEST.class.getResource(path);Files.lines(Paths.get(url.toURI()), 解决方法：采用getResourceAsStream读取文件 123456InputStream is = this.getClass().getResourceAsStream(path);BufferedReader br = new BufferedReader(new InputStreamReader(is));String s = \"\";br.lines().forEach(str -&gt; &#123; ... &#125;); 获取resource下的文件路径的方法12345//注意'/'String path1 = test.class.getResource(\"/convertFile\").getPath();String path2 = test.class.getResource(\"/convertFile\").toURI().getPath();String path3 = test.class.getClassLoader().getResource(\"convertFile\").getPath();String path4= test.class.getClassLoader().getResource(\"convertFile\").toURI().getPath(); 借此机会顺便整理一下关于JavaIO相关的知识，经常忘记这部分API。 InputStream、ReaderInputStream 为字节输入流，它本身为一个抽象类，必须依靠其子类实现各种功能，此抽象类是表示字节输入流的所有类的超类。 继承自InputStream 的流都是向程序中输入数据的，且数据单位为字节（8bit）； 123456789101112File file = new File(\"/Users/zh/as.sh\"); InputStream in = new FileInputStream(file); InputStreamReader reader = new InputStreamReader(in,\"UTF-8\"); StringBuffer sb = new StringBuffer(); while (reader.ready()) &#123; sb.append((char) reader.read()); // 转成char加到StringBuffer对象中 &#125; System.out.println(sb.toString()); reader.close(); in.close(); OutputStream、Writer12345String str = \"hello world\";// 构建FileOutputStream对象,文件不存在会自动新建OutputStream out = new FileOutputStream(\"src/test2.txt\");out.write(str.getBytes());out.close(); 复制文件到另一个文件123456789FileInputStream in = new FileInputStream(\"AtomicityTest.java\");FileOutputStream out = new FileOutputStream(\"copy.txt\");int b;while ((b = in.read()) != -1)&#123; out.write(b);&#125;out.flush();in.close();out.close(); 参考链接：https://my.oschina.net/airship/blog/1927940","categories":[{"name":"记录","slug":"记录","permalink":"https://originer.github.io/Horizon.github.io/categories/记录/"}],"tags":[]},{"title":"RocketMQ单主单从模式部署","slug":"RocketMq学习","date":"2018-11-28T06:36:18.000Z","updated":"2019-02-20T03:54:45.220Z","comments":true,"path":"2018/11/28/RocketMq学习/","link":"","permalink":"https://originer.github.io/Horizon.github.io/2018/11/28/RocketMq学习/","excerpt":"RocketMq是一个阿里开源的基于Java语言的高性能、高吞吐量的分布式消息中间件。 阿里中间件团队对RocketMq的解释：http://jm.taobao.org/2017/01/12/rocketmq-quick-start-in-10-minutes/ apache-rocketmq部署：Master-Slave单主单从需要两台机器，学习可以使用虚拟机代替。 首先先从git上clone代码，然后maven编译，编译完可以在 ../rocketmq-master/distribution/target路径下找到apache-rocketmq.tar.gz","text":"RocketMq是一个阿里开源的基于Java语言的高性能、高吞吐量的分布式消息中间件。 阿里中间件团队对RocketMq的解释：http://jm.taobao.org/2017/01/12/rocketmq-quick-start-in-10-minutes/ apache-rocketmq部署：Master-Slave单主单从需要两台机器，学习可以使用虚拟机代替。 首先先从git上clone代码，然后maven编译，编译完可以在 ../rocketmq-master/distribution/target路径下找到apache-rocketmq.tar.gz 解压代码到指定路径：tar -zxvf apache-rocketmq.tar.gz -C /usr/local/rocketmq创建存储路径: /usr/local/rocketmq/store mkdir /usr/local/rocketmq/store/commitlog mkdir /usr/local/rocketmq/store/consumequeue mkdir /usr/local/rocketmq/store/index 配置文件：vim /usr/local/rocketmq/conf/2m-2s-async/broker-a.properties vim /usr/local/rocketmq/conf/2m-2s-async/broker-a-s.properties 修改日志配置：mkdir -p /usr/local/rocketmq/logs cd /usr/local/rocketmq/conf &amp;&amp; sed -i ‘s#${user.home}#/usr/local/rocketmq#g’ *.xml 这里要注意，如果是mac系统sed命令跟linux有点区别，需要在 sed -i 后面添加 &quot;&quot;. 修改配置文件12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758#所属集群名字brokerClusterName=rocketmq-cluster#broker 名字，注意此处不同的配置文件填写的不一样 brokerName=broker-a|broker-b#0 表示 Master，&gt;0 表示 SlavebrokerId=0#nameServer 地址，分号分割 namesrvAddr=rocketmq-nameserver1:9876;rocketmq-nameserver2:9876 #在发送消息时，自动创建服务器不存在的 topic，默认创建的队列数 defaultTopicQueueNums=4#是否允许 Broker 自动创建 Topic，建议线下开启，线上关闭 autoCreateTopicEnable=true#是否允许 Broker 自动创建订阅组，建议线下开启，线上关闭 autoCreateSubscriptionGroup=true#Broker 对外服务的监听端口listenPort=10911#删除文件时间点，默认凌晨 4 点deleteWhen=04#文件保留时间，默认 48 小时fileReservedTime=120#commitLog 每个文件的大小默认 1G mapedFileSizeCommitLog=1073741824#ConsumeQueue 每个文件默认存 30W 条，根据业务情况调整 mapedFileSizeConsumeQueue=300000 #destroyMapedFileIntervalForcibly=120000 #redeleteHangedFileInterval=120000#检测物理文件磁盘空间diskMaxUsedSpaceRatio=88#存储路径storePathRootDir=/usr/local/rocketmq/store#commitLog 存储路径 storePathCommitLog=/usr/local/rocketmq/store/commitlog #消费队列存储路径存储路径 storePathConsumeQueue=/usr/local/rocketmq/store/consumequeue #消息索引存储路径storePathIndex=/usr/local/rocketmq/store/index#checkpoint 文件存储路径 storeCheckpoint=/usr/local/rocketmq/store/checkpoint#abort 文件存储路径abortFile=/usr/local/rocketmq/store/abort#限制的消息大小maxMessageSize=65536#flushCommitLogLeastPages=4 #flushConsumeQueueLeastPages=2#flushCommitLogThoroughInterval=10000 #flushConsumeQueueThoroughInterval=60000#Broker 的角色#- ASYNC_MASTER 异步复制 Master #- SYNC_MASTER 同步双写 Master #- SLAVEbrokerRole=ASYNC_MASTER#刷盘方式#- ASYNC_FLUSH 异步刷盘 #- SYNC_FLUSH 同步刷盘 flushDiskType=ASYNC_FLUSH#checkTransactionMessageEnable=false #发消息线程池数量 #sendMessageThreadPoolNums=128 #拉消息线程池数量 #pullMessageThreadPoolNums=128 修改启动脚本参数：vim /usr/local/rocketmq/bin/runbroker.sh JAVA_OPT=&quot;${JAVA_OPT} -server -Xms1g -Xmx1g -Xmn512m -XX:PermSize=128m - XX:MaxPermSize=320m&quot; vim /usr/local/rocketmq/bin/runserver.sh JAVA_OPT=&quot;${JAVA_OPT} -server -Xms1g -Xmx1g -Xmn512m -XX:PermSize=128m -XX:MaxPermSize=320m&quot; 启动NameServercd /usr/local/rocketmq/bin nohup sh mqnamesrv &amp; 启动A、B机器cd /usr/local/rocketmq/binnohup sh mqbroker -c /usr/local/rocketmq/conf/2m-2s-async/broker-a.propertiesnetstat -ntlpjpstail -f -n 500 /usr/local/rocketmq/logs/rocketmqlogs/broker.logtail -f -n 500 /usr/local/rocketmq/logs/rocketmqlogs/namesrv.log 遇到的坑runbroker.sh runserver.sh 里面默认的JAVA_HOME配置项需要改一下，不然会出现 Please set the JAVA_HOME variable in your environment, We need java(x64)! 12345678# [ ! -e \"$JAVA_HOME/bin/java\" ] &amp;&amp; JAVA_HOME=$HOME/jdk/java# [ ! -e \"$JAVA_HOME/bin/java\" ] &amp;&amp; JAVA_HOME=/usr/java# [ ! -e \"$JAVA_HOME/bin/java\" ] &amp;&amp; error_exit \"Please set the JAVA_HOME variable in your environment, We need java(x64)!\"export JAVA_HOME=/Library/Java/JavaVirtualMachines/jdk1.8.0_191.jdk/Contents/Homeexport JAVA=\"$JAVA_HOME/bin/java\"export BASE_DIR=$(dirname $0)/..export CLASSPATH=.:$&#123;BASE_DIR&#125;/conf:$&#123;CLASSPATH&#125;","categories":[{"name":"RocketMQ","slug":"RocketMQ","permalink":"https://originer.github.io/Horizon.github.io/categories/RocketMQ/"}],"tags":[{"name":"RocketMq","slug":"RocketMq","permalink":"https://originer.github.io/Horizon.github.io/tags/RocketMq/"}]},{"title":"MySql性能优化实践","slug":"MySql性能优化","date":"2018-11-28T06:05:34.000Z","updated":"2018-11-28T06:05:34.000Z","comments":true,"path":"2018/11/28/MySql性能优化/","link":"","permalink":"https://originer.github.io/Horizon.github.io/2018/11/28/MySql性能优化/","excerpt":"sql性能优化一般有以下几种方式： sql及索引、数据表结构、系统配置、硬件这四个按顺序效果越来越小，成本越来越高，所以对数据库性能进行优化一般都是从sql语句和索引入手。","text":"sql性能优化一般有以下几种方式： sql及索引、数据表结构、系统配置、硬件这四个按顺序效果越来越小，成本越来越高，所以对数据库性能进行优化一般都是从sql语句和索引入手。 如何发现有问题的SQL使用MySql慢查询日志 123456789101112USE sakila;-- 查询是否开启了慢查询日志SHOW VARIABLES LIKE 'slow_query_log';-- 开启慢查询日志SET GLOBAL slow_query_log = ON;-- 查询具体日志参数SHOW VARIABLES LIKE '%log';-- 把没有使用到索引的sql语句记录到日志中SET GLOBAL log_queries_not_using_indexes = ON; 慢查询日志分析工具 mysqldumpslow pt-query-digest Sql语句优化explain执行计划分析 max优化EXPLAIN SELECT max(payment_date) FROM payment; 可以看出，max查询在表数据比较多时要全部遍历是比较慢的，可以采用建立索引来进行优化 CREATE INDEX idx_paydate on payment(payment_date); 这是添加索引后的结果： 通过索引，就避免的遍历表，可以通过索引直接取到数据，因为索引是有顺序的。 count优化select count(release_year=’2006’ OR NULL) as ‘2006’,count(release_year=’2007’ OR NULL) as ‘2007’ from film; 一个技巧，用or Null 可以分别统计多列的数据。 子查询优化 把子查询优化成join查询，但是要注意数据重复问题，可以用distinct去重。 group by 优化limit 优化limit常用于分页处理，时常伴随order by使用，所以会造成大量的IO。 优化方式：尽量使用主键，使用主键可以利用到索引，减少扫描行数。如果要查询的id非常大，就可以利用主键id是有顺序的这一特点来做限制，比如 select id from t order by id limit 100,5; 会扫描105行，如果id非常大的时候就会扫描非常多，利用select id from t where id &gt; 100 and id &lt; 105 order by id limit 1,5; 就可以显著减少扫描的行数。 EXPLAIN select film_id,description from sakila.film order by film_id limit 600,5 EXPLAIN select film_id,description from sakila.film where film_id&gt;600 and film_id&lt;=605 order by film_id limit 0,5 索引优化如何建立索引 在where group by order by on 中出现的列 索引字段越小越好 离散度大的列放到联合索引前面（离散度可以用 select （distinct count col）from table来统计，一般数量越接近表的行数离散度越好） 如果索引能够覆盖到全部的列，把索引成为覆盖索引。 重复及冗余索引索引一般可以增加查询效率，但是会降低写入效率，所以并不是越多越好。要尽可能的降低重复索引和冗余索引。 作为主键的列本身就是索引，所以在建立别的联合索引的时候不需要把主键添加进来。 查询重复和冗余索引： 1SELECT a.TABLE_SCHEMA, a.TABLE_NAME, a.COLUMN_NAME, a.INDEX_NAME AS 'index1', b.INDEX_NAME AS 'index2' FROM information_schema.STATISTICS a JOIN information_schema.STATISTICS b ON a.TABLE_SCHEMA = b.TABLE_SCHEMA AND a.TABLE_NAME = b.TABLE_NAME AND a.SEQ_IN_INDEX = b.SEQ_IN_INDEX AND a.COLUMN_NAME = b.COLUMN_NAME WHERE a.SEQ_IN_INDEX = 1 AND a.INDEX_NAME &lt;&gt; b.INDEX_NAME 使用工具 pt-duplicate-key-checker 也可以找出重复冗余索引，同时还能对优化索引提出建议。 数据库表优化使用合适的数据类型 使用可以存下数据的最小数据类型 使用更简单的数据类型，比如 int 比 varchar 更容易被处理 尽可能使用 not null 定义字段 少用 text 类型，用的时候优先考虑分表 例如，用int存储时间类型，通过FORM_UNIXTIME() UNIX_TIMESTAMP() 来进行转换。用bigint存储ip地址，通过INET_ATON() INET_NTOA()来进行转换。 数据表范式优化一般是指第三范式，即数据表中的非关键字段对候选关键字段不存在函数依赖关系。 反范式化：为了查询效率，有时候表设计要有适当的冗余； 数据表垂直拆分垂直拆分就是把一个表分成多个表，解决表宽度的问题。 把不常用的字段单独放一个表 把大字段比如text类型的单独放一个表 把经常使用的字段放在一起 数据表水平拆分解决数据量过大的问题，把同一张表按照序号建立1-n张重复的表，然后对数据操作的时候可以通过id的hash值取模来判断数据在哪张表，这样就避免了大量数据在同一张表的问题。 注意保留一张汇总表，用于后台统计。拆分表主要是给前台使用，提高查询效率。 系统配置优化数据库一般都是部署在linux系统的，对系统的参数配置也会影响到数据库性能。 MySql配置文件常用参数innodb_buffer_pool_size 用于配置innoDB的缓冲池，一般大小设置为总内存的75% innodb_buffer_pool_instance配置多个缓冲池 innodb_flush_log_at_trx_commit把事务变更刷新到磁盘的策略，对IO效率影响很大。可取0，1，2默认为1，建议设置为2。 innodb_read_io_threads innodb_write_io_threads innodb读写的IO进程数，默认为4 innodb_file_per_table使用共享表空间，默认为off，也就是所有表都会建立在共享表空间。","categories":[{"name":"数据库","slug":"数据库","permalink":"https://originer.github.io/Horizon.github.io/categories/数据库/"}],"tags":[{"name":"sql","slug":"sql","permalink":"https://originer.github.io/Horizon.github.io/tags/sql/"}]},{"title":"Git常用命令整理","slug":"Git命令整理","date":"2018-11-28T02:17:56.000Z","updated":"2019-03-13T11:01:17.848Z","comments":true,"path":"2018/11/28/Git命令整理/","link":"","permalink":"https://originer.github.io/Horizon.github.io/2018/11/28/Git命令整理/","excerpt":"mkdir： XX (创建一个空目录 XX指目录名) pwd： 显示当前目录的路径。 git init 把当前的目录变成可以管理的git仓库，生成隐藏.git文件。 git add XX 把xx文件添加到暂存区去。","text":"mkdir： XX (创建一个空目录 XX指目录名) pwd： 显示当前目录的路径。 git init 把当前的目录变成可以管理的git仓库，生成隐藏.git文件。 git add XX 把xx文件添加到暂存区去。 git commit –m “XX” 提交文件 –m 后面的是注释。 git status 查看仓库状态 git diff XX 查看XX文件修改了那些内容 git log 查看历史记录 git reset –hard HEAD^ 或者 git reset –hard HEAD~ 回退到上一个版 (如果想回退到100个版本，使用git reset –hard HEAD~100 ) cat XX 查看XX文件内容 git reflog 查看历史记录的版本号id git checkout — XX 把XX文件在工作区的修改全部撤销。 git rm XX 删除XX文件 git remote add origin https://github.com/tugenhua0707/testgit 关联一个远程库 git push –u(第一次要用-u 以后不需要) origin master 把当前master分支推送到远程库 git clone https://github.com/tugenhua0707/testgit 从远程库中克隆 git checkout –b dev 创建dev分支 并切换到dev分支上 git branch 查看当前所有的分支 git checkout master 切换回master分支 git merge dev 在当前的分支上合并dev分支 git branch –d dev 删除dev分支 git branch name 创建分支 git stash 把当前的工作隐藏起来 等以后恢复现场后继续工作 git stash list 查看所有被隐藏的文件列表 git stash apply 恢复被隐藏的文件，但是内容不删除 git stash drop 删除文件 git stash pop 恢复文件的同时 也删除文件 git remote 查看远程库的信息 git remote –v 查看远程库的详细信息 git push origin master Git会把master分支推送到远程库对应的远程分支上 git pull 抓取分支 git branch –set-upstream master origin/master 设置本地分支和远程分支的链接 git remote rm origingit remote add origin [url]git rev-parse HEAD 查看commitId git checkout -b branchname 创建并切换到本地分支git pull origin remotebranchname 将改分支与远程分支关联 git push origin –delete 删除远程分支 git push origin –delete tag 删除远程tag git cofing –global user.name git config –global user.email git config –global -l 查看全局git账户 git ls-files -d | xargs echo -e | xargs git checkout – 恢复commit中被删除的文件 (xagrs echo -e 用于转义中文，如果文件中没有中文字符可以省略) git ls-files -m | xargs echo -e | xargs git checkout – 恢复commit中被修改的文件 git reset –soft HEAD^ 撤销上一次commit，代码不会变动","categories":[{"name":"工具","slug":"工具","permalink":"https://originer.github.io/Horizon.github.io/categories/工具/"}],"tags":[]},{"title":"Netty核心组件：EventLoop和EventLoopGroup","slug":"Netty核心组件：EventLoop和EventLoopGroup","date":"2018-11-27T09:08:12.000Z","updated":"2018-12-02T06:33:06.718Z","comments":true,"path":"2018/11/27/Netty核心组件：EventLoop和EventLoopGroup/","link":"","permalink":"https://originer.github.io/Horizon.github.io/2018/11/27/Netty核心组件：EventLoop和EventLoopGroup/","excerpt":"Reactor线程模型 Reactor单线程模型 Reactor多线程模型 Reactor主从线程模型 Netty的线程模型netty可以根据配置，灵活的使用上面的几种线程模型。","text":"Reactor线程模型 Reactor单线程模型 Reactor多线程模型 Reactor主从线程模型 Netty的线程模型netty可以根据配置，灵活的使用上面的几种线程模型。 1234567891011121314151617EventLoopGroup bossGroup = new NioEventLoopGroup();EventLoopGroup workerGroup = new NioEventLoopGroup();try &#123; ServerBootstrap b = new ServerBootstrap(); b.group(bossGroup, workerGroup).channel(NioServerSocketChannel.class).childHandler(new ChannelInitializer&lt;SocketChannel&gt;() &#123; @Override public void initChannel(SocketChannel ch) &#123; ch.pipeline().addLast(new Encoder()); ch.pipeline().addLast(new BizHandler()); &#125; &#125;); ChannelFuture f = b.bind(8888).sync(); f.channel().closeFuture().sync();&#125; finally &#123; bossGroup.shutdownGracefully(); workerGroup.shutdownGracefully();&#125; 上面是一段Netty服务端的启动代码，服务端在启动的时候创建了两个NioEventLoopGroup，实际上就是启动了两个独立的Reactor线程池，一个用于接收连接，一个用来处理IO事件，或者执行系统Task。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152@Overrideprotected void run() &#123; for (;;) &#123; try &#123; switch (selectStrategy.calculateStrategy(selectNowSupplier, hasTasks())) &#123; case SelectStrategy.CONTINUE: continue; case SelectStrategy.SELECT: select(wakenUp.getAndSet(false)); if (wakenUp.get()) &#123; selector.wakeup(); &#125; default: // fallthrough &#125; cancelledKeys = 0; needsToSelectAgain = false; final int ioRatio = this.ioRatio; if (ioRatio == 100) &#123; try &#123; processSelectedKeys(); &#125; finally &#123; // Ensure we always run tasks. runAllTasks(); &#125; &#125; else &#123; final long ioStartTime = System.nanoTime(); try &#123; processSelectedKeys(); &#125; finally &#123; // Ensure we always run tasks. final long ioTime = System.nanoTime() - ioStartTime; runAllTasks(ioTime * (100 - ioRatio) / ioRatio); &#125; &#125; &#125; catch (Throwable t) &#123; handleLoopException(t); &#125; // Always handle shutdown even if the loop processing threw an exception. try &#123; if (isShuttingDown()) &#123; closeAll(); if (confirmShutdown()) &#123; return; &#125; &#125; &#125; catch (Throwable t) &#123; handleLoopException(t); &#125; &#125;&#125; 简单的理解是，每次一个新的Channel连接进来会被绑定一个NioEventLoop，然后接下来这个Channel的所有读写事件都是由这个NioEventLoop来负责，避免了多线程操作导致的竞争。 NioEventLoop新连接接入过程 创建NioSocketChannel 新连接进入的处理逻辑","categories":[{"name":"网络编程","slug":"网络编程","permalink":"https://originer.github.io/Horizon.github.io/categories/网络编程/"}],"tags":[{"name":"Netty","slug":"Netty","permalink":"https://originer.github.io/Horizon.github.io/tags/Netty/"}]},{"title":"SQL索引学习","slug":"SQL索引学习","date":"2018-11-26T07:55:48.000Z","updated":"2018-11-26T07:55:48.000Z","comments":true,"path":"2018/11/26/SQL索引学习/","link":"","permalink":"https://originer.github.io/Horizon.github.io/2018/11/26/SQL索引学习/","excerpt":"面试的时候除了基本的增删改查，一般就是会问一些sql优化相关的，这部分很多知识是跟索引有关系的。面试两次都被SQL索引问题问倒了，有必要给自己充一下电，深入学习一下sql的索引机制。","text":"面试的时候除了基本的增删改查，一般就是会问一些sql优化相关的，这部分很多知识是跟索引有关系的。面试两次都被SQL索引问题问倒了，有必要给自己充一下电，深入学习一下sql的索引机制。 关于索引索引分类：聚集索引和非聚集索引。以字典举例，拼音查询就是聚集索引，部首查询就是非聚集索引。 聚集索引和非聚集索引的根本区别是表记录的排列顺序和与索引的排列顺序是否一致，简单理解：比如聚集索引，a开头的数据后面一定是b开头的，跟物理排列顺序一致。非聚集索引就像部首查询，两个相同部首的可能位置相差非常远。 原理明白了，那他们是怎么存储的呢？在这里简单的说一下，聚集索引就是在数据库被开辟一个物理空间存放他的排列的值，例如1-100，所以当插入数据时，他会重新排列整个整个物理空间，而非聚集索引其实可以看作是一个含有聚集索引的表，他只仅包含原表中非聚集索引的列和指向实际物理表的指针。他只记录一个指针，其实就有点和堆栈差不多的感觉了。 个人理解：索引其实就是另外开辟一块空间，用来保存经过索引排列过顺序的数据，然后这些数据会映射到真正在表中存储的数据，实际上是以空间换时间的做法。一般数据库中的索引结构都是B+树。 建立索引的原则1) 定义主键的数据列一定要建立索引。 2) 定义有外键的数据列一定要建立索引。 3) 对于经常查询的数据列最好建立索引。 4) 对于需要在指定范围内的快速或频繁查询的数据列; 5) 经常用在WHERE子句中的数据列。 6) 经常出现在关键字order by、group by、distinct后面的字段，建立索引。如果建立的是复合索引，索引的字段顺序要和这些关键字后面的字段顺序一致，否则索引不会被使用。 7) 对于那些查询中很少涉及的列，重复值比较多的列不要建立索引。 8) 对于定义为text、image和bit的数据类型的列不要建立索引。 9) 对于经常存取的列避免建立索引 9) 限制表上的索引数目。对一个存在大量更新操作的表，所建索引的数目一般不要超过3个，最多不要超过5个。索引虽说提高了访问速度，但太多索引会影响数据的更新操作。 10) 对复合索引，按照字段在查询条件中出现的频度建立索引。在复合索引中，记录首先按照第一个字段排序。对于在第一个字段上取值相同的记录，系统再按照第二个字段的取值排序，以此类推。因此只有复合索引的第一个字段出现在查询条件中，该索引才可能被使用,因此将应用频度高的字段，放置在复合索引的前面，会使系统最大可能地使用此索引，发挥索引的作用。 如何对索引执行效果进行分析然后进行查询优化：在MySql中有慢查询语句，可以帮助找到执行缓慢的sql。在my.ini文件中配置开启，可以保存超时的语句。然后就可以用执行计划explain进行分析。 EXPLAIN SELECT * from dept_emp; EXPLAIN 执行结果中的具体含义： id SELECT识别符。这是SELECT的查询序列号 select_type SELECT类型,可以为以下任何一种:SIMPLE:简单SELECT(不使用UNION或子查询)PRIMARY:最外面的SELECTUNION:UNION中的第二个或后面的SELECT语句DEPENDENT UNION:UNION中的第二个或后面的SELECT语句,取决于外面的查询UNION RESULT:UNION 的结果SUBQUERY:子查询中的第一个SELECTDEPENDENT SUBQUERY:子查询中的第一个SELECT,取决于外面的查询DERIVED:导出表的SELECT(FROM子句的子查询) table 输出的行所引用的表 type 联接类型。下面给出各种联接类型,按照从最佳类型到最坏类型进行排序:system:表仅有一行(=系统表)。这是const联接类型的一个特例。const:表最多有一个匹配行,它将在查询开始时被读取。因为仅有一行,在这行的列值可被优化器剩余部分认为是常数。const表很快,因为它们只读取一次!eq_ref:对于每个来自于前面的表的行组合,从该表中读取一行。这可能是最好的联接类型,除了const类型。ref:对于每个来自于前面的表的行组合,所有有匹配索引值的行将从这张表中读取。ref_or_null:该联接类型如同ref,但是添加了MySQL可以专门搜索包含NULL值的行。index_merge:该联接类型表示使用了索引合并优化方法。unique_subquery:该类型替换了下面形式的IN子查询的ref: value IN (SELECT primary_key FROM single_table WHERE some_expr) unique_subquery是一个索引查找函数,可以完全替换子查询,效率更高。index_subquery:该联接类型类似于unique_subquery。可以替换IN子查询,但只适合下列形式的子查询中的非唯一索引: value IN (SELECT key_column FROM single_table WHERE some_expr)range:只检索给定范围的行,使用一个索引来选择行。index:该联接类型与ALL相同,除了只有索引树被扫描。这通常比ALL快,因为索引文件通常比数据文件小。ALL:对于每个来自于先前的表的行组合,进行完整的表扫描。 possible_keys 指出MySQL能使用哪个索引在该表中找到行 key 显示MySQL实际决定使用的键(索引)。如果没有选择索引,键是NULL。 key_len 显示MySQL决定使用的键长度。如果键是NULL,则长度为NULL。 ref 显示使用哪个列或常数与key一起从表中选择行。 rows 显示MySQL认为它执行查询时必须检查的行数。多行之间的数据相乘可以估算要处理的行数。 filtered 显示了通过条件过滤出的行数的百分比估计值。 Extra 该列包含MySQL解决查询的详细信息Distinct:MySQL发现第1个匹配行后,停止为当前的行组合搜索更多的行。Not exists:MySQL能够对查询进行LEFT JOIN优化,发现1个匹配LEFT JOIN标准的行后,不再为前面的的行组合在该表内检查更多的行。range checked for each record (index map: #):MySQL没有发现好的可以使用的索引,但发现如果来自前面的表的列值已知,可能部分索引可以使用。Using filesort:MySQL需要额外的一次传递,以找出如何按排序顺序检索行。Using index:从只使用索引树中的信息而不需要进一步搜索读取实际的行来检索表中的列信息。Using temporary:为了解决查询,MySQL需要创建一个临时表来容纳结果。Using where:WHERE 子句用于限制哪一个行匹配下一个表或发送到客户。Using sort_union(…), Using union(…), Using intersect(…):这些函数说明如何为index_merge联接类型合并索引扫描。Using index for group-by:类似于访问表的Using index方式,Using index for group-by表示MySQL发现了一个索引,可以用来查 询GROUP BY或DISTINCT查询的所有列,而不要额外搜索硬盘访问实际的表。","categories":[{"name":"数据库","slug":"数据库","permalink":"https://originer.github.io/Horizon.github.io/categories/数据库/"}],"tags":[]},{"title":"Java设计模式：观察者模式","slug":"设计模式：观察者模式","date":"2018-11-21T09:34:40.000Z","updated":"2018-11-21T09:34:40.000Z","comments":true,"path":"2018/11/21/设计模式：观察者模式/","link":"","permalink":"https://originer.github.io/Horizon.github.io/2018/11/21/设计模式：观察者模式/","excerpt":"观察者模式定义可以理解为发布订阅模式，订阅者订阅之后就可以监听发布者的消息。","text":"观察者模式定义可以理解为发布订阅模式，订阅者订阅之后就可以监听发布者的消息。 主要角色 抽象被观察者角色：也就是一个抽象主题，它把所有对观察者对象的引用保存在一个集合中，每个主题都可以有任意数量的观察者。抽象主题提供一个接口，可以增加和删除观察者角色。一般用一个抽象类和接口来实现。 抽象观察者角色：为所有的具体观察者定义一个接口，在得到主题通知时更新自己。 具体被观察者角色：也就是一个具体的主题，在集体主题的内部状态改变时，所有登记过的观察者发出通知。 具体观察者角色：实现抽象观察者角色所需要的更新接口，一边使本身的状态与制图的状态相协调。 使用场景涉及到消息发布订阅的都可以用这种模式，适用范围十分广泛 代码实现123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138public class ObserverTest &#123; /** * 被观察者 */ public interface Observerable &#123; void registerObserver(Observer o); void removeObserver(Observer o); void notifyObserver(); &#125; /** * 观察者 */ public interface Observer &#123; void notify(String message); &#125; public static class Girl implements Observerable &#123; private String message; List&lt;Observer&gt; observerList; public Girl() &#123; observerList = new ArrayList&lt;&gt;(); &#125; @Override public void registerObserver(Observer o) &#123; observerList.add(o); &#125; @Override public void removeObserver(Observer o) &#123; observerList.remove(o); &#125; //核心方法，用来通知所有订阅者 @Override public void notifyObserver() &#123; for (Observer observer : observerList) &#123; observer.notify(message); &#125; &#125; //一些特例，不需要通知所有订阅者时使用 public void hasBoyFriend() &#123; message = \"女神有男朋友了\"; notifyObserver(); &#125; public void getMarried() &#123; message = \"女神结婚了，你们都死心吧!\"; notifyObserver(); &#125; public void getSingled() &#123; message = \"女神单身了，你们有机会了!\"; notifyObserver(); &#125; &#125; /** * 男孩 */ public static class Boy implements Observer &#123; public void notify(String message) &#123; System.out.println(\"男孩收到消息：\" + message); &#125; &#125; /** * 男人 */ public static class Man implements Observer &#123; public void notify(String message) &#123; System.out.println(\"男人收到消息：\" + message); &#125; &#125; /** * 老男人 */ public static class OldMan implements Observer &#123; public void notify(String message) &#123; System.out.println(\"老男人收到消息：\" + message); &#125; &#125; public static void main(String[] args) &#123; Girl girl = new Girl(); Boy boy = new Boy(); Man man = new Man(); OldMan oldMan = new OldMan(); // 通知男孩、男人、老男人，女神有男朋友了 girl.registerObserver(boy); girl.registerObserver(man); girl.registerObserver(oldMan); girl.hasBoyFriend(); System.out.println(\"====================\"); // 通知男孩，男人，女神结婚了 girl.removeObserver(oldMan); girl.getMarried(); System.out.println(\"====================\"); girl.registerObserver(oldMan); girl.getSingled(); &#125; //Netty中的一段代码，使用Netty添加监听器属于典型的观察者模式 public void write(NioSocketChannel channel, Object object) &#123; ChannelFuture channelFuture = channel.writeAndFlush(object); channelFuture.addListener(future -&gt; &#123; if (future.isSuccess()) &#123; &#125; else &#123; &#125; &#125;); channelFuture.addListener(future -&gt; &#123; if (future.isSuccess()) &#123; &#125; else &#123; &#125; &#125;); channelFuture.addListener(future -&gt; &#123; if (future.isSuccess()) &#123; &#125; else &#123; &#125; &#125;); &#125;&#125;","categories":[{"name":"设计模式","slug":"设计模式","permalink":"https://originer.github.io/Horizon.github.io/categories/设计模式/"}],"tags":[{"name":"设计模式","slug":"设计模式","permalink":"https://originer.github.io/Horizon.github.io/tags/设计模式/"}]},{"title":"SpringMVC数据绑定总结","slug":"SpringMVC数据绑定总结","date":"2018-11-21T06:19:24.000Z","updated":"2018-12-05T07:22:17.512Z","comments":true,"path":"2018/11/21/SpringMVC数据绑定总结/","link":"","permalink":"https://originer.github.io/Horizon.github.io/2018/11/21/SpringMVC数据绑定总结/","excerpt":"","text":"SpringMVC数据绑定原理SpringMVC的数据绑定像一个黑盒子，通过ajax请求发送过来的字段都能被我们后端定义的字段精准接收到，看上去很神奇其实原理挺简单的，http请求传递的数据都是String类型的，我们可以在方法中定义参数的类型，当请求中的数据包含这个参数的时候，会使用转码器自动转化成我们需要的数据类型。 能够传递的数据类型基本类型基本类型名称与前端名称对应 包装类型使用包装类型传的值可以为null 获取参数的方式一：直接将请求参数名作为Controller中方法的形参public String login (String username,String password) ： 解释：括号中的参数必须与页面Form 表单中的 name 名字相同 二：使用@RequestParam 绑定请求参数参数值举例：public String login(RequestParam (“username”) String name) : 解释：双引号中的username 必须与页面 name 名字相同，String name 中的name可以随便写 三：用注解@RequestMapping接收参数的方法1@RequestMapping(value=\"/login/&#123;username&#125;/&#123;password&#125;\") public String login(@PathVariable(“username”) String name，@PathVariable(“password”) String name) 解释:上面的 @RequestMapping(value=”/login/{username}/{password}”) 是以注解的方式写在方法上的。注解上的usernname和 password 必须好页面上name 相同 四：使用Pojo对象（就是封装的类，类中封装的字段作为参数）绑定请求参数值，原理是利用Set的页面反射机制找到User对象中的属性举例：@ReauestMapping（value=/login”） 1public String login(User user)&#123; 解释：就是把封装的一个类当成一个参数放在方法中，封装类中的属性就是就是参数。 五：使用原生的Servlet API 作为Controller 方法的参数12345public String login(HttpServletRequest request) &#123;String usernma=Request.getParameter(\"username\");｝ 另外，如果有特殊需求，SpringMVC支持自定义参数转码器，比较常用的比如日期转码。","categories":[{"name":"Spring相关","slug":"Spring相关","permalink":"https://originer.github.io/Horizon.github.io/categories/Spring相关/"}],"tags":[{"name":"SpringMVC","slug":"SpringMVC","permalink":"https://originer.github.io/Horizon.github.io/tags/SpringMVC/"}]},{"title":"Java虚拟机学习笔记","slug":"Java虚拟机学习笔记","date":"2018-11-20T02:06:37.000Z","updated":"2018-11-20T02:06:37.000Z","comments":true,"path":"2018/11/20/Java虚拟机学习笔记/","link":"","permalink":"https://originer.github.io/Horizon.github.io/2018/11/20/Java虚拟机学习笔记/","excerpt":"Java内存区域与内存溢出异常运行时数据区域下图是Java运行时数据区域划分图 区域 是否线程共享 是否会内存溢出 程序计数器 否 不会 java虚拟机栈 否 会 本地方法栈 否 会 堆 是 会 方法区 是 会","text":"Java内存区域与内存溢出异常运行时数据区域下图是Java运行时数据区域划分图 区域 是否线程共享 是否会内存溢出 程序计数器 否 不会 java虚拟机栈 否 会 本地方法栈 否 会 堆 是 会 方法区 是 会 1.程序计数器(线程私有) 一块较小的内存，可以看作是当前线程所执行的字节码的行号指示器； 在虚拟机概念模型（各种虚拟机实现可能不一样）中，字节码解释器工作时就是通过改变这个计数器的值来选取下一条需要执行的字节码指令； 程序计数器是属于线程私有的内存； 如果执行的是Java方法，该计数器记录的是正在执行的虚拟机字节码指令的地址；如果是Native方法则为空； 2.Java虚拟机栈（线程私有） Java虚拟机栈也是线程私有的； 描述的是Java方法执行的内存模型：每个方法在执行的同时都会创建一个栈帧（Stack Frame）用于存储局部变量表、操作数栈、动态链接、方法出口等信息。每一个方法从调用直至执行完成的过程，就对应着一个栈帧在虚拟机中入栈到出栈的过程； 局部变量表存放了编译器可知的各种基本数据类型、对象引用和returnAddress类型；其所需的内存空间在编辑期完成分配，不会再运行期改变； 可能存在两种异常：StackOverflowError(请求栈深度过大)和OutOfMemoryError（内存不够时）； 3.本地方法栈 与虚拟机栈非常相似，只不过是为虚拟机使用到的Native方法服务； 可能存在两种异常：StackOverflowError和OutOfMemoryError； 4.Java堆（线程共享） Java堆是被所有线程共享的，在虚拟机启动时创建； 此内存区域的唯一目的就是存放对象实例，几乎所有的对象实例都在这分配； 是垃圾收集器管理的主要区域，可以分为新生代和老年代； 可以物理不连续，只要逻辑上是连续的即可； 如果堆中没有内存完成实例分配也无法再扩展时，会抛出OutOfMemoryError异常； 5.方法区/元空间（永久代）（线程共享） 是线程共享的区域； 用于存储已被虚拟机加载的类信息、常量、静态变量、即时编译器编译后的代码等数据； 该区域对于垃圾收集来说条件比较苛刻，但是还是非常有必要要进行回收处理； 当无法满足内存分配需求时，将抛出OutOfMemoryError异常； 6.运行时常量池 是方法区的一部分； Class文件中除了有类的版本、字段、方法、接口等描述信息外，还有一项信息是常量池，用于存放编译器生成的各种字面量和符号引用，这部分内容将在类加载后进入方法区的运行时常量池中存放； Java虚拟机规范要求较少，通常还会把翻译出来的直接引用也存储在此； 另外一个重要特征是具备动态性，可以在运行期间将新的常量放入池中，如String的intern方法； 可能存在的异常：OutOfMemoryError； 7.直接内存 并不是虚拟机运行时数据区的一部分，也不是Java虚拟机规范中定义的内存区域； JDK 1.4的NIO引入了基于通道（Channel）和缓冲区（Buffer）的IO方法，可以使用Native函数库直接分配对外内存，然后通过一个存储在Java堆中的DirectByteBuffer对象作为这块内存的引用进行操作以提升性能； 对象的访问定位 栈上的reference类型在虚拟机规范中只规定了一个指向对象的引用，并没有定义这个引用应该通过何种方式去定位、访问堆栈对象的具体位置，目前主流的方式方式有句柄和直接指针两种。 通过句柄：Java堆中划出一块内存作为句柄池，reference中存储的就是对象的句柄地址，而句柄中包含了对象实例数据与类型数据各自的具体地址信息。其最大好处就是reference存储的是稳定的句柄地址，在对象被移动（垃圾收集时移到）只改变实例数据指针，而reference不需要修改； 通过直接指针：Java堆对象的布局中必须考虑如果放置访问类型数据的相关信息，而reference中存在的直接就是对象地址。其最大好处在于速度更快，节省了一次指针定位的时机开销。HotSpot采用该方式进行对象访问，但其他语言和框架采用句柄的也非常常见。 Java垃圾回收机器与内存分配策略程序计时器、虚拟机栈、本地方法栈：随线程而灭，栈帧随方法而进行出栈和入栈，每一个栈帧分配的内存在类结构确定就已知，因此这几个区域不需要考虑回收； 对于Java堆和方法区，只有程序运行期间才知道会创建哪些对象，内存的分配和回收都是动态的，垃圾收集器所关注的是这部分内存； 判断Java中对象存活的算法1.引用计数算法给对象添加引用计数器，当有地方引用它时就加1，引用失效就减1，为0时就认为对象不再被使用可回收。该算法失效简单，判断高效，但并不被主流虚拟机采用，主要原因是它很难解决对象之间相互循环引用的问题。 2.可达性分析算法通过一系列的称为“GC Roots”的对象作为起点，从这些节点开始向下搜索，搜索所走过的路径称为引用链（Reference Chain），如果一个对象到GC Roots没有引用链相连，则该对象是不可用的。 在Java语言中，可作为GC Roots的对象包括： 虚拟机栈（栈帧中的本地变量表）中引用的对象； 方法区中类静态属性引用的对象； 方法区中常量引用的对象； 本地方法栈中JNI（即一般说的Native方法）引用的对象； 垃圾收集算法 1.标记-清除算法(Mark-Sweep)：首先标记出所有需要回收的对象，然后统一回收所有被标记的对象；缺点是效率不高且容易产生大量不连续的内存碎片； 复制算法：将可用内存分为大小相等的两块，每次只使用其中一块；当这一块用完了，就将还活着的对象复制到另一块上，然后把已使用过的内存清理掉。在HotSpot里，考虑到大部分对象存活时间很短将内存分为Eden和两块Survivor，默认比例为8:1:1。代价是存在部分内存空间浪费，适合在新生代使用； 标记-整理算法：首先标记出所有需要回收的对象，然后让所有存活的对象都向一端移动，然后直接清理掉端边界以外的内存。适用于老年代。 ​ 分代收集算法：一般把Java堆分新生代和老年代，在新生代用复制算法，在老年代用标记-清理或标记-整理算法，是现代虚拟机通常采用的算法。 垃圾收集器 垃圾收集算法是内存回收的方法论，垃圾收集器就是内存回收的具体实现。 这里讨论JDK 1.7 Update 14之后的HotSpot虚拟机（此时G1仍处于实验状态），包含的虚拟机如下图所示（存在连线的表示可以搭配使用）： 1.Serial收集器（单线程的收集器） 最基本、发展历史最悠久，在JDK 1.3之前是新生代收集的唯一选择； 是一个单线程（并非指一个收集线程，而是会暂停所有工作线程）的收集器，采用的是复制算法; 现在依然是虚拟机运行在Client模式下的默认新生代收集器，主要就是因为它简单而高效（没有线程交互的开销）； 2.ParNew收集器（Serial收集器的多线程版本） 其实就是Serial收集器的多线程版本； ParNew收集器在单CPU环境中绝对不会有比Serial收集器更好的效果； 是许多运行在Server模式下虚拟机首选的新生代收集器，重要原因就是除了Serial收集器外，只有它能与CMS收集器配合工作； 并行（Parallel）：指多条垃圾收集线程并行工作，但此时用户线程仍处于等待状态； 并发（Concurrent）：指用户线程与垃圾收集线程同时执行，用户线程在继续执行而垃圾收集程序运行在另外一个CPU上； 3.Parallel Scavenge收集器 吞吐量=运行用户代码时间/(运行用户代码时间+垃圾收集时间) 新生代收集器，使用复制算法，并行的多线程收集器； 与CMS关注于尽可能缩短垃圾收集时用户线程停顿时间不同，PS的目标是达到一个可控制的吞吐量； 高吞吐量可以高效率利用CPU时间，适合在后台运算而不需要太多交互的任务； -XX:MaxGCPauseMillis参数可以设置最大停顿时间，而停顿时间缩短是以牺牲吞吐量和新生代空间来换取的； 另外它还支持GC自适应的调节策略； 4.Serial Old收集器 是Serial收集器的老年代版本，同样是单线程，使用标记-整理算法； 主要是给Client模式下的虚拟机使用的； 在Server模式下主要是给JDK 1.5及之前配合Parallel Scavenge使用或作为CMS收集器的后备预案； 5.Parallel Old收集器 是Parallel Scavenge的老年代版本，使用多线程和标记-整理算法； 6.CMS收集器 是一种以获取最短回收停顿时间为目标的收集器，特别适合互联网站或者B/S的服务端； 它是基于标记-清除 算法实现的，主要包括4个步骤：初始标记（STW-stop the world，只是初始标记一下GC Roots能直接关联到的对象，速度很快）、并发标记（非STW，执行GC RootsTracing，耗时比较长）、重新标记（STW，修正并发标记期间因用户程序继续导致变动的那一部分对象标记）和并发清除（非STW，耗时较长）； 还有3个明显的缺点：CMS收集器对CPU非常敏感（占用部分线程及CPU资源，影响总吞吐量）、无法处理浮动垃圾（默认达到92%就触发垃圾回收）、大量内存碎片产生（可以通过参数启动压缩）； 7.G1收集器 一款面向服务端应用的垃圾收集器，后续会替换掉CMS垃圾收集器； 特点：并行与并发（充分利用多核多CPU缩短Stop-The-World时间）、分代收集（独立管理整个Java堆，但针对不同年龄的对象采取不同的策略）、空间整合（基于标记-整理）、可预测的停顿（将堆分为大小相等的独立区域，避免全区域的垃圾收集）； 关于Region：新生代和老年代不再物理隔离，只是部分Region的集合；G1跟踪各个Region垃圾堆积的价值大小，在后台维护一个优先列表，根据允许的收集时间优先回收价值最大的Region；Region之间的对象引用以及其他收集器中的新生代与老年代之间的对象引用，采用Remembered Set来避免全堆扫描； 分为几个步骤：1.初始标记（标记一下GC Roots能直接关联的对象并修改TAMS值，需要STW但耗时很短）、2.并发标记（从GC Root从堆中对象进行可达性分析找存活的对象，耗时较长但可以与用户线程并发执行）、3.最终标记（为了修正并发标记期间产生变动的那一部分标记记录，这一期间的变化记录在Remembered Set Log里，然后合并到Remembered Set里，该阶段需要STW但是可并行执行）、4.筛选回收（对各个Region回收价值排序，根据用户期望的GC停顿时间制定回收计划来回收）； 理解GC日志 最前面的数字代表GC发生的时间（虚拟机启动以后的秒杀）； “[GC”和“[Full GC”说明停顿类型，有Full代表的是Stop-The-World的； “[DefNew”、“[Tenured”和“[Perm”表示GC发生的区域； 方括号内部的“3324K -&gt; 152K(3712K)” 含义是 “GC前该内存已使用容量 -&gt; GC后该内存区域已使用容量(该区域总容量)”; 方括号之外的“3324K -&gt; 152K(11904)” 含义是 “GC前Java堆已使用容量 -&gt; GC后Java堆已使用容量(Java堆总容量)”; 再往后“0.0025925 secs”表示该内存区域GC所占用的时间； 内存分配与回收策略 对象优先在新生代分配 大对象直接进入老年代 长期存活的对象将进入老年代 动态对象年龄判断：如果在Survivor空间中相同年龄所有对象大小总和大于Survivor空间的一半，大于或等于该年龄的对象直接进入老年代； 空间分配担保：发生Minor GC前，虚拟机会先检查老年代最大可用连续空间是否大于新生代所有对象总空间，如果不成立，虚拟机会查看HandlePromotionFailure设置值是否允许担保失败，如果允许继续检查老年代最大可用的连续空间是否大于历次晋升到老年代的平均大小，如果大于会尝试进行一次Minor GC；如果小于或者不允许冒险，会进行一次Full GC； 虚拟机类加载机制概述 虚拟机把描述类的数据从Class文件加载到内存，并对数据进行校验、转换解析和初始化，最终形成可以被虚拟机直接使用的Java类型，这就是虚拟机的类加载机制。 在Java语言里面，类型的加载、连接和初始化过程都是在程序运行期间完成，这虽然增量一些性能开销，但是会为Java应用程序提供高度的灵活性。 类加载的时机 类的整个生命周期：加载、验证、准备、解析、初始化、使用和卸载；其中验证、准备和解析统称为连接； 虚拟机规范没有强制约束类加载的时机，但严格规定了有且只有5种情况必须立即对类进行初始化：遇到new、getstatic、putstatic和invokestatic指令；对类进行反射调用时如果类没有进行过初始化；初始化时发现父类还没有进行初始化；虚拟机启动指定的主类；动态语言中MethodHandle实例最后解析结果REF_getStatic等的方法句柄对应的类没有初始化时； 类加载的过程1.加载 通过一个类的全限定名来获取定义此类的二进制字节流； 将这个字节流所代表的静态存储结构转化为方法区的运行时数据结构； 在内存中生成一个代表这个类的java.lang.Class对象，作为方法区这个类的各种数据的访问入口； 2.验证 验证是连接阶段的第一步，其目的是确保Class文件的字节流中包含的信息符合当前虚拟机的要求，并且不会危害虚拟机自身的安全； 验证阶段是非常重要的，这个阶段是否严谨决定了Java虚拟机是否能承受恶意代码的攻击； 校验动作：文件格式验证（基于二进制字节流）、元数据验证（对类的元数据语义分析）、字节码验证（对方法体语义分析）、符号引用验证（对类自身以外的信息进行匹配性校验）； 3.准备 正式为变量分配内存并设置类变量初始值的阶段，这些变量所使用的内存都将在这个方法区中进行分配； 需要强调两点：这时候内存分配的仅包括类变量，而不包括类实例变量；这里所说的初始化通常情况下是数据类型的零值，真正的赋值是在初始化阶段，如果是static final的则是直接赋值； 4.解析 解析阶段是虚拟机将常量池内的符号引用（如CONSTANT_Class_info、CONSTANT_Fieldref_info、CONSTANT_Methodref_info等7种）替换为直接引用的过程； 符号引用可以是任何形式的字面量，与虚拟机实现的内存布局无关，引用的目标并不一定已经加载到内存中；而直接引用是直接指向目标的指针、相对偏移量或是一个能间接定位到目标的句柄，它和虚拟机实现的内存布局相关，引用的目标必定以及在内存中存在； 对同一个符号引用进行多次解析请求是很常见的事情，虚拟机实现可以对第一次解析的结果进行缓存； 5.初始化 是类加载过程的最后一步，真正开始执行类中定义的Java程序代码（或者说是字节码）； 初始化阶段是执行类构造器方法的过程，该方法是由编译器自动收集类中的所有类变量的赋值动作和静态语句块中的语句合并产生的； 方法与类的构造函数（或者说是实例构造器方法）不同，它不需要显式地调用父类构造器，虚拟机会保证在子类的方法执行之前，父类的方法已执行完毕； 执行接口的方法不需要先执行父接口的方法，只有当父接口中定义的变量使用时父接口才会初始化，接口的实现类在初始化时也一样不会执行接口的方法； 方法初始化是加锁阻塞等待的，应当避免在方法中有耗时很长的操作； 类加载器 虚拟机设计团队把类加载阶段的“通过一个类的全限定名来获取描述此类的二进制字节流”这个动作放到虚拟机外部去实现，实现这个动作的代码模块称为类加载器； 这是Java语言的一项创新，也是Java语言流行的重要原因，在类层次划分、OSGI、热部署、代码加密等领域大放异彩 类与类加载器 对于任意一个类，都需要由加载它的类加载器和这个类本身一同确立其在Java虚拟机的唯一性，每一个类加载器都拥有一个独立的类名称空间； 比较两个类是否相等（如Class对象的equals方法、isAssignableFrom方法、isInstance方法），只有在这两个类是由同一个类加载器加载的前提下才有意义； 双亲委派模型 关于双亲委派模型，这篇文章写得简单易懂:http://www.jianshu.com/p/acc7595f1b9d 三种系统提供的类加载器：启动类加载器（Bootstrap ClassLoader）、扩展类加载器（Extension ClassLoader）、应用程序类加载器（Application ClassLoader）； 双亲委派模型要求除了顶层的启动类加载器外，其他的类加载器都应当有自己的父类加载器，这里一般不会以继承的关系来实现，而是使用组合的关系来复用父加载器的代码； 其工作过程是：如果一个类加载器收到了类加载的请求，它首先不会自己去尝试加载这个类，而是把这个请求委派给父类加载器去完成，只有父类加载器反馈自己无法完成这个加载请求时（它的搜索范围中没有找到所需的类），子加载器才会尝试自己去加载； 这样的好处是Java类随着它的类加载器具备了一种带有优先级的层次关系，对保证Java程序的稳定运作很重要； 实现双亲委派的代码都集中在java.lang.ClassLoader的loadClass方法中，逻辑清晰易懂； 关于Java内存模型：https://juejin.im/post/5bf2977751882505d840321d?utm_source=gold_browser_extension","categories":[{"name":"JVM","slug":"JVM","permalink":"https://originer.github.io/Horizon.github.io/categories/JVM/"}],"tags":[]},{"title":"常用排序算法总结","slug":"常用排序算法总结","date":"2018-11-19T09:25:10.000Z","updated":"2018-12-02T06:35:38.069Z","comments":true,"path":"2018/11/19/常用排序算法总结/","link":"","permalink":"https://originer.github.io/Horizon.github.io/2018/11/19/常用排序算法总结/","excerpt":"都是一些比较经典和基础的排序算法，应该是每个开发者都要掌握的，但是工作中用到的机会其实不多，时间长了会忘记。但是面试的时候也许会用到，所以做一个总结，方便自己复习。 排序动态视图展示：https://visualgo.net/en/sorting","text":"都是一些比较经典和基础的排序算法，应该是每个开发者都要掌握的，但是工作中用到的机会其实不多，时间长了会忘记。但是面试的时候也许会用到，所以做一个总结，方便自己复习。 排序动态视图展示：https://visualgo.net/en/sorting 一、稳定性: 稳定：冒泡排序、插入排序、归并排序和基数排序 不稳定：选择排序、快速排序、希尔排序、堆排序 二、平均时间复杂度 O(n^2):直接插入排序，简单选择排序，冒泡排序。 在数据规模较小时（9W内），直接插入排序，简单选择排序差不多。当数据较大时，冒泡排序算法的时间代价最高。性能为O(n^2)的算法基本上是相邻元素进行比较，基本上都是稳定的。 O(nlogn):快速排序，归并排序，希尔排序，堆排序。 其中，快排是最好的， 其次是归并和希尔，堆排序在数据量很大时效果明显。 三、排序算法的选择 1.数据规模较小 （1）待排序列基本序的情况下，可以选择直接插入排序； （2）对稳定性不作要求宜用简单选择排序，对稳定性有要求宜用插入或冒泡 2.数据规模不是很大 （1）完全可以用内存空间，序列杂乱无序，对稳定性没有要求，快速排序，此时要付出log（N）的额外空间。 （2）序列本身可能有序，对稳定性有要求，空间允许下，宜用归并排序 3.数据规模很大 （1）对稳定性有求，则可考虑归并排序。 ​ （2）对稳定性没要求，宜用堆排序 4.序列初始基本有序（正序），宜用直接插入，冒泡 直接插入排序1234567891011121314151617181920212223242526272829//伪代码mark first element as sortedfor each unsorted element X 'extract' the element X for j = lastSortedIndex down to 0 if current element j &gt; X move sorted element to the right by 1 break loop and insert X here//实现public static int[] insertSort(int[] arr) &#123; int len = arr.length; int insertNum;//要插入的数 for (int i = 1; i &lt; len; i++) &#123;//因为第一次不用，所以从1开始 insertNum = arr[i]; int j = i - 1;//序列元素个数 while (j &gt;= 0 &amp;&amp; arr[j] &gt; insertNum) &#123;//从后往前循环，将大于insertNum的数向后移动 arr[j + 1] = arr[j];//元素向后移动 j--; &#125; arr[j + 1] = insertNum;//找到位置，插入当前元素 &#125; return arr;&#125; 冒泡排序1234567891011121314151617181920212223242526272829/** * 冒泡排序 * do * * swapped = false * * for i = 1 to indexOfLastUnsortedElement-1 * * if leftElement &gt; rightElement * * swap(leftElement, rightElement) * * swapped = true; swapCounter++ * * while swapped */public static int[] bubbleSort(int[] arr) &#123; int len = arr.length; for (int i = 0; i &lt; len; i++) &#123; for (int j = 0; j &lt; len - i - 1; j++) &#123;//注意第二重循环的条件 if (arr[j] &gt; arr[j + 1]) &#123; int temp = arr[j]; arr[j] = arr[j + 1]; arr[j + 1] = temp; &#125; &#125; &#125; return arr;&#125; 选择排序12345678910111213141516171819202122232425262728293031323334353637/** * repeat (numOfElements - 1) times * * set the first unsorted element as the minimum * * for each of the unsorted elements * * if element &lt; currentMinimum * * set element as new minimum * * swap minimum with first unsorted positio */public static int[] sort(int[] arr) &#123; for (int i = 0; i &lt; arr.length; i++) &#123; int min = findMinIndex(arr, i); swap(arr, i, min); &#125; return arr;&#125;private static void swap(int[] arr, int i, int min) &#123; int tmp = arr[i]; arr[i] = arr[min]; arr[min] = tmp;&#125;private static int findMinIndex(int[] arr, int i) &#123; int min = i; for (int j = i + 1; j &lt; arr.length; j++) &#123; if (arr[j] &lt; arr[min]) &#123; min = j; &#125; &#125; return min;&#125; 快速排序123456789101112131415161718192021222324252627282930313233343536373839404142434445464748/** * 快速排序，递归实现 * for each (unsorted) partition * * set first element as pivot * * storeIndex = pivotIndex + 1 * * for i = pivotIndex + 1 to rightmostIndex * * if element[i] &lt; element[pivot] * * swap(i, storeIndex); storeIndex++ * * swap(pivot, storeIndex - 1) */public class QuickSort &#123; public static int[] quickSort(int[] arr, int start, int end) &#123; if (start &lt; end) &#123; int baseNum = arr[start];//选基准值 int midNum;//记录中间值 int i = start; int j = end; do &#123; while ((arr[i] &lt; baseNum) &amp;&amp; i &lt; end) &#123; i++; &#125; while ((arr[j] &gt; baseNum) &amp;&amp; j &gt; start) &#123; j--; &#125; if (i &lt;= j) &#123; midNum = arr[i]; arr[i] = arr[j]; arr[j] = midNum; i++; j--; &#125; &#125; while (i &lt;= j); if (start &lt; j) &#123; quickSort(arr, start, j); &#125; if (end &gt; i) &#123; quickSort(arr, i, end); &#125; &#125; return arr; &#125;&#125;","categories":[{"name":"算法","slug":"算法","permalink":"https://originer.github.io/Horizon.github.io/categories/算法/"}],"tags":[]},{"title":"Java常用的缓存方案","slug":"缓存相关","date":"2018-11-19T07:37:45.000Z","updated":"2018-11-19T07:37:45.000Z","comments":true,"path":"2018/11/19/缓存相关/","link":"","permalink":"https://originer.github.io/Horizon.github.io/2018/11/19/缓存相关/","excerpt":"","text":"缓存命中率缓存的设计要考虑到具体的业务场景，一般来说，并发量越大，缓存的收益就越大。 缓存的分类本地缓存编程实现（成员变量、局部变量、静态变量）Guava Cache 分布式缓存Memcache、Redis Guava Cache 类似一个ConcurrentHashMap、包含了多余的信息，使用LRU策略来实现缓存。 Memcache Memcache本身不提供分布式解决方案，需要在应用服务器上进行实现。 Memcache的内存结构 redis 缓存穿透概念访问一个不存在的key，缓存不起作用，请求会穿透到DB，流量大时DB会挂掉。 解决方案 采用布隆过滤器，使用一个足够大的bitmap，用于存储可能访问的key，不存在的key直接被过滤； 访问key未在DB查询到值，也将空值写进缓存，但可以设置较短过期时间。 缓存雪崩概念大量的key设置了相同的过期时间，导致在缓存在同一时刻全部失效，造成瞬时DB请求量大、压力骤增，引起雪崩。 解决方案可以给缓存设置过期时间时加上一个随机值时间，使得每个key的过期时间分布开来，不会集中在同一时刻失效。 缓存击穿概念一个存在的key，在缓存过期的一刻，同时有大量的请求，这些请求都会击穿到DB，造成瞬时DB请求量大、压力骤增。 解决方案在访问key之前，采用SETNX（set if not exists）来设置另一个短期key来锁住当前key的访问，访问结束再删除该短期key。","categories":[{"name":"Java","slug":"Java","permalink":"https://originer.github.io/Horizon.github.io/categories/Java/"}],"tags":[]},{"title":"CopyOnWriteArrayList详解","slug":"CopyOnWriteArrayList详解","date":"2018-11-18T12:05:41.000Z","updated":"2018-11-18T12:05:41.000Z","comments":true,"path":"2018/11/18/CopyOnWriteArrayList详解/","link":"","permalink":"https://originer.github.io/Horizon.github.io/2018/11/18/CopyOnWriteArrayList详解/","excerpt":"CopyOnWriteArrayList与JMM一 CopyOnWriteArrayList与JMM说明：本文代码均以JDK1.8的源码为准。 1 什么是CopyOnWriteArrayList关于CopyOnWriteArrayList是什么以及基本用法，在这里不多说，网上可以搜到大量这方面的文章。在这里只做简要说明：CopyOnWriteArrayList相当于线程安全的ArrayList，是一个可变数组。它具有如下特性： 是线程安全的 写操作会复制整个基础数组，因此写操作开销很大 适用于如下情况：数组大小较小，并且读操作比写操作多很多的情形","text":"CopyOnWriteArrayList与JMM一 CopyOnWriteArrayList与JMM说明：本文代码均以JDK1.8的源码为准。 1 什么是CopyOnWriteArrayList关于CopyOnWriteArrayList是什么以及基本用法，在这里不多说，网上可以搜到大量这方面的文章。在这里只做简要说明：CopyOnWriteArrayList相当于线程安全的ArrayList，是一个可变数组。它具有如下特性： 是线程安全的 写操作会复制整个基础数组，因此写操作开销很大 适用于如下情况：数组大小较小，并且读操作比写操作多很多的情形 2 CopyOnWriteArrayList的设计原理与JMM下面我们分析CopyOnWriteArrayList的设计原理，结合JMM的基础知识，分析CopyOnWriteArrayList是如何保证线程安全的。 首先看用来实际保存数据的数组： 12/** The array, accessed only via getArray/setArray. */private transient volatile Object[] array; 可以看到array数组前面使用了volatile变量来修饰。volatile主要用来解决内存可见性问题。关于volatile的详细实现原理可以参考《深入理解java内存模型.pdf》以及Java并发编程：volatile关键字解析-博客园-海子。 2.1 CopyOnWriteArrayList的读方法读方法比较简单，直接从array中获取对应索引的值。 123456789101112131415161718192021/** * &#123;@inheritDoc&#125; * * @throws IndexOutOfBoundsException &#123;@inheritDoc&#125; */public E get(int index) &#123; return get(getArray(), index);&#125;@SuppressWarnings(\"unchecked\")private E get(Object[] a, int index) &#123; return (E) a[index];&#125;/** * Gets the array. Non-private so as to also be accessible * from CopyOnWriteArraySet class. */final Object[] getArray() &#123; return array;&#125; 2.2 CopyOnWriteArrayList的写方法 set方法源码如下： 12345678910111213141516171819202122232425262728293031323334/** * Replaces the element at the specified position in this list with the * specified element. * * @throws IndexOutOfBoundsException &#123;@inheritDoc&#125; */public E set(int index, E element) &#123; final ReentrantLock lock = this.lock; lock.lock(); try &#123; Object[] elements = getArray(); E oldValue = get(elements, index); if (oldValue != element) &#123; int len = elements.length; Object[] newElements = Arrays.copyOf(elements, len); newElements[index] = element; setArray(newElements); &#125; else &#123; // Not quite a no-op; ensures volatile write semantics setArray(elements); &#125; return oldValue; &#125; finally &#123; lock.unlock(); &#125;&#125;/** * Sets the array. */final void setArray(Object[] a) &#123; array = a;&#125; set方法的功能是将对应索引的元素置为一个新值。执行流程： （1）加锁 （2）获取对应索引已有的值 （3）比较已有的值和新值，如果不相等，转4，否则转5 （4）创建新的数组，复制原数组的元素，并将对应索引置为新值。然后将新数组赋给array（setArray） （5）setArray-将array赋给array 这里有一个比较奇怪的点，为什么已有的值和新值相等的时候，还要执行setArray呢？本质上setArray也没有做什么事情。 这段代码混合使用了锁以及volatile。锁的用法比较容易理解，它在使用同一个锁的不同线程之间保证内存顺序性，代码结尾的释放锁的操作提供了本线程和其他欲获取相同的锁的线程之间的happens-before语义。但是CopyOnWriteArrayList类中其他代码，不一定会使用到这把锁，因此，前面所述的锁带来的内存模型含义对这部分代码执行是不适用的。 其他没用到这把锁的代码，读写是volatile读和volatile写（因为array前面使用volatile关键字修饰）。由volatile来保证happens-before语义。 volatile的特性及原理 volatile 变量自身具有下列特性:（1）可见性。对一个volatile 变量的读,总是能看到(任意线程)对这个volatile变量最后的写入。（2）原子性:对任意单个volatile 变量的读/写具有原子性,但类似于volatile++这种复合操作不具有原子性。 volatile 写和锁的释放有相同的内存语义。 为了实现 volatile 的内存语义,编译器在生成字节码时,会在指令序列中插入内存屏障来禁止特定类型的处理器重排序。 这里调用setArray的原因是，确保set方法对array执行的永远是volatile写。这就和其他对array执行volatile读的线程之间建立了happens-before语义。非常重要的一点：volatile读/写语义针对的是读写操作，而不是使用volatile修饰的变量本身。这样说更直白一点：在一个volatile写操作之前的对其他非volatile变量的写，happens-before于同一个volatile变量读操作之后的对其他变量的读。这句话比较绕，看下面一个例子就比较易懂了。 12345678910111213// initial conditionsint nonVolatileField = 0;CopyOnWriteArrayList&lt;String&gt; list = /* a single String */// Thread 1nonVolatileField = 1; // (1)list.set(0, \"x\"); // (2)// Thread 2String s = list.get(0); // (3)if (s == \"x\") &#123; int localVar = nonVolatileField; // (4)&#125; 现在假设原始数组中无元素“x”，这样(2)成功设置了元素”x”，(3)处可以成功获取到元素”x”。这种情况下，(4)一定会读取到(1)处设置的值1.因为(2)处的volatile写以及在此之前的任何写操作都happens-before(3)处的读以及之后的所有读。 但是，假设一开始数组中就有了元素”x”，如果else不调用setArray，那么(2)处的写就不是volatile写，(4)处的读就不一定能读到(1)处设置的值！ 很显然我们不想让内存可见性依赖于list中已有的值，为了确保任何情况下的内存可见性，set方法必须永远都是一个volatile写，这就是为何要在else代码块中调用setArray的原因。 其他写方法（add、remove）比较易懂，在此不详述。 3 参考资料 Java多线程系列–“JUC集合”02之 CopyOnWriteArrayList Why setArray() method call required in CopyOnWriteArrayList 深入理解java内存模型.pdf Java并发编程：volatile关键字解析-博客园-海子 二 为什么Java HashMap、CopyOnWriteArrayList等集合自己实现readObject和writeObject方法PS:本文源码参考的是JDK 1.8. 1 readObject、writeObject方法是什么？作用是什么？当一个class实现了Serializable接口，那么意味着这个类可以被序列化。如果类不实现readObject、writeObject方法，那么会执行默认的序列化和反序列化逻辑，否则执行自定义的序列化和反序列化逻辑，即readObject、writeObject方法的逻辑。 JDK提供的对于Java对象序列化操作的类是ObjectOutputStream，反序列化的类是ObjectInputStream。下面我们来看序列化的实现（ObjectOutputStream.writeObject）。 1234567891011121314151617181920212223242526272829303132333435/** * Write the specified object to the ObjectOutputStream. The class of the * object, the signature of the class, and the values of the non-transient * and non-static fields of the class and all of its supertypes are * written. Default serialization for a class can be overridden using the * writeObject and the readObject methods. Objects referenced by this * object are written transitively so that a complete equivalent graph of * objects can be reconstructed by an ObjectInputStream. * * &lt;p&gt;Exceptions are thrown for problems with the OutputStream and for * classes that should not be serialized. All exceptions are fatal to the * OutputStream, which is left in an indeterminate state, and it is up to * the caller to ignore or recover the stream state. * * @throws InvalidClassException Something is wrong with a class used by * serialization. * @throws NotSerializableException Some object to be serialized does not * implement the java.io.Serializable interface. * @throws IOException Any exception thrown by the underlying * OutputStream. */public final void writeObject(Object obj) throws IOException &#123; if (enableOverride) &#123; writeObjectOverride(obj); return; &#125; try &#123; writeObject0(obj, false); &#125; catch (IOException ex) &#123; if (depth == 0) &#123; writeFatalException(ex); &#125; throw ex; &#125;&#125; 从方法注释可以看到，此方法正是执行了将对象序列化的操作。并且默认的序列化机制可以通过重写readObject、writeObject方法实现。实际调用的方法writeObject0最终会调到writeSerialData： 123456789101112131415161718192021222324252627282930313233343536373839404142/** * Writes instance data for each serializable class of given object, from * superclass to subclass. */private void writeSerialData(Object obj, ObjectStreamClass desc) throws IOException&#123; ObjectStreamClass.ClassDataSlot[] slots = desc.getClassDataLayout(); for (int i = 0; i &lt; slots.length; i++) &#123; ObjectStreamClass slotDesc = slots[i].desc; //如果类重写了writeObject方法 if (slotDesc.hasWriteObjectMethod()) &#123; PutFieldImpl oldPut = curPut; curPut = null; SerialCallbackContext oldContext = curContext; if (extendedDebugInfo) &#123; debugInfoStack.push( \"custom writeObject data (class \\\"\" + slotDesc.getName() + \"\\\")\"); &#125; try &#123; curContext = new SerialCallbackContext(obj, slotDesc); bout.setBlockDataMode(true); //调用实现类自己的writeobject方法 slotDesc.invokeWriteObject(obj, this); bout.setBlockDataMode(false); bout.writeByte(TC_ENDBLOCKDATA); &#125; finally &#123; curContext.setUsed(); curContext = oldContext; if (extendedDebugInfo) &#123; debugInfoStack.pop(); &#125; &#125; curPut = oldPut; &#125; else &#123; defaultWriteFields(obj, slotDesc); &#125; &#125;&#125; 2 为什么是private方法？javadoc上没有明确说明声明为private的原因，一个可能的原因是，除了子类以外没有其他类会使用它，这样不会被滥用。 另一个原因是，不希望这些方法被子类override。每个类都可以有自己的writeObject方法，序列化引擎会逐一调用。readObject相同。 3 HashMap中对readObject、writeObject方法的实现3.1 为什么HashMap要自定义序列化逻辑下文是摘自《Effective Java》： For example, consider the case of a hash table. The physical representation is a sequence of hash buckets containing key-value entries. The bucket that an entry resides in is a function of the hash code of its key, which is not, in general, guaranteed to be the same from JVM implementation to JVM implementation. In fact, it isn’t even guaranteed to be the same from run to run. Therefore, accepting the default serialized form for a hash table would constitute a serious bug. Serializing and deserializing the hash table could yield an object whose invariants were seriously corrupt. 大概意思是：对于同一个key，在不同的JVM平台上计算出来的hash值可能不同，导致的结果就是，同一个hashmap反序列化之后和序列化之前不同，导致同一个key取出来的值不同。 3.2 HashMap是如何解决的 将可能造成数据不一致的元素使用transient修饰，在序列化的时候忽略这些元素：Entry[] tablesizemodCount HashMap中对writeObject的实现： 12345678910111213141516171819202122private void writeObject(java.io.ObjectOutputStream s) throws IOException &#123; int buckets = capacity(); // Write out the threshold, loadfactor, and any hidden stuff s.defaultWriteObject(); s.writeInt(buckets); s.writeInt(size); internalWriteEntries(s);&#125;// Called only from writeObject, to ensure compatible ordering.void internalWriteEntries(java.io.ObjectOutputStream s) throws IOException &#123; Node&lt;K,V&gt;[] tab; if (size &gt; 0 &amp;&amp; (tab = table) != null) &#123; for (int i = 0; i &lt; tab.length; ++i) &#123; for (Node&lt;K,V&gt; e = tab[i]; e != null; e = e.next) &#123; s.writeObject(e.key); s.writeObject(e.value); &#125; &#125; &#125;&#125; HashMap不会将保存数据的数组序列化，而是将元素个数以及每个元素的key、value序列化。而在反序列化的时候，重新计算，填充hashmap： readObject的实现： 1234567891011121314151617181920212223242526272829303132333435363738394041424344/** * Reconstitute the &#123;@code HashMap&#125; instance from a stream (i.e., * deserialize it). */private void readObject(java.io.ObjectInputStream s) throws IOException, ClassNotFoundException &#123; // Read in the threshold (ignored), loadfactor, and any hidden stuff s.defaultReadObject(); reinitialize(); if (loadFactor &lt;= 0 || Float.isNaN(loadFactor)) throw new InvalidObjectException(\"Illegal load factor: \" + loadFactor); s.readInt(); // Read and ignore number of buckets int mappings = s.readInt(); // Read number of mappings (size) if (mappings &lt; 0) throw new InvalidObjectException(\"Illegal mappings count: \" + mappings); else if (mappings &gt; 0) &#123; // (if zero, use defaults) // Size the table using given load factor only if within // range of 0.25...4.0 float lf = Math.min(Math.max(0.25f, loadFactor), 4.0f); float fc = (float)mappings / lf + 1.0f; int cap = ((fc &lt; DEFAULT_INITIAL_CAPACITY) ? DEFAULT_INITIAL_CAPACITY : (fc &gt;= MAXIMUM_CAPACITY) ? MAXIMUM_CAPACITY : tableSizeFor((int)fc)); float ft = (float)cap * lf; threshold = ((cap &lt; MAXIMUM_CAPACITY &amp;&amp; ft &lt; MAXIMUM_CAPACITY) ? (int)ft : Integer.MAX_VALUE); @SuppressWarnings(&#123;\"rawtypes\",\"unchecked\"&#125;) Node&lt;K,V&gt;[] tab = (Node&lt;K,V&gt;[])new Node[cap]; table = tab; // Read the keys and values, and put the mappings in the HashMap for (int i = 0; i &lt; mappings; i++) &#123; @SuppressWarnings(\"unchecked\") K key = (K) s.readObject(); @SuppressWarnings(\"unchecked\") V value = (V) s.readObject(); putVal(hash(key), key, value, false, false); &#125; &#125;&#125; 这样就避免了反序列化之后根据Key获取到的元素与序列化之前获取到的元素不同。 4 为什么CopyOnWriteArrayList也需要自定义序列化逻辑？writeObject、readObject实现： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647/** * Saves this list to a stream (that is, serializes it). * * @param s the stream * @throws java.io.IOException if an I/O error occurs * @serialData The length of the array backing the list is emitted * (int), followed by all of its elements (each an Object) * in the proper order. */ private void writeObject(java.io.ObjectOutputStream s) throws java.io.IOException &#123; s.defaultWriteObject(); Object[] elements = getArray(); // Write out array length s.writeInt(elements.length); // Write out all elements in the proper order. for (Object element : elements) s.writeObject(element); &#125; /** * Reconstitutes this list from a stream (that is, deserializes it). * @param s the stream * @throws ClassNotFoundException if the class of a serialized object * could not be found * @throws java.io.IOException if an I/O error occurs */ private void readObject(java.io.ObjectInputStream s) throws java.io.IOException, ClassNotFoundException &#123; s.defaultReadObject(); // bind to new lock resetLock(); // Read in array length and allocate array int len = s.readInt(); Object[] elements = new Object[len]; // Read in all elements in the proper order. for (int i = 0; i &lt; len; i++) elements[i] = s.readObject(); setArray(elements); &#125; 而数组被声明为transient： 12/** The array, accessed only via getArray/setArray. */private transient volatile Object[] array; 可以看出其逻辑和ArrayList相同：是将数组长度以及所有元素序列化，在反序列化的时候新建数组，填充元素。 如果采用默认的序列化机制会有如下问题：存储数据的数组实际上是动态数组，每次在放满以后自动增长设定的长度值，如果数组自动增长长度设为100，而实际只放了一个元素，那就会序列化很多null元素，所以ArrayList把元素数组设置为transient。","categories":[{"name":"Java集合框架","slug":"Java集合框架","permalink":"https://originer.github.io/Horizon.github.io/categories/Java集合框架/"}],"tags":[{"name":"Java集合框架","slug":"Java集合框架","permalink":"https://originer.github.io/Horizon.github.io/tags/Java集合框架/"}]},{"title":"HTTP协议相关笔记","slug":"HTTP协议相关笔记","date":"2018-11-17T07:51:01.000Z","updated":"2018-11-17T07:51:01.000Z","comments":true,"path":"2018/11/17/HTTP协议相关笔记/","link":"","permalink":"https://originer.github.io/Horizon.github.io/2018/11/17/HTTP协议相关笔记/","excerpt":"什么是HTTP协议协议是指计算机通信网络中两台计算机之间进行通信所必须共同遵守的规定或规则，超文本传输协议(HTTP)是一种通信协议，它允许将超文本标记语言(HTML)文档从Web服务器传送到客户端的浏览器。","text":"什么是HTTP协议协议是指计算机通信网络中两台计算机之间进行通信所必须共同遵守的规定或规则，超文本传输协议(HTTP)是一种通信协议，它允许将超文本标记语言(HTML)文档从Web服务器传送到客户端的浏览器。 URL详解 URL(Uniform Resource Locator) 地址用于描述一个网络上的资源, 基本格式如下 1schema://host[:port#]/path/.../[?query-string][#anchor] scheme 指定低层使用的协议(例如：http, https, ftp) host HTTP服务器的IP地址或者域名 port# HTTP服务器的默认端口是80，这种情况下端口号可以省略。如果使用了别的端口，必须指明，例如 http://www.cnblogs.com:8080/ path 访问资源的路径 query-string 发送给http服务器的数据 anchor- 锚 HTTP协议是无状态的http协议是无状态的，同一个客户端的这次请求和上次请求是没有对应关系，对http服务器来说，它并不知道这两个请求来自同一个客户端。 为了解决这个问题， Web程序引入了Cookie机制来维护状态. 打开一个网页需要浏览器发送很多次Request\\1. 当你在浏览器输入URL http://www.cnblogs.com 的时候，浏览器发送一个Request去获取 http://www.cnblogs.com 的html. 服务器把Response发送回给浏览器. \\2. 浏览器分析Response中的 HTML，发现其中引用了很多其他文件，比如图片，CSS文件，JS文件。 \\3. 浏览器会自动再次发送Request去获取图片，CSS文件，或者JS文件。 \\4. 等所有的文件都下载成功后。 网页就被显示出来了。 Get和Post方法的区别Http协议定义了很多与服务器交互的方法，最基本的有4种，分别是GET,POST,PUT,DELETE. 一个URL地址用于描述一个网络上的资源，而HTTP中的GET, POST, PUT, DELETE就对应着对这个资源的查，改，增，删4个操作。 我们最常见的就是GET和POST了。GET一般用于获取/查询资源信息，而POST一般用于更新资源信息. 我们看看GET和POST的区别 \\1. GET提交的数据会放在URL之后，以?分割URL和传输数据，参数之间以&amp;相连，如EditPosts.aspx?name=test1&amp;id=123456. POST方法是把提交的数据放在HTTP包的Body中. \\2. GET提交的数据大小有限制（因为浏览器对URL的长度有限制），而POST方法提交的数据没有限制. \\3. GET方式需要使用Request.QueryString来取得变量的值，而POST方式通过Request.Form来获取变量的值。 \\4. GET方式提交数据，会带来安全问题，比如一个登录页面，通过GET方式提交数据时，用户名和密码将出现在URL上，如果页面可以被缓存或者其他人可以访问这台机器，就可以从历史记录获得该用户的账号和密码. 状态码Response 消息中的第一行叫做状态行，由HTTP协议版本号， 状态码， 状态消息 三部分组成。 状态码用来告诉HTTP客户端,HTTP服务器是否产生了预期的Response. HTTP/1.1中定义了5类状态码， 状态码由三位数字组成，第一个数字定义了响应的类别 1XX 提示信息 - 表示请求已被成功接收，继续处理 2XX 成功 - 表示请求已被成功接收，理解，接受 3XX 重定向 - 要完成请求必须进行更进一步的处理 4XX 客户端错误 - 请求有语法错误或请求无法实现 5XX 服务器端错误 - 服务器未能实现合法的请求 HTTP协议是无状态的和Connection: keep-alive的区别无状态是指协议对于事务处理没有记忆能力，服务器不知道客户端是什么状态。从另一方面讲，打开一个服务器上的网页和你之前打开这个服务器上的网页之间没有任何联系 HTTP是一个无状态的面向连接的协议，无状态不代表HTTP不能保持TCP连接，更不能代表HTTP使用的是UDP协议（无连接） 从HTTP/1.1起，默认都开启了Keep-Alive，保持连接特性，简单地说，当一个网页打开完成后，客户端和服务器之间用于传输HTTP数据的TCP连接不会关闭，如果客户端再次访问这个服务器上的网页，会继续使用这一条已经建立的连接 Keep-Alive不会永久保持连接，它有一个保持时间，可以在不同的服务器软件（如Apache）中设定这个时间 http和https的区别超文本传输协议HTTP协议被用于在Web浏览器和网站服务器之间传递信息，HTTP协议以明文方式发送内容，不提供任何方式的数据加密，如果攻击者截取了Web浏览器和网站服务器之间的传输报文，就可以直接读懂其中的信息，因此，HTTP协议不适合传输一些敏感信息，比如：信用卡号、密码等支付信息。为了解决HTTP协议的这一缺陷，需要使用另一种协议：安全套接字层超文本传输协议HTTPS，为了数据传输的安全，HTTPS在HTTP的基础上加入了SSL协议，SSL依靠证书来验证服务器的身份，并为浏览器和服务器之间的通信加密。 一、HTTP和HTTPS的基本概念HTTP：是互联网上应用最为广泛的一种网络协议，是一个客户端和服务器端请求和应答的标准（TCP），用于从WWW服务器传输超文本到本地浏览器的传输协议，它可以使浏览器更加高效，使网络传输减少。HTTPS：是以安全为目标的HTTP通道，简单讲是HTTP的安全版，即HTTP下加入SSL层，HTTPS的安全基础是SSL，因此加密的详细内容就需要SSL。HTTPS协议的主要作用可以分为两种：一种是建立一个信息安全通道，来保证数据传输的安全；另一种就是确认网站的真实性。 二、HTTP与HTTPS有什么区别？1、https协议需要到ca申请证书，一般免费证书较少，因而需要一定费用。 2、http是超文本传输协议，信息是明文传输，https则是具有安全性的ssl加密传输协议。 3、http和https使用的是完全不同的连接方式，用的端口也不一样，前者是80，后者是443。 4、http的连接很简单，是无状态的；HTTPS协议是由SSL+HTTP协议构建的可进行加密传输、身份认证的网络协议，比http协议安全。 三、HTTPS的工作原理我们都知道HTTPS能够加密信息，以免敏感信息被第三方获取，所以很多银行网站或电子邮箱等等安全级别较高的服务都会采用HTTPS协议。 1、客户端发起HTTPS请求这个没什么好说的，就是用户在浏览器里输入一个https网址，然后连接到server的443端口。 2、服务端的配置采用HTTPS协议的服务器必须要有一套数字证书，可以自己制作，也可以向组织申请，区别就是自己颁发的证书需要客户端验证通过，才可以继续访问，而使用受信任的公司申请的证书则不会弹出提示页面(startssl就是个不错的选择，有1年的免费服务)。这套证书其实就是一对公钥和私钥，如果对公钥和私钥不太理解，可以想象成一把钥匙和一个锁头，只是全世界只有你一个人有这把钥匙，你可以把锁头给别人，别人可以用这个锁把重要的东西锁起来，然后发给你，因为只有你一个人有这把钥匙，所以只有你才能看到被这把锁锁起来的东西。 3、传送证书这个证书其实就是公钥，只是包含了很多信息，如证书的颁发机构，过期时间等等。 4、客户端解析证书这部分工作是有客户端的TLS来完成的，首先会验证公钥是否有效，比如颁发机构，过期时间等等，如果发现异常，则会弹出一个警告框，提示证书存在问题。如果证书没有问题，那么就生成一个随机值，然后用证书对该随机值进行加密，就好像上面说的，把随机值用锁头锁起来，这样除非有钥匙，不然看不到被锁住的内容。 5、传送加密信息这部分传送的是用证书加密后的随机值，目的就是让服务端得到这个随机值，以后客户端和服务端的通信就可以通过这个随机值来进行加密解密了。 6、服务段解密信息服务端用私钥解密后，得到了客户端传过来的随机值(私钥)，然后把内容通过该值进行对称加密，所谓对称加密就是，将信息和私钥通过某种算法混合在一起，这样除非知道私钥，不然无法获取内容，而正好客户端和服务端都知道这个私钥，所以只要加密算法够彪悍，私钥够复杂，数据就够安全。 7、传输加密后的信息这部分信息是服务段用私钥加密后的信息，可以在客户端被还原。 8、客户端解密信息客户端用之前生成的私钥解密服务段传过来的信息，于是获取了解密后的内容，整个过程第三方即使监听到了数据，也束手无策。 HTTP1.0 HTTP 1.1主要区别长连接HTTP 1.0需要使用keep-alive参数来告知服务器端要建立一个长连接，而HTTP1.1默认支持长连接。HTTP是基于TCP/IP协议的，创建一个TCP连接是需要经过三次握手的,有一定的开销，如果每次通讯都要重新建立连接的话，对性能有影响。因此最好能维持一个长连接，可以用个长连接来发多个请求。 节约带宽HTTP 1.1支持只发送header信息(不带任何body信息)，如果服务器认为客户端有权限请求服务器，则返回100，否则返回401。客户端如果接受到100，才开始把请求body发送到服务器。这样当服务器返回401的时候，客户端就可以不用发送请求body了，节约了带宽。另外HTTP还支持传送内容的一部分。这样当客户端已经有一部分的资源后，只需要跟服务器请求另外的部分资源即可。这是支持文件断点续传的基础。 HOST域现在可以web server例如tomat，设置虚拟站点是非常常见的，也即是说，web server上的多个虚拟站点可以共享同一个ip和端口。HTTP1.0是没有host域的，HTTP1.1才支持这个参数。 HTTP1.1 HTTP 2.0主要区别多路复用HTTP2.0使用了多路复用的技术，做到同一个连接并发处理多个请求，而且并发请求的数量比HTTP1.1大了好几个数量级。当然HTTP1.1也可以多建立几个TCP连接，来支持处理更多并发的请求，但是创建TCP连接本身也是有开销的。TCP连接有一个预热和保护的过程，先检查数据是否传送成功，一旦成功过，则慢慢加大传输速度。因此对应瞬时并发的连接，服务器的响应就会变慢。所以最好能使用一个建立好的连接，并且这个连接可以支持瞬时并发的请求。 数据压缩HTTP1.1不支持header数据的压缩，HTTP2.0使用HPACK算法对header的数据进行压缩，这样数据体积小了，在网络上传输就会更快。 服务器推送意思是说，当我们对支持HTTP2.0的web server请求数据的时候，服务器会顺便把一些客户端需要的资源一起推送到客户端，免得客户端再次创建连接发送请求到服务器端获取。这种方式非常合适加载静态资源。服务器端推送的这些资源其实存在客户端的某处地方，客户端直接从本地加载这些资源就可以了，不用走网络，速度自然是快很多的。 cookie 和session 的区别 cookie 是一种发送到客户浏览器的文本串句柄，并保存在客户机硬盘上，可以用来在某个WEB站点会话间持久的保持数据。 session其实指的就是访问者从到达某个特定主页到离开为止的那段时间。 Session其实是利用Cookie进行信息处理的，当用户首先进行了请求后，服务端就在用户浏览器上创建了一个Cookie，当这个Session结束时，其实就是意味着这个Cookie就过期了。注：为这个用户创建的Cookie的名称是aspsessionid。这个Cookie的唯一目的就是为每一个用户提供不同的身份认证。 cookie和session的共同之处在于：cookie和session都是用来跟踪浏览器用户身份的会话方式。 cookie 和session的区别是：cookie数据保存在客户端，session数据保存在服务器端。 如果web服务器端使用的是session，那么所有的数据都保存在服务器上，客户端每次请求服务器的时候会发送当前会话的sessionid，服务器根据当前sessionid判断相应的用户数据标志，以确定用户是否登录或具有某种权限。由于数据是存储在服务器上面，所以你不能伪造，但是如果你能够获取某个登录用户的 sessionid，用特殊的浏览器伪造该用户的请求也是能够成功的。sessionid是服务器和客户端链接时候随机分配的，一般来说是不会有重复，但如果有大量的并发请求，也不是没有重复的可能性. 如果浏览器使用的是cookie，那么所有的数据都保存在浏览器端，比如你登录以后，服务器设置了cookie用户名，那么当你再次请求服务器的时候，浏览器会将用户名一块发送给服务器，这些变量有一定的特殊标记。服务器会解释为cookie变量，所以只要不关闭浏览器，那么cookie变量一直是有效的，所以能够保证长时间不掉线。如果你能够截获某个用户的 cookie变量，然后伪造一个数据包发送过去，那么服务器还是认为你是合法的。所以，使用 cookie被攻击的可能性比较大。如果设置了的有效时间，那么它会将 cookie保存在客户端的硬盘上，下次再访问该网站的时候，浏览器先检查有没有 cookie，如果有的话，就读取该 cookie，然后发送给服务器。如果你在机器上面保存了某个论坛 cookie，有效期是一年，如果有人入侵你的机器，将你的 cookie拷走，然后放在他的浏览器的目录下面，那么他登录该网站的时候就是用你的的身份登录的。所以 cookie是可以伪造的。当然，伪造的时候需要主意，直接copy cookie文件到 cookie目录，浏览器是不认的，他有一个index.dat文件，存储了 cookie文件的建立时间，以及是否有修改，所以你必须先要有该网站的 cookie文件，并且要从保证时间上骗过浏览器 1、cookie数据存放在客户的浏览器上，session数据放在服务器上。 2、cookie不是很安全，别人可以分析存放在本地的COOKIE并进行COOKIE欺骗 考虑到安全应当使用session。 3、session会在一定时间内保存在服务器上。当访问增多，会比较占用你服务器的性能 考虑到减轻服务器性能方面，应当使用COOKIE。 4、单个cookie保存的数据不能超过4K，很多浏览器都限制一个站点最多保存20个cookie。5、所以个人建议： 将登陆信息等重要信息存放为SESSION 其他信息如果需要保留，可以放在COOKIE中","categories":[{"name":"HTTP","slug":"HTTP","permalink":"https://originer.github.io/Horizon.github.io/categories/HTTP/"}],"tags":[{"name":"HTTP","slug":"HTTP","permalink":"https://originer.github.io/Horizon.github.io/tags/HTTP/"}]},{"title":"Java并发核心-AQS","slug":"AQS基础","date":"2018-11-15T06:10:23.000Z","updated":"2018-11-15T06:10:23.000Z","comments":true,"path":"2018/11/15/AQS基础/","link":"","permalink":"https://originer.github.io/Horizon.github.io/2018/11/15/AQS基础/","excerpt":"Java并发包（JUC）中提供了很多并发工具，这其中，很多我们耳熟能详的并发工具，譬如ReentrangLock、Semaphore，它们的实现都用到了一个共同的基类–AbstractQueuedSynchronizer,简称AQS。AQS是一个用来构建锁和同步器的框架，使用AQS能简单且高效地构造出应用广泛的大量的同步器，比如我们提到的ReentrantLock，Semaphore，其他的诸如ReentrantReadWriteLock，SynchronousQueue，FutureTask等等皆是基于AQS的。当然，我们自己也能利用AQS非常轻松容易地构造出符合我们自己需求的同步器。","text":"Java并发包（JUC）中提供了很多并发工具，这其中，很多我们耳熟能详的并发工具，譬如ReentrangLock、Semaphore，它们的实现都用到了一个共同的基类–AbstractQueuedSynchronizer,简称AQS。AQS是一个用来构建锁和同步器的框架，使用AQS能简单且高效地构造出应用广泛的大量的同步器，比如我们提到的ReentrantLock，Semaphore，其他的诸如ReentrantReadWriteLock，SynchronousQueue，FutureTask等等皆是基于AQS的。当然，我们自己也能利用AQS非常轻松容易地构造出符合我们自己需求的同步器。 AQS实现原理 AQS的底层是使用一个int变量表示同步状态，有一个内置的FIFO的队列用来完成获取资源线程的排队工作。 1234/** * The synchronization state. */private volatile int state; state可以通过以下的方式进行操作： 1234567891011protected final boolean compareAndSetState(int expect, int update) &#123; // See below for intrinsics setup to support this return unsafe.compareAndSwapInt(this, stateOffset, expect, update);&#125;protected final void setState(int newState) &#123; state = newState;&#125;protected final int getState() &#123; return state;&#125; 内置队列AQS中会维护一个内置队列，这是队列的结点类： 1234567891011121314151617181920static final class Node &#123; /** waitStatus值，表示线程已被取消（等待超时或者被中断）*/ static final int CANCELLED = 1; /** waitStatus值，表示后继线程需要被唤醒（unpaking）*/ static final int SIGNAL = -1; /**waitStatus值，表示结点线程等待在condition上，当被signal后，会从等待队列转移到同步到队列中 */ /** waitStatus value to indicate thread is waiting on condition */ static final int CONDITION = -2; /** waitStatus值，表示下一次共享式同步状态会被无条件地传播下去 static final int PROPAGATE = -3; /** 等待状态，初始为0 */ volatile int waitStatus; /**当前结点的前驱结点 */ volatile Node prev; /** 当前结点的后继结点 */ volatile Node next; /** 与当前结点关联的排队中的线程 */ volatile Thread thread; /** ...... */ &#125; 添加结点123private Node addWaiter(Node mode) &#123; //以给定模式构造结点。mode有两种：EXCLUSIVE（独占）和SHARED（共享） Node node = new Node(Thread.currentThread(), mode); 12345678910111213141516171819202122232425262728293031//尝试快速方式直接放到队尾。Node pred = tail;if (pred != null) &#123; node.prev = pred; if (compareAndSetTail(pred, node)) &#123; pred.next = node; return node; &#125;&#125;//上一步失败则通过enq入队。enq(node);return node;｝private Node enq(final Node node) &#123; //CAS\"自旋\"，直到成功加入队尾 for (;;) &#123; Node t = tail; if (t == null) &#123; // 队列为空，创建一个空的标志结点作为head结点，并将tail也指向它。 if (compareAndSetHead(new Node())) tail = head; &#125; else &#123;//正常流程，放入队尾 node.prev = t; if (compareAndSetTail(t, node)) &#123; t.next = node; return t; &#125; &#125; &#125;&#125; 同步方式 protected boolean tryAcquire(int arg) : 独占式获取同步状态，试着获取，成功返回true，反之为false protected boolean tryRelease(int arg) ：独占式释放同步状态，等待中的其他线程此时将有机会获取到同步状态； protected int tryAcquireShared(int arg) ：共享式获取同步状态，返回值大于等于0，代表获取成功；反之获取失败； protected boolean tryReleaseShared(int arg) ：共享式释放同步状态，成功为true，失败为false protected boolean isHeldExclusively() ： 是否在独占模式下被线程占用。 共享式共享式锁的实现有：Semaphore，CountDownLatch上面的方法都是没有默认实现的，需要自己实现。可以以CountDownLatch为例看一下如何自定义一个同步锁： 12345678910111213141516171819202122232425262728293031/** * Synchronization control For CountDownLatch. * Uses AQS state to represent count. */private static final class Sync extends AbstractQueuedSynchronizer &#123; private static final long serialVersionUID = 4982264981922014374L; //在这里初始化state进行上锁 Sync(int count) &#123; setState(count); &#125; int getCount() &#123; return getState(); &#125; protected int tryAcquireShared(int acquires) &#123; return (getState() == 0) ? 1 : -1; &#125; //共享锁是可重入的，这里是对state-1，代表释放锁 protected boolean tryReleaseShared(int releases) &#123; // Decrement count; signal when transition to zero for (;;) &#123; int c = getState(); if (c == 0) return false; int nextc = c-1; if (compareAndSetState(c, nextc)) return nextc == 0; &#125; &#125;&#125; 独占式独占式的实现有：ReentrantLock 下面是ReentrantLock中自定义的独占式锁： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546abstract static class Sync extends AbstractQueuedSynchronizer &#123; private static final long serialVersionUID = -5179523762034025860L; /** * 这个方法是抽象的，实现在NonfairSync和FairSync中。调用这个方法时会代理给acquirer()方法 */ abstract void lock(); //这里acquires=1是写死的 final boolean nonfairTryAcquire(int acquires) &#123; final Thread current = Thread.currentThread(); int c = getState(); if (c == 0) &#123; //采用CAS机制更新state if (compareAndSetState(0, acquires)) &#123; //把当前线程设置为独占线程 setExclusiveOwnerThread(current); return true; &#125; &#125; //判断请求锁的线程是不是独占的线程，这里可以看出这个锁是可以重入的 else if (current == getExclusiveOwnerThread()) &#123; int nextc = c + acquires; if (nextc &lt; 0) // overflow throw new Error(\"Maximum lock count exceeded\"); setState(nextc); return true; &#125; return false; &#125; protected final boolean tryRelease(int releases) &#123; int c = getState() - releases; if (Thread.currentThread() != getExclusiveOwnerThread()) throw new IllegalMonitorStateException(); boolean free = false; if (c == 0) &#123; free = true; setExclusiveOwnerThread(null); &#125; setState(c); return free; &#125; ...&#125; 公平锁与非公平锁的实现： 123456789101112131415161718192021222324252627282930313233343536373839404142434445 static final class NonfairSync extends Sync &#123; private static final long serialVersionUID = 7316153563782823691L; //直接利用CAS进行上锁，如果失败了就交给acquire处理 final void lock() &#123; if (compareAndSetState(0, 1)) setExclusiveOwnerThread(Thread.currentThread()); else acquire(1); &#125; protected final boolean tryAcquire(int acquires) &#123; return nonfairTryAcquire(acquires); &#125; &#125;static final class FairSync extends Sync &#123; private static final long serialVersionUID = -3000897897090466540L; final void lock() &#123; acquire(1); &#125; //公平锁与非公平锁的区别就是非公平锁在state=0，也就是没上锁时，会优先从队列头部取出一个等待的线程获取锁 //只有队列为空才会进行CAS更新 //非公平锁是可重入的，如果请求上锁的线程与锁定的线程是同一个，就把state累加 protected final boolean tryAcquire(int acquires) &#123; final Thread current = Thread.currentThread(); int c = getState(); if (c == 0) &#123; if (!hasQueuedPredecessors() &amp;&amp; compareAndSetState(0, acquires)) &#123; setExclusiveOwnerThread(current); return true; &#125; &#125; else if (current == getExclusiveOwnerThread()) &#123; int nextc = c + acquires; if (nextc &lt; 0) throw new Error(\"Maximum lock count exceeded\"); setState(nextc); return true; &#125; return false; &#125;&#125; 从上面代码可以看出，上锁操作都代理给了acquire方法，下面分析一下这个方法： 1234567891011//acquire方法在AQS类中，首先会进行tryAcquire方法，而tryAcquire是由AQS的子类实现的，也就是绕了一圈//调用的其实还是 FairSync、NonfairSync类中的方法//调用过程 :// [ReentrantLock]lock-&gt;[ReentrantLock.Sync]lock-&gt;[Sync.FairSync]acquire-&gt;// [AQS]tryAcquire-&gt;[Sync.FairSync]tryAcquire//如果获取锁失败了，就把线程加到队列中public final void acquire(int arg) &#123; if (!tryAcquire(arg) &amp;&amp; acquireQueued(addWaiter(Node.EXCLUSIVE), arg)) selfInterrupt();&#125;","categories":[{"name":"Java并发编程","slug":"Java并发编程","permalink":"https://originer.github.io/Horizon.github.io/categories/Java并发编程/"}],"tags":[]},{"title":"SpringCloud学习","slug":"SpringCloud学习","date":"2018-11-12T07:30:21.000Z","updated":"2019-02-20T02:35:53.617Z","comments":true,"path":"2018/11/12/SpringCloud学习/","link":"","permalink":"https://originer.github.io/Horizon.github.io/2018/11/12/SpringCloud学习/","excerpt":"","text":"个人理解SpringClound是以SpringBoot为骨架，整合了注册中心网关负载均衡RPC等功能的分布式框架。 eureka 服务注册中心 ribbon 负载均衡 feign 声明式的http客户端 Hystrix 断路器，服务调用失败时快速响应失败 zuul网关 可以做一些服务转发路由，并且可以做一些过滤和安全校验","categories":[{"name":"SpringClound","slug":"SpringClound","permalink":"https://originer.github.io/Horizon.github.io/categories/SpringClound/"}],"tags":[{"name":"SpringClound","slug":"SpringClound","permalink":"https://originer.github.io/Horizon.github.io/tags/SpringClound/"}]},{"title":"ThreadLocal源码研究","slug":"ThreadLocal源码研究","date":"2018-11-12T03:00:13.000Z","updated":"2018-12-02T06:35:06.111Z","comments":true,"path":"2018/11/12/ThreadLocal源码研究/","link":"","permalink":"https://originer.github.io/Horizon.github.io/2018/11/12/ThreadLocal源码研究/","excerpt":"ThreadLocal 是并发编程中经常用到的一个工具类，但是之前对这个类并不是很熟悉，只是觉得很高端。今天在群里看到有人讨论，索性研究一下源码以彻底掌握这个东西 ThreadLocal 是什么早在JDK 1.2的版本中就提供java.lang.ThreadLocal，ThreadLocal为解决多线程程序的并发问题提供了一种新的思路。使用这个工具类可以很简洁地编写出优美的多线程程序。","text":"ThreadLocal 是并发编程中经常用到的一个工具类，但是之前对这个类并不是很熟悉，只是觉得很高端。今天在群里看到有人讨论，索性研究一下源码以彻底掌握这个东西 ThreadLocal 是什么早在JDK 1.2的版本中就提供java.lang.ThreadLocal，ThreadLocal为解决多线程程序的并发问题提供了一种新的思路。使用这个工具类可以很简洁地编写出优美的多线程程序。 ThreadLocal很容易让人望文生义，想当然地认为是一个“本地线程”。其实，ThreadLocal并不是一个Thread，而是Thread的局部变量，也许把它命名为ThreadLocalVariable更容易让人理解一些。 当使用ThreadLocal维护变量时，ThreadLocal为每个使用该变量的线程提供独立的变量副本，所以每一个线程都可以独立地改变自己的副本，而不会影响其它线程所对应的副本。 从线程的角度看，目标变量就象是线程的本地变量，这也是类名中“Local”所要表达的意思。 线程局部变量并不是Java的新发明，很多语言（如IBM IBM XL FORTRAN）在语法层面就提供线程局部变量。在Java中没有提供在语言级支持，而是变相地通过ThreadLocal的类提供支持。 所以，在Java中编写线程局部变量的代码相对来说要笨拙一些，因此造成线程局部变量没有在Java开发者中得到很好的普及。 ThreadLocal 源码分析ThreadLocal 接口方法1234public T get() &#123; &#125; public void set(T value) &#123; &#125; public void remove() &#123; &#125; protected T initialValue() &#123; &#125; 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122public class ThreadLocal&lt;T&gt; &#123; /**ThreadLocals rely on per-thread linear-probe hash maps attached to each thread (Thread.threadLocals and inheritableThreadLocals). The ThreadLocal objects act as keys, searched via threadLocalHashCode. */ //每个线程对应一个基于线性探测的哈希表（ThreadLocalMap类型），通过Thread类的threadLocals属性关联。 //在该哈希表中，逻辑上key为ThreadLocal，实质上通过threadLocalHashCode属性作为哈希值查找。 private final int threadLocalHashCode = nextHashCode(); /** The next hash code to be given out. Updated atomically. Starts at zero.*/ private static AtomicInteger nextHashCode = new AtomicInteger(); private static final int HASH_INCREMENT = 0x61c88647; /**Returns the next hash code.*/ private static int nextHashCode() &#123; return nextHashCode.getAndAdd(HASH_INCREMENT); &#125; /**Returns the current thread's \"initial value\" for this thread-local variable. This method will be invoked the first time a thread accesses the variable with the &#123;@link #get&#125; method, unless the thread previously invoked the &#123;@link #set&#125; method, in which case the &lt;tt&gt;initialValue&lt;/tt&gt; method will not be invoked for the thread. Normally, this method is invoked at most once per thread, but it may be invoked again in case of subsequent invocations of &#123;@link #remove&#125; followed by &#123;@link #get&#125;. &lt;p&gt;This implementation simply returns &lt;tt&gt;null&lt;/tt&gt;; if the programmer desires thread-local variables to have an initial value other than &lt;tt&gt;null&lt;/tt&gt;, &lt;tt&gt;ThreadLocal&lt;/tt&gt; must be subclassed, and this method overridden. Typically, an anonymous inner class will be used. * @return the initial value for this thread-local */ //初始化线程本地变量，注意上面讲到的关于该方法的正确理解 protected T initialValue() &#123; return null; &#125; /** Creates a thread local variable.*/ public ThreadLocal() &#123; &#125; /**Returns the value in the current thread's copy of this thread-local variable. If the variable has no value for the current thread, it is first initialized to the value returned by an invocation of the &#123;@link #initialValue&#125; method. * @return the current thread's value of this thread-local */ public T get() &#123; Thread t = Thread.currentThread();//获取当前线程对象 ThreadLocalMap map = getMap(t);//获取当前线程对象关联的ThreadLocalMap if (map != null) &#123; ThreadLocalMap.Entry e = map.getEntry(this);//以this作为key，查找线程本地变量 if (e != null)//如果该线程本地变量已经存在，返回即可 return (T)e.value; &#125; return setInitialValue();//如果该线程本地变量不存在，设置初始值并返回 &#125; /**Variant of set() to establish initialValue. Used instead of set() in case user has overridden the set() method. * @return the initial value */ private T setInitialValue() &#123; T value = initialValue();//获取线程本地变量的初始值 Thread t = Thread.currentThread(); ThreadLocalMap map = getMap(t); if (map != null)//如果当前线程关联的ThreadLocalMap已经存在，将线程本地变量插入哈希表 map.set(this, value); else createMap(t, value);//否则，创建新的ThreadLocalMap并将&lt;this,value&gt;组成的键值对加入到ThreadLocalMap中 return value; &#125; /**Sets the current thread's copy of this thread-local variableto the specified value. Most subclasses will have no need to override this method, relying solely on the &#123;@link #initialValue&#125; * method to set the values of thread-locals. * * @param value the value to be stored in the current thread's copy of this thread-local. */ public void set(T value) &#123; Thread t = Thread.currentThread(); ThreadLocalMap map = getMap(t);//获取当前线程的ThreadLocalMap if (map != null) map.set(this, value); else createMap(t, value); &#125; /**Removes the current thread's value for this thread-local variable. If this thread-local variable is subsequently &#123;@linkplain #get read&#125; by the current thread, its value will be reinitialized by invoking its &#123;@link #initialValue&#125; method, unless its value is &#123;@linkplain #set set&#125; by the current thread in the interim. This may result in multiple invocations of the &lt;tt&gt;initialValue&lt;/tt&gt; method in the current thread. * * @since 1.5 */ public void remove() &#123;//从当前线程的ThreadLocalMap中移除线程本地变量 ThreadLocalMap m = getMap(Thread.currentThread()); if (m != null) m.remove(this); &#125; /** Get the map associated with a ThreadLocal. Overridden in InheritableThreadLocal.*/ ThreadLocalMap getMap(Thread t) &#123; return t.threadLocals; &#125; /**Create the map associated with a ThreadLocal. Overridden in InheritableThreadLocal.*/ //创建ThreadLocalMap后与当前线程关联，并将线程本地变量插入ThreadLocalMap void createMap(Thread t, T firstValue) &#123; t.threadLocals = new ThreadLocalMap(this, firstValue); &#125; //其他 static ThreadLocalMap createInheritedMap(ThreadLocalMap parentMap) &#123; return new ThreadLocalMap(parentMap); &#125; T childValue(T parentValue) &#123; throw new UnsupportedOperationException(); &#125; static class ThreadLocalMap &#123;//基于线性探测解决冲突的哈希映射表 ...... &#125;......&#125; ThreadLocal 存储结构 从图中可以看出，ThreadLocal的内存存储结构类似一个HashMap的ThreadLocalMap，用Entry数组来存储键值对，key是ThreadLocal对象，value则是具体的值。值得一提的是，为了方便GC，Entry继承了WeakReference，也就是弱引用。 强引用 软引用：可被回收。GC 不一定会回收，但内存紧张就会被回收，不会导致OOM。 弱引用：发现就回收，不管空间够不够。 虚引用：对象回收跟踪，必须和引用队列一起使用，作业在于跟踪垃圾回收过程。 ThreadLocal 实例12345678910111213141516171819202122232425public class ThreadLocalExample1 &#123; public static final ThreadLocal&lt;String&gt; threadLocal = new ThreadLocal&lt;&gt;(); public static void main(String[] args) throws InterruptedException &#123; ExecutorService executor = Executors.newFixedThreadPool(3); for (int i = 0; i &lt; 3; i++) &#123; executor.submit(() -&gt; &#123; System.out.println(Thread.currentThread().getName() + \" 设置值为：\" + Thread.currentThread().getName()); threadLocal.set(Thread.currentThread().getName()); &#125;); &#125; TimeUnit.SECONDS.sleep(2); for (int i = 0; i &lt; 3; i++) &#123; executor.submit(() -&gt; &#123; System.out.println(Thread.currentThread().getName() + \"获得值:\" + threadLocal.get()); &#125;); &#125; executor.shutdown(); System.out.println(threadLocal.get()); &#125;&#125; pool-1-thread-1 设置值为：pool-1-thread-1pool-1-thread-2 设置值为：pool-1-thread-2pool-1-thread-3 设置值为：pool-1-thread-3pool-1-thread-3获得值:pool-1-thread-3pool-1-thread-1获得值:pool-1-thread-1pool-1-thread-2获得值:pool-1-thread-2null ThreadLocal是一个线程独占的变量，不会受其他线程的影响。例如上面的例子，每个线程单独设置的值不会影响到别的线程，由于主线程没有设置值，所以返回为null； 我们可以重写ThreadLocal的初始化方法，在没有设置值时返回我们想要的默认值： 1public static final ThreadLocal&lt;String&gt; threadLocal = ThreadLocal.withInitial(() -&gt; \"初始值\"); 内存泄露与WeakReference1234567891011121314151617181920212223242526272829303132333435363738394041424344/** * ThreadLocal 内存泄漏 * @author Zz **/public class ThreadLocalExample2 &#123; public static class MyThreadLocal extends ThreadLocal &#123; private byte[] a = new byte[1024*1024*1]; @Override public void finalize() &#123; System.out.println(\"My threadlocal 1 MB finalized.\"); &#125; &#125; public static class My50MB &#123;//占用内存的大对象 private byte[] a = new byte[1024*1024*50]; @Override public void finalize() &#123; System.out.println(\"My 50 MB finalized.\"); &#125; &#125; public static void main(String[] args) throws InterruptedException &#123; new Thread(() -&gt; &#123; ThreadLocal tl = new MyThreadLocal(); tl.set(new My50MB()); tl=null;//断开ThreadLocal的强引用 System.out.println(\"Full GC 1\"); System.gc(); &#125;).start(); System.out.println(\"Full GC 2\"); System.gc(); Thread.sleep(1000); System.out.println(\"Full GC 3\"); System.gc(); Thread.sleep(1000); System.out.println(\"Full GC 4\"); System.gc(); Thread.sleep(1000); &#125;&#125; Full GC 2Full GC 1My threadlocal 1 MB finalized.Full GC 3My 50 MB finalized.Full GC 4 从输出可以看出，一旦threadLocal的强引用断开，key的内存就可以得到释放。只有当线程结束后，value的内存才释放。每个thread中都存在一个map， map的类型是ThreadLocal.ThreadLocalMap。Map中的key为一个threadlocal实例。这个Map的确使用了弱引用，不过弱引用只是针对key。每个key都弱引用指向threadlocal。当把threadlocal实例置为null以后，没有任何强引用指threadlocal实例，所以threadlocal将会被gc回收。但是，我们的value却不能回收，因为存在一条从current thread连接过来的强引用。只有当前thread结束以后, current thread就不会存在栈中,强引用断开, Current Thread, Map, value将全部被GC回收. 简单来说就是，如果线程没有被销毁，value就不会被回收。所以在使用线程池的情况下线程不会被销毁，就有可能出现内存泄漏； ThreadLocal的实现是这样的：每个Thread 维护一个 ThreadLocalMap 映射表，这个映射表的 key 是 ThreadLocal实例本身，value 是真正需要存储的 Object。也就是说 ThreadLocal 本身并不存储值，它只是作为一个 key 来让线程从 ThreadLocalMap 获取 value。值得注意的是图中的虚线，表示 ThreadLocalMap 是使用 ThreadLocal 的弱引用作为 Key 的，弱引用的对象在 GC 时会被回收。 ThreadLocalMap使用ThreadLocal的弱引用作为key，如果一个ThreadLocal没有外部强引用来引用它，那么系统 GC 的时候，这个ThreadLocal势必会被回收，这样一来，ThreadLocalMap中就会出现key为null的Entry，就没有办法访问这些key为null的Entry的value，如果当前线程再迟迟不结束的话，这些key为null的Entry的value就会一直存在一条强引用链：Thread Ref -&gt; Thread -&gt; ThreaLocalMap -&gt; Entry -&gt; value永远无法回收，造成内存泄漏。 比较两种情况，我们可以发现：由于ThreadLocalMap的生命周期跟Thread一样长，如果都没有手动删除对应key，都会导致内存泄漏，但是使用弱引用可以多一层保障：弱引用ThreadLocal不会内存泄漏，对应的value在下一次ThreadLocalMap调用set,get,remove的时候会被清除。 因此，ThreadLocal内存泄漏的根源是：由于ThreadLocalMap的生命周期跟Thread一样长，如果没有手动删除对应key就会导致内存泄漏，而不是因为弱引用。 为什么使用弱引用 key 使用强引用：引用的ThreadLocal的对象被回收了，但是ThreadLocalMap还持有ThreadLocal的强引用，如果没有手动删除，ThreadLocal不会被回收，导致Entry内存泄漏。 key 使用弱引用：引用的ThreadLocal的对象被回收了，由于ThreadLocalMap持有ThreadLocal的弱引用，即使没有手动删除，ThreadLocal也会被回收。value在下一次ThreadLocalMap调用set,get，remove的时候会被清除。 比较两种情况，我们可以发现：由于ThreadLocalMap的生命周期跟Thread一样长，如果都没有手动删除对应key，都会导致内存泄漏，但是使用弱引用可以多一层保障：弱引用ThreadLocal不会内存泄漏，对应的value在下一次ThreadLocalMap调用set,get,remove的时候会被清除。 因此，ThreadLocal内存泄漏的根源是：由于ThreadLocalMap的生命周期跟Thread一样长，如果没有手动删除对应key就会导致内存泄漏，而不是因为弱引用。 ThreadLocal 最佳实践综合上面的分析，我们可以理解ThreadLocal内存泄漏的前因后果，那么怎么避免内存泄漏呢？ 每次使用完ThreadLocal，都调用它的remove()方法，清除数据。 在使用线程池的情况下，没有及时清理ThreadLocal，不仅是内存泄漏的问题，更严重的是可能导致业务逻辑出现问题。所以，使用ThreadLocal就跟加锁完要解锁一样，用完就清理。 ThreadLocal 与同步机制的区别ThreadLocal和线程同步机制相比有什么优势呢？ThreadLocal和线程同步机制都是为了解决多线程中相同变量的访问冲突问题。 在同步机制中，通过对象的锁机制保证同一时间只有一个线程访问变量。这时该变量是多个线程共享的，使用同步机制要求程序慎密地分析什么时候对变量进行读写，什么时候需要锁定某个对象，什么时候释放对象锁等繁杂的问题，程序设计和编写难度相对较大。 而ThreadLocal则从另一个角度来解决多线程的并发访问。ThreadLocal会为每一个线程提供一个独立的变量副本，从而隔离了多个线程对数据的访问冲突。因为每一个线程都拥有自己的变量副本，从而也就没有必要对该变量进行同步了。ThreadLocal提供了线程安全的共享对象，在编写多线程代码时，可以把不安全的变量封装进ThreadLocal。 由于ThreadLocal中可以持有任何类型的对象，低版本JDK所提供的get()返回的是Object对象，需要强制类型转换。但JDK 5.0通过泛型很好的解决了这个问题，在一定程度地简化ThreadLocal的使用，代码清单一就使用了JDK 5.0新的ThreadLocal版本。 FastThreadLocal我们知道ThreadLocal的底层和HashMap一样，是一个链表结构。这样在数据量多了以后get()方法的效率就会变低。Netty提供了一种号称效率更高的FastThreadLocal，FastThreadLocal并不继承自ThreadLocal，是Netty模仿ThreadLocal API单独实现的一个类。底层使用了数组结构，每个FastThreadLocal都会维护一套索引，这样无论数据量多少，get()的效率都是O(1)。 源码研究创建过程1234public FastThreadLocal() &#123; index = InternalThreadLocalMap.nextVariableIndex(); //访问数组的索引 cleanerFlagIndex = InternalThreadLocalMap.nextVariableIndex(); //是否放入清除队列标志的索引&#125; 可以看出，FastThreadLocal维护了两个索引，每次创建FastThreadLocal这个索引值都会原子递增。即在JVM中每个FastThreadLocal都有唯一的一个标记。 总结通过对ThreadLocal源码的分析，可以发现ThreadLocal的数据是存在一个类似HashMap的ThreadLocalMap的数据结构中。但是ThreadLocalMap本身并不是ThreadLocal的内部对象，而是保存在Thread类中。这样很巧妙的避开了多线程同步的问题，从而实现了线程局部变量。 补充：Netty提供了一种号称效率更高的FastThreadLocal，后续会补充。 1）线程对象直接提供 set、get方法，以便直接获取线程本地存储相关的变量属性。 2）将数据存储基于数组存储。","categories":[],"tags":[{"name":"Java并发编程","slug":"Java并发编程","permalink":"https://originer.github.io/Horizon.github.io/tags/Java并发编程/"}]},{"title":"ConcurrentHashMap源码研究","slug":"ConcurrentHashMap源码研究","date":"2018-11-09T08:39:45.000Z","updated":"2018-11-09T08:39:45.000Z","comments":true,"path":"2018/11/09/ConcurrentHashMap源码研究/","link":"","permalink":"https://originer.github.io/Horizon.github.io/2018/11/09/ConcurrentHashMap源码研究/","excerpt":"HashMap是我们平时开发过程中用的比较多的集合，但它是非线程安全的，在涉及到多线程并发的情况，进行put操作有可能会引起死循环，导致CPU利用率接近100%。 ConcurrentHashMap就是一个线程安全版的HashMap，但是这个类和HashMap都在JDK8发生了较大的变化。在这里分析一下源码，来了解一下JDK8下CuncurrentHashMap是如何保证线程安全的。ConcurrentHashMap不支持key或value为null。 HashTable也是一个线程安全Map，且不能存储Null值。它的操作方法和HashMap很类似，但是所有操作都加上synchronized，而且是将整个HashTable对象加锁，也就是同时只能有一个线程访问、修改HashTable。这样带来的问题就是在多线程环境中代价大、效率低。","text":"HashMap是我们平时开发过程中用的比较多的集合，但它是非线程安全的，在涉及到多线程并发的情况，进行put操作有可能会引起死循环，导致CPU利用率接近100%。 ConcurrentHashMap就是一个线程安全版的HashMap，但是这个类和HashMap都在JDK8发生了较大的变化。在这里分析一下源码，来了解一下JDK8下CuncurrentHashMap是如何保证线程安全的。ConcurrentHashMap不支持key或value为null。 HashTable也是一个线程安全Map，且不能存储Null值。它的操作方法和HashMap很类似，但是所有操作都加上synchronized，而且是将整个HashTable对象加锁，也就是同时只能有一个线程访问、修改HashTable。这样带来的问题就是在多线程环境中代价大、效率低。 JDK6 的实现 ConcurrentHashMap引入了Segement数据结构 Segement12345static class Segment&lt;K,V&gt; extends ReentrantLock implements Serializable &#123; private static final long serialVersionUID = 2249069246763182397L; final float loadFactor; Segment(float lf) &#123; this.loadFactor = lf; &#125;&#125; 数据节点12345678910111213static final class HashEntry&lt;K,V&gt; &#123; final K key; final int hash; volatile V value; final HashEntry&lt;K,V&gt; next; HashEntry(K key, int hash, HashEntry&lt;K,V&gt; next, V value) &#123; this.key = key; this.hash = hash; this.next = next; this.value = value; &#125;&#125; 构造函数12345678910111213141516171819202122232425262728293031public ConcurrentHashMap(int initialCapacity, float loadFactor, int concurrencyLevel) &#123; if (!(loadFactor &gt; 0) || initialCapacity &lt; 0 || concurrencyLevel &lt;= 0) throw new IllegalArgumentException(); if (concurrencyLevel &gt; MAX_SEGMENTS) concurrencyLevel = MAX_SEGMENTS; // Find power-of-two sizes best matching arguments int sshift = 0; int ssize = 1; while (ssize &lt; concurrencyLevel) &#123; ++sshift; ssize &lt;&lt;= 1; &#125; segmentShift = 32 - sshift; segmentMask = ssize - 1; this.segments = Segment.newArray(ssize); if (initialCapacity &gt; MAXIMUM_CAPACITY) initialCapacity = MAXIMUM_CAPACITY; int c = initialCapacity / ssize; if (c * ssize &lt; initialCapacity) ++c; int cap = 1; while (cap &lt; c) cap &lt;&lt;= 1; for (int i = 0; i &lt; this.segments.length; ++i) this.segments[i] = new Segment&lt;K,V&gt;(cap, loadFactor);&#125; JDK8 的实现JDK 1.8取消类segments字段，直接用table数组存储键值对，JDK1.6中每个bucket中键值对组织方式是单向链表，查找复杂度是O(n)，JDK1.8中当链表长度超过TREEIFY_THRESHOLD时，链表转换为红黑树，查询复杂度可以降低到O(log n)，改进性能； 首先先了解一下ConcurrentHashMap中的几个重要的参数： transient volatile Node&lt;K,V&gt;[] table：键值对桶数组 private transient volatile Node&lt;K,V&gt;[] nextTable： rehash扩容时用到的新键值对数组 private transient volatile long baseCount：记录当前键值对总数，通过CAS更新，对所有线程可见 private transient volatile int sizeCtl sizeCtl表示键值对总数阈值，通过CAS更新, 对所有线程可见 当sizeCtl &lt; 0时，表示多个线程在等待扩容； 当sizeCtl = 0时，默认值； 当sizeCtl &gt; 0时，表示扩容的阈值； private transient volatile int cellBusy：自旋锁； private transient volatile CounterCell[] counterCells: counter cell表，长度总为2的幂次； static class Segment&lt;K,V&gt;：在JDK1.8中，Segment类仅仅在序列化和反序列化时发挥作用； 123456789101112131415161718192021/** * races. Updated via CAS. * 记录容器的容量大小，通过CAS更新 */private transient volatile long baseCount;/** * 这个sizeCtl是volatile的，那么他是线程可见的，一个思考:它是所有修改都在CAS中进行，但是sizeCtl为什么不设计成LongAdder(jdk8出现的)类型呢？ * 或者设计成AtomicLong(在高并发的情况下比LongAdder低效)，这样就能减少自己操作CAS了。 * * 来看下注释，当sizeCtl小于0说明有多个线程正则等待扩容结果，参考transfer函数 * * sizeCtl等于0是默认值，大于0是扩容的阀值 */private transient volatile int sizeCtl;/** * 自旋锁 （锁定通过 CAS） 在调整大小和/或创建 CounterCells 时使用。 在CounterCell类更新value中会使用，功能类似显示锁和内置锁，性能更好 * 在Striped64类也有应用 */private transient volatile int cellsBusy; 数据节点123456789101112static class Node&lt;K,V&gt; implements Map.Entry&lt;K,V&gt; &#123; final int hash; final K key; volatile V val; volatile Node&lt;K,V&gt; next; Node(int hash, K key, V val, Node&lt;K,V&gt; next) &#123; this.hash = hash; this.key = key; this.val = val; this.next = next;&#125; 构造函数123456789// cap 是 &gt;= initialCapacity的最小二次幂public ConcurrentHashMap(int initialCapacity) &#123; if (initialCapacity &lt; 0) throw new IllegalArgumentException(); int cap = ((initialCapacity &gt;= (MAXIMUM_CAPACITY &gt;&gt;&gt; 1)) ? MAXIMUM_CAPACITY : tableSizeFor(initialCapacity + (initialCapacity &gt;&gt;&gt; 1) + 1)); this.sizeCtl = cap;&#125; put 过程分析123public V put(K key, V value) &#123; return putVal(key, value, false);&#125; put方法是直接调用putVal方法，其中onlyIfAbsent的作用是，如果为true，那么当值相等[hash &amp;&amp; equals]都满足条件时，值不会被覆盖。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970final V putVal(K key, V value, boolean onlyIfAbsent) &#123; //key 或 value 为null会直接抛出异常。 if (key == null || value == null) throw new NullPointerException(); int hash = spread(key.hashCode()); int binCount = 0; //这边加了一个循环，就是不断的尝试，因为在table的初始化和casTabAt用到了compareAndSwapInt、compareAndSwapObject //因为如果其他线程正在修改tab，那么尝试就会失败，所以这边要加一个for循环，不断的尝试 for (Node &lt; K, V &gt; [] tab = table;;) &#123; Node &lt; K, V &gt; f; int n, i, fh; //初始化tab if (tab == null || (n = tab.length) == 0) tab = initTable(); // 如果tab中不存在我们要存的值，就使用CAS的方式把值放入到tab中。 else if ((f = tabAt(tab, i = (n - 1) &amp; hash)) == null) &#123; //1 if (casTabAt(tab, i, null, new Node &lt; K, V &gt; (hash, key, value, null))) //2 break; // no lock when adding to empty bin &#125; else if ((fh = f.hash) == MOVED) // a // 如果走到这里，说明有其他线程正在进行扩容操作，这是一个辅助类。 tab = helpTransfer(tab, f); else &#123; V oldVal = null; // 这个地方设计非常的巧妙，内置锁synchronized锁住了f,因为f是指定特定的tab[i]的， // 所以就锁住了整行链表,这个设计跟分段锁有异曲同工之妙，只是其他读取操作需要用cas来保证 synchronized(f) &#123; if (tabAt(tab, i) == f) &#123; // if (fh &gt;= 0) &#123; binCount = 1; for (Node &lt; K, V &gt; e = f;; ++binCount) &#123; K ek; if (e.hash == hash &amp;&amp; ((ek = e.key) == key || (ek != null &amp;&amp; key.equals(ek)))) &#123; oldVal = e.val; if (!onlyIfAbsent) e.val = value; break; &#125; Node &lt; K, V &gt; pred = e; if ((e = e.next) == null) &#123; pred.next = new Node &lt; K, V &gt; (hash, key, value, null); break; &#125; &#125; &#125; else if (f instanceof TreeBin) &#123; // Node &lt; K, V &gt; p; binCount = 2; if ((p = ((TreeBin &lt; K, V &gt; ) f).putTreeVal(hash, key, value)) != null) &#123; oldVal = p.val; if (!onlyIfAbsent) p.val = value; &#125; &#125; &#125; &#125; if (binCount != 0) &#123; if (binCount &gt;= TREEIFY_THRESHOLD) treeifyBin(tab, i); //转化为红黑树 if (oldVal != null) return oldVal; break; &#125; &#125; &#125; addCount(1 L, binCount); return null;&#125; synchronized (f) {}操作通过对桶的首元素 = 链表表头 Or 红黑树根节点加锁，从而实现对整个桶进行加锁，有锁分离思想的体现； get 过程分析1234567891011121314151617181920212223public V get(Object key) &#123; Node&lt;K,V&gt;[] tab; Node&lt;K,V&gt; e, p; int n, eh; K ek; int h = spread(key.hashCode()); // 先获得存储链表的table if ((tab = table) != null &amp;&amp; (n = tab.length) &gt; 0 &amp;&amp; (e = tabAt(tab, (n - 1) &amp; h)) != null) &#123; //判断hash equals是否满足条件，如果符合就直接返回值 if ((eh = e.hash) == h) &#123; if ((ek = e.key) == key || (ek != null &amp;&amp; key.equals(ek))) return e.val; &#125;//如果eh=-1就说明e节点为ForWordingNode,这说明什么，说明这个节点已经不存在了，被另一个线程正则扩容所以要查找key对应的值的话，直接到新newtable找 else if (eh &lt; 0) return (p = e.find(h, key)) != null ? p.val : null; // 对bucket中的链表进行遍历，找到满足条件的数据 while ((e = e.next) != null) &#123; if (e.hash == h &amp;&amp; ((ek = e.key) == key || (ek != null &amp;&amp; key.equals(ek)))) return e.val; &#125; &#125; return null;&#125; remove 过程分析12345public boolean remove(Object key, Object value) &#123; if (key == null) throw new NullPointerException(); return value != null &amp;&amp; replaceNode(key, null, value) != null;&#125; table原子操作方法获取tab[i]：tabAt123static final &lt;K,V&gt; Node&lt;K,V&gt; tabAt(Node&lt;K,V&gt;[] tab, int i) &#123; return (Node&lt;K,V&gt;)U.getObjectVolatile(tab, ((long)i &lt;&lt; ASHIFT) + ABASE);&#125; tabAt方法原子读取table[i]；调用Unsafe对象的getObjectVolatile方法获取tab[i]，由于对volatile写操作happen-before于volatile读操作，因此其他线程对table的修改均对get读取可见；((long)i &lt;&lt; ASHIFT) + ABASE)计算i元素的地址 与JDK1.6对比JDK 1.8取消类segments字段，直接用table数组存储键值对，JDK1.6中每个bucket中键值对组织方式是单向链表，查找复杂度是O(n)，JDK1.8中当链表长度超过TREEIFY_THRESHOLD时，链表转换为红黑树，查询复杂度可以降低到O(log n)，改进性能； 锁分离JDK1.8中，一个线程每次对一个桶（链表 or 红黑树）进行加锁，其他线程仍然可以访问其他桶，本质是减小锁的粒度，在线程操作不同的Entry时不需要上锁； 线程安全ConcurrentHashMap底层数据结构与HashMap相同，仍然采用table数组+链表+红黑树结构；一个线程进行put/remove操作时，对桶（链表 or 红黑树）加上synchronized独占锁；ConcurrentHashMap采用CAS算法保证线程安全； 总结：JDK8之后取消了segment，采用同步和cas算法来保证线程安全。底层增加了红黑树结构提升了性能。","categories":[{"name":"Java集合框架","slug":"Java集合框架","permalink":"https://originer.github.io/Horizon.github.io/categories/Java集合框架/"}],"tags":[{"name":"Java集合框架","slug":"Java集合框架","permalink":"https://originer.github.io/Horizon.github.io/tags/Java集合框架/"}]},{"title":"Netty核心组件：Channel和Pipline","slug":"Netty核心组件：Channel与Pipline","date":"2018-11-09T07:06:35.000Z","updated":"2018-12-02T06:32:24.650Z","comments":true,"path":"2018/11/09/Netty核心组件：Channel与Pipline/","link":"","permalink":"https://originer.github.io/Horizon.github.io/2018/11/09/Netty核心组件：Channel与Pipline/","excerpt":"Channel分析Channel接口","text":"Channel分析Channel接口 AbstractChannel AbstractChannel的构造函数和主要参数1234567891011121314151617181920212223242526272829303132private final Channel parent;private final ChannelId id;private final Unsafe unsafe;private final DefaultChannelPipeline pipeline;private final VoidChannelPromise unsafeVoidPromise = new VoidChannelPromise(this, false);private final CloseFuture closeFuture = new CloseFuture(this);private volatile SocketAddress localAddress;private volatile SocketAddress remoteAddress;private volatile EventLoop eventLoop;private volatile boolean registered;/** Cache for the string representation of this channel */private boolean strValActive;private String strVal;/** * Creates a new instance. * * @param parent * the parent of this channel. &#123;@code null&#125; if there's no parent. */protected AbstractChannel(Channel parent) &#123; this.parent = parent; id = newId(); //每个channel都包含一个unsafa 和 pipline unsafe = newUnsafe(); pipeline = newChannelPipeline();&#125;protected DefaultChannelPipeline newChannelPipeline() &#123; return new DefaultChannelPipeline(this);&#125; 从上面代码中可以看出，每个Channel都会绑定一条唯一的Pipline，默认是采用DefaultChannelPipeline。AbstractChannel实现了Channel接口的骨架，其他各种类型的Channel基本都继承自这个类。我们以NioSocketServerChannel为例进行分析： Unsafe每一个Channel都对应一个Unsafe对象，unsafe是用来做一些底层的操作。NioServerSocketChannel对应NioMessageUnsafe, NioSocketChannel对应NioByteUnsafe 。 ChannelPipline分析## ​ DefaultChannelPipline DefaultChannelPipline的构造函数 1234567891011protected DefaultChannelPipeline(Channel channel) &#123; this.channel = ObjectUtil.checkNotNull(channel, \"channel\"); succeededFuture = new SucceededChannelFuture(channel, null); voidPromise = new VoidChannelPromise(channel, true); tail = new TailContext(this); head = new HeadContext(this); head.next = tail; tail.prev = head;&#125; 可以看出Pipline的数据结构是一条双向链表，在初始化的时候会生成头尾结点。从下面代码可以看出，head结点实际上是outbuound，tail节点是inbound。 1234567891011121314151617181920212223242526272829303132final class TailContext extends AbstractChannelHandlerContext implements ChannelInboundHandler &#123; TailContext(DefaultChannelPipeline pipeline) &#123; super(pipeline, null, TAIL_NAME, true, false); setAddComplete(); &#125; ...&#125;final class HeadContext extends AbstractChannelHandlerContext implements ChannelOutboundHandler, ChannelInboundHandler &#123; //头结点是最特殊的，包含一个Unsafe对象，可以直接操控socket private final Unsafe unsafe; HeadContext(DefaultChannelPipeline pipeline) &#123; super(pipeline, null, HEAD_NAME, false, true); unsafe = pipeline.channel().unsafe(); setAddComplete(); &#125; ... &#125; //super构造函数 AbstractChannelHandlerContext(DefaultChannelPipeline pipeline, EventExecutor executor, String name, boolean inbound, boolean outbound) &#123; this.name = ObjectUtil.checkNotNull(name, \"name\"); this.pipeline = pipeline; this.executor = executor; this.inbound = inbound; this.outbound = outbound; // Its ordered if its driven by the EventLoop or the given Executor is an instanceof OrderedEventExecutor. ordered = executor == null || executor instanceof OrderedEventExecutor; &#125; pipline 添加结点我们在创建客户端或者服务端时，常常会用到类似下面的代码，为客户端或者服务端添加handler： 123456789bootstrap.childHandler(new ChannelInitializer &lt; SocketChannel &gt; () &#123; @Override public void initChannel(SocketChannel ch) throws Exception &#123; ChannelPipeline p = ch.pipeline(); p.addLast(new Spliter()); p.addLast(new Decoder()); p.addLast(new BusinessHandler()); p.addLast(new Encoder()); &#125;&#125;); 添加结点的方法是 addLast ，从源代码可以看出一次是可以添加多个ChannelHandler的，最终会用一个for循环来添加。 12345678910111213141516public final ChannelPipeline addLast(ChannelHandler... handlers) &#123; return addLast(null, handlers);&#125; public final ChannelPipeline addLast(EventExecutorGroup executor, ChannelHandler... handlers) &#123; if (handlers == null) &#123; throw new NullPointerException(\"handlers\"); &#125; for (ChannelHandler h: handlers) &#123; if (h == null) &#123; break; &#125; addLast(executor, null, h); &#125; return this;&#125; 最后是走到下面的代码里面，首先会检查添加的handler是否已经添加过。只有标注了@Sharable的handler才能重复添加。 1234567891011121314151617181920212223242526272829303132333435public final ChannelPipeline addLast(EventExecutorGroup group, String name, ChannelHandler handler) &#123; final AbstractChannelHandlerContext newCtx; synchronized (this) &#123; //检查handler是否重复 isSharable checkMultiplicity(handler); //创建结点 newCtx = newContext(group, filterName(name, handler), handler); //添加结点 addLast0(newCtx); // If the registered is false it means that the channel was not registered on an eventloop yet. // In this case we add the context to the pipeline and add a task that will call // ChannelHandler.handlerAdded(...) once the channel is registered. if (!registered) &#123; newCtx.setAddPending(); callHandlerCallbackLater(newCtx, true); return this; &#125; EventExecutor executor = newCtx.executor(); if (!executor.inEventLoop()) &#123; newCtx.setAddPending(); executor.execute(new Runnable() &#123; @Override public void run() &#123; callHandlerAdded0(newCtx); &#125; &#125;); return this; &#125; &#125; //回调用户方法 callHandlerAdded0(newCtx); return this;&#125; 添加结点的代码在 addLast0 中，熟悉双向链表的话应该很容易就能理解下面的代码： 1234567private void addLast0(AbstractChannelHandlerContext newCtx) &#123; AbstractChannelHandlerContext prev = tail.prev; newCtx.prev = prev; newCtx.next = tail; prev.next = newCtx; tail.prev = newCtx;&#125; pipeline删除结点pipline中的结点支持热插拔，可以动态编织pipline。 123456789101112131415161718192021222324252627282930313233343536373839404142public final ChannelHandler remove(String name) &#123; //先找到需要删除的结点 return remove(getContextOrDie(name)).handler();&#125; private AbstractChannelHandlerContext remove(final AbstractChannelHandlerContext ctx) &#123; assert ctx != head &amp;&amp; ctx != tail; synchronized (this) &#123; //移除结点 remove0(ctx); // If the registered is false it means that the channel was not registered on an eventloop yet. // In this case we remove the context from the pipeline and add a task that will call // ChannelHandler.handlerRemoved(...) once the channel is registered. if (!registered) &#123; callHandlerCallbackLater(ctx, false); return ctx; &#125; EventExecutor executor = ctx.executor(); if (!executor.inEventLoop()) &#123; executor.execute(new Runnable() &#123; @Override public void run() &#123; callHandlerRemoved0(ctx); &#125; &#125;); return ctx; &#125; &#125; //回调用户函数 callHandlerRemoved0(ctx); return ctx; &#125; private static void remove0(AbstractChannelHandlerContext ctx) &#123; AbstractChannelHandlerContext prev = ctx.prev; AbstractChannelHandlerContext next = ctx.next; prev.next = next; next.prev = prev; &#125; pipline中的事件传播顺序 inBound事件从head节点传播到tail节点。 outBound事件从tail节点传播到head节点。 异常传播只会往后传播，而且不分inbound还是outbound节点，不像outBound事件一样会往前传播","categories":[{"name":"网络编程","slug":"网络编程","permalink":"https://originer.github.io/Horizon.github.io/categories/网络编程/"}],"tags":[{"name":"Netty","slug":"Netty","permalink":"https://originer.github.io/Horizon.github.io/tags/Netty/"}]},{"title":"Netty核心组件：解码器/编码器","slug":"Netty核心组件：解码器编码器","date":"2018-11-09T06:50:47.000Z","updated":"2018-12-02T06:31:15.623Z","comments":true,"path":"2018/11/09/Netty核心组件：解码器编码器/","link":"","permalink":"https://originer.github.io/Horizon.github.io/2018/11/09/Netty核心组件：解码器编码器/","excerpt":"我们知道，数据在网络上都是通过字节流传输的，Netty作为一款网络通讯框架，编解码是很重要的一个模块。","text":"我们知道，数据在网络上都是通过字节流传输的，Netty作为一款网络通讯框架，编解码是很重要的一个模块。 解码器 ByteToMessageDecoder ByteToMessageDecoder中有个ByteBuf用来读取字节，还有一个Cumulator累加器用来计算当前读取的字节流。 本质上ByteToMessageDecoder还是一个入站Handler，所以最重要的方法就是channelRead(): 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647public void channelRead(ChannelHandlerContext ctx, Object msg) throws Exception &#123; //如果消息是字节流，就进行处理，否则就进行向下传播 if (msg instanceof ByteBuf) &#123; CodecOutputList out = CodecOutputList.newInstance(); try &#123; ByteBuf data = (ByteBuf) msg; //判断first是不是null，也就是判断是不是第一次读取数据 //如果是就直接把data复制给cumulation （cumulation就是一个ByteBuf） //否则就把data累加到cumulation上 first = cumulation == null; if (first) &#123; cumulation = data; &#125; else &#123; cumulation = cumulator.cumulate(ctx.alloc(), cumulation, data); &#125; //调用decode，对字节流进行解码 callDecode(ctx, cumulation, out); &#125; catch (DecoderException e) &#123; throw e; &#125; catch (Exception e) &#123; throw new DecoderException(e); &#125; finally &#123; // 如果累计区没有可读字节了 if (cumulation != null &amp;&amp; !cumulation.isReadable()) &#123; //把读取次数清空 numReads = 0; //释放累计区 cumulation.release(); //赋值为null，方便GC cumulation = null; // 如果超过了 16 次，就压缩累计区，主要是将已经读过的数据丢弃，将 readIndex 归零。 &#125; else if (++ numReads &gt;= discardAfterReads) &#123; numReads = 0; discardSomeReadBytes(); &#125; int size = out.size(); decodeWasNull = !out.insertSinceRecycled(); //把out中的数据循环发送出去 fireChannelRead(ctx, out, size); //清空out out.recycle(); &#125; &#125; else &#123; ctx.fireChannelRead(msg); &#125;&#125; channelRead的任务是把字节读到累计器里面，然后调用callDecodec来进行解码： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859protected void callDecode(ChannelHandlerContext ctx, ByteBuf in, List&lt;Object&gt; out) &#123; try &#123; //循环判断有无可读数据，一直读到ByteBuf中没有数据为止 while (in.isReadable()) &#123; int outSize = out.size(); //如果out中已经有数据了就发送给下一个handler if (outSize &gt; 0) &#123; //注意，是可以多条一起发送的，然后把out列表清空 fireChannelRead(ctx, out, outSize); out.clear(); // Check if this handler was removed before continuing with decoding. // If it was removed, it is not safe to continue to operate on the buffer. // // See: // - https://github.com/netty/netty/issues/4635 if (ctx.isRemoved()) &#123; break; &#125; outSize = 0; &#125; // 得到可读字节数 int oldInputLength = in.readableBytes(); // 调用 decode 方法，将成功解码后的数据放入道 out 数组中，可能会删除当前节点， //删除之前会将数据发送到最后的 handler decodeRemovalReentryProtection(ctx, in, out); // Check if this handler was removed before continuing the loop. // If it was removed, it is not safe to continue to operate on the buffer. // // See https://github.com/netty/netty/issues/1664 if (ctx.isRemoved()) &#123; break; &#125; //后面的都是判断读完退出的条件 if (outSize == out.size()) &#123; if (oldInputLength == in.readableBytes()) &#123; break; &#125; else &#123; continue; &#125; &#125; if (oldInputLength == in.readableBytes()) &#123; throw new DecoderException( StringUtil.simpleClassName(getClass()) + \".decode() did not read anything but decoded a message.\"); &#125; if (isSingleDecode()) &#123; break; &#125; &#125; &#125; catch (DecoderException e) &#123; throw e; &#125; catch (Exception cause) &#123; throw new DecoderException(cause); &#125;&#125; Netty有很多内置解码器，最常用的有以下几种： 基于固定长度的解码器 FixedLengthFrameDecoder基于固定长度的解码器实现比较简单，就是每次从字节流中取出固定的字节数： 123456789101112131415161718//注意这个decode是重写ByteToMessageDecoder @Override protected final void decode(ChannelHandlerContext ctx, ByteBuf in, List&lt;Object&gt; out) throws Exception &#123; //调用具体的decode实现 Object decoded = decode(ctx, in); if (decoded != null) &#123; //把解析出的具体对象添加到out列表中，然后由父类ByteToMessageDecoder的channelRead方法向下传播 out.add(decoded); &#125; &#125;protected Object decode(ChannelHandlerContext ctx, ByteBuf in) throws Exception &#123; if (in.readableBytes() &lt; frameLength) &#123; return null; &#125; else &#123; //读取固定长度的字节流 return in.readRetainedSlice(frameLength); &#125;&#125; 基于分隔符的解码器 DelimiterBasedFrameDecoder可以自定义分隔符，是比较常用的解码器，处理逻辑跟基于长度的类似，就不贴代码了。 基于长度域的解码器 LengthFieldBasedFrameDecoder这个解码器应该是内置解码器里用处最广的一个，首先需要了解几个比较重要的参数： 1234567891011121314//数据存储采用大端模式或小端模式,默认采用大端private final ByteOrder byteOrder;//报文最大长度private final int maxFrameLength;//报文长度字段在整个报文中的偏移量private final int lengthFieldOffset;//报文长度字段所占的字节，一般占1、2、3、4、8字节，其他的需要自己重写getUnadjustedFrameLength方法private final int lengthFieldLength;//lengthFieldOffset + lengthFieldLength 长度字段结束位置的偏移量private final int lengthFieldEndOffset;//长度字段值的补偿值，因为有时候报文的字段长度不包括长度字段本身占用的字节private final int lengthAdjustment;//可以去除报文头的部分private final int initialBytesToStrip; 了解参数的具体含义之后根据具体的报文配置完成后就可以直接拿来用，配置的参数可以参考下面的公式： 公式: 发送数据包长度 = 长度域的值 + lengthFieldOffset + lengthFieldLength + lengthAdjustment 除此之外，netty还提供了http、https等常用协议的解码器，实现原理都差不多。 编码器 MessageToByteEncoder编码器与解码器相反，是把业务逻辑处理完后的对象编码成字节流通过socket发送出去： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152public void write(ChannelHandlerContext ctx, Object msg, ChannelPromise promise) throws Exception &#123; ByteBuf buf = null; try &#123; //判断消息类型是否可处理，如果不能处理就传递给下一个handler if (acceptOutboundMessage(msg)) &#123; //强转数据类型 @SuppressWarnings(\"unchecked\") I cast = (I) msg; //分配内存 preferDirect默认为true buf = allocateBuffer(ctx, cast, preferDirect); try &#123; //调用子类实现的encode，把cast转成字节流塞入buf中 encode(ctx, cast, buf); &#125; finally &#123; //释放对象 ReferenceCountUtil.release(cast); &#125; //如果buf是可读的，就是有取到具体的字节流就传播给下一个结点，一直到headcontext结点 //否则就传递个空字节流 if (buf.isReadable()) &#123; ctx.write(buf, promise); &#125; else &#123; buf.release(); ctx.write(Unpooled.EMPTY_BUFFER, promise); &#125; //加个保险，释放内存后在赋值为null 防止内存泄漏 buf = null; &#125; else &#123; ctx.write(msg, promise); &#125; &#125; catch (EncoderException e) &#123; throw e; &#125; catch (Throwable e) &#123; throw new EncoderException(e); &#125; finally &#123; //最后在判断一次，如果因为异常没有被赋值为null的话就再次调用释放内存 if (buf != null) &#123; buf.release(); &#125; &#125;&#125; protected ByteBuf allocateBuffer(ChannelHandlerContext ctx, @SuppressWarnings(\"unused\") I msg, boolean preferDirect) throws Exception &#123; if (preferDirect) &#123; //分配可以直接使用IO buffer缓冲区，堆外内存 return ctx.alloc().ioBuffer(); &#125; else &#123; //分配堆缓冲区 return ctx.alloc().heapBuffer(); &#125; &#125;","categories":[{"name":"网络编程","slug":"网络编程","permalink":"https://originer.github.io/Horizon.github.io/categories/网络编程/"}],"tags":[{"name":"Netty","slug":"Netty","permalink":"https://originer.github.io/Horizon.github.io/tags/Netty/"}]},{"title":"并发框架Disruptor学习","slug":"生产者消费者模型-并发框架Disruptor","date":"2018-11-08T05:17:21.000Z","updated":"2019-03-22T09:53:47.594Z","comments":true,"path":"2018/11/08/生产者消费者模型-并发框架Disruptor/","link":"","permalink":"https://originer.github.io/Horizon.github.io/2018/11/08/生产者消费者模型-并发框架Disruptor/","excerpt":"Disruptor 是一个基于生产者消费者模型的高性能并发框架，可以用来代替Java内置的阻塞队列实现的生产者消费者模型。 Disruptor高效的原因Disruptor通过以下设计来解决队列速度慢的问题： 环形数组结构 为了避免垃圾回收，采用数组而非链表。同时，数组对处理器的缓存机制更加友好。 元素位置定位 数组长度2^n，通过位运算，加快定位的速度。下标采取递增的形式。不用担心index溢出的问题。index是long类型，即使100万QPS的处理速度，也需要30万年才能用完。 无锁设计 每个生产者或者消费者线程，会先申请可以操作的元素在数组中的位置，申请到之后，直接在该位置写入或者读取数据。 下面忽略数组的环形结构，介绍一下如何实现无锁设计。整个过程通过原子变量CAS，保证操作的线程安全。","text":"Disruptor 是一个基于生产者消费者模型的高性能并发框架，可以用来代替Java内置的阻塞队列实现的生产者消费者模型。 Disruptor高效的原因Disruptor通过以下设计来解决队列速度慢的问题： 环形数组结构 为了避免垃圾回收，采用数组而非链表。同时，数组对处理器的缓存机制更加友好。 元素位置定位 数组长度2^n，通过位运算，加快定位的速度。下标采取递增的形式。不用担心index溢出的问题。index是long类型，即使100万QPS的处理速度，也需要30万年才能用完。 无锁设计 每个生产者或者消费者线程，会先申请可以操作的元素在数组中的位置，申请到之后，直接在该位置写入或者读取数据。 下面忽略数组的环形结构，介绍一下如何实现无锁设计。整个过程通过原子变量CAS，保证操作的线程安全。 核心组件介绍环形数组：RingBuffer RingBufferFields用来创建环形数组，并且对初始数组进行填充12345678910111213141516171819202122232425262728293031323334 private final long indexMask; //任务进度标记 private final Object[] entries; //空数组 protected final int bufferSize; //数组大小 protected final Sequencer sequencer; //序号管理器RingBufferFields( EventFactory&lt;E&gt; eventFactory, Sequencer sequencer) &#123; this.sequencer = sequencer; this.bufferSize = sequencer.getBufferSize(); if (bufferSize &lt; 1) &#123; throw new IllegalArgumentException(\"bufferSize must not be less than 1\"); &#125; if (Integer.bitCount(bufferSize) != 1) &#123; throw new IllegalArgumentException(\"bufferSize must be a power of 2\"); &#125; //推测是对数组当前处理任务的标记，因为数组一开始就会填充满所以执行任务的进度是 bufferSize - 1 //比如初始化一个 size为10 的数组，经过填充后0-9都是已经占用了，所以任务执行标记标注在 9 this.indexMask = bufferSize - 1; //具体涉及到一些数组偏移量和增量地址的问题，暂不研究，可以理解为开辟一个bufferSize的环形数组 //通过一系列操作创建了一个环形数组 this.entries = new Object[sequencer.getBufferSize() + 2 * BUFFER_PAD]; //填充数组，内存预加载机制 //注意这里传入的是一个eventFactroy，通常就是重写newInstance方法，用来初始化。 fill(eventFactory);&#125;private void fill(EventFactory&lt;E&gt; eventFactory) &#123; for (int i = 0; i &lt; bufferSize; i++) &#123; //newInstance返回的是我们定义的具体事件 entries[BUFFER_PAD + i] = eventFactory.newInstance(); &#125;｝ RingBuffer主要分为单生产者和多生产者，在进行create的时候可以进行选择：1234567891011121314public static &lt;E&gt; RingBuffer&lt;E&gt; create( ProducerType producerType, EventFactory&lt;E&gt; factory, int bufferSize, WaitStrategy waitStrategy) &#123; switch (producerType) &#123; case SINGLE: return createSingleProducer(factory, bufferSize, waitStrategy); case MULTI: return createMultiProducer(factory, bufferSize, waitStrategy); default: throw new IllegalStateException(producerType.toString()); &#125;&#125; 创建一个单生产者的RingBuffer123456789public static &lt;E&gt; RingBuffer&lt;E&gt; createSingleProducer( EventFactory&lt;E&gt; factory, int bufferSize, WaitStrategy waitStrategy) &#123; //单生产者与多生产者最大的区别就在于sequencer，下面是sequencer的UML图 SingleProducerSequencer sequencer = new SingleProducerSequencer(bufferSize, waitStrategy); return new RingBuffer&lt;E&gt;(factory, sequencer);&#125; 序号管理器：Sequencer SingleProducerSequencer 单生产者序号管理器获取下一个可用序号next()123456789101112131415161718192021222324252627282930313233//假设第一次调用next() 此时：n=1 nextValue=-1 cachedValue=-1public long next(int n) &#123; if (n &lt; 1) &#123; throw new IllegalArgumentException(\"n must be &gt; 0\"); &#125; //取出序号管理器的下一个值，初始值为-1 long nextValue = this.nextValue; //-1；0 //获得下一个序号 long nextSequence = nextValue + n; //0；1 //判断生产者序号有没有超过ringBuffer的大小 long wrapPoint = nextSequence - bufferSize; //0-10 = -10；1-10=-9； long cachedGatingSequence = this.cachedValue; //-1；-1； //-10&gt;-1 -1&gt;-1 FALSE //如果生产者序号大于最小的消费者就挂起自旋 if (wrapPoint &gt; cachedGatingSequence || cachedGatingSequence &gt; nextValue) &#123; cursor.setVolatile(nextValue); // StoreLoad fence long minSequence; //获取数组中的最小序号与wrapPoint比较 while (wrapPoint &gt; (minSequence = Util.getMinimumSequence(gatingSequences, nextValue))) &#123; //挂起自旋 LockSupport.parkNanos(1L); // TODO: Use waitStrategy to spin? &#125; //更新缓存值 this.cachedValue = minSequence; &#125; // 0 this.nextValue = nextSequence; // 0 return nextSequence;&#125; 通过分析代码，可以看出，disruptor在管理序号的时候使用了自旋锁和CAS操作来代替锁，同时也使用了填充缓存行的技术，最高效的利用了CPU的性能。 MultiProducerSequencer 多生产者序号管理器获取下一个可用序号next()123456789101112131415161718192021222324252627282930313233public long next(int n) &#123; if (n &lt; 1) &#123; throw new IllegalArgumentException(\"n must be &gt; 0\"); &#125; long current; long next; do &#123; current = cursor.get(); next = current + n; long wrapPoint = next - bufferSize; long cachedGatingSequence = gatingSequenceCache.get(); if (wrapPoint &gt; cachedGatingSequence || cachedGatingSequence &gt; current) &#123; long gatingSequence = Util.getMinimumSequence(gatingSequences, current); //猜测是生产者生产过快，所以需要停顿一下 if (wrapPoint &gt; gatingSequence) &#123; LockSupport.parkNanos(1); // TODO, should we spin based on the wait strategy? continue; &#125; gatingSequenceCache.set(gatingSequence); //采用CAS方式更新cusor的值 &#125; else if (cursor.compareAndSet(current, next)) &#123; break; &#125; &#125; while (true); return next;&#125; 序号栅栏机制下面三个要求是获取序号和更新序号的规则： 消费者序号小于生产者序号 消费者序号必须小于其前置（依赖关系）消费者的序号 生产者序号不能大于消费者中最小的序号数值 执行器：EventProcessor文档中对EventProcessor的解释是用于执行事件的，可以添加等待策略，需要实现一个Runnable接口，主要实现类有两个BatchEventProcessor WorkProcessor BatchEventProcessorrun()123456789101112131415161718192021222324252627282930313233//内部的比较关键的状态参数private static final int IDLE = 0;private static final int HALTED = IDLE + 1;private static final int RUNNING = HALTED + 1;private final AtomicInteger running = new AtomicInteger(IDLE);public void run() &#123; //修改runing的标志 if (running.compareAndSet(IDLE, RUNNING)) &#123; sequenceBarrier.clearAlert(); notifyStart(); try &#123; // 判断是否执行事件 if (running.get() == RUNNING) &#123; processEvents(); &#125; &#125; finally &#123; notifyShutdown(); running.set(IDLE); &#125; &#125; else &#123; // This is a little bit of guess work. The running state could of changed to HALTED by // this point. However, Java does not have compareAndExchange which is the only way // to get it exactly correct. if (running.get() == RUNNING) &#123; throw new IllegalStateException(\"Thread is already running\"); &#125; else &#123; earlyExit(); &#125; &#125;&#125; processEvents()123456789101112131415161718192021222324252627282930313233343536private void processEvents() &#123; T event = null; //获取下一个可用序号给消费者使用 long nextSequence = sequence.get() + 1L; while (true) &#123; try &#123; //根据消费策略获取真实可用序号，这是整个执行逻辑的核心 //想要消费的序号必须小于生产者生产的序号，如果不符合条件就根据具体的等待策略进行等待 //waitFor有多种实现，这个取决于选用了什么样的等待策略 final long availableSequence = sequenceBarrier.waitFor(nextSequence); if (batchStartAware != null) &#123; batchStartAware.onBatchStart(availableSequence - nextSequence + 1); &#125; // 说明生产者速度比消费者快，有多余的事件可进行消费 // 如果事件全部被消费完了就会跳出循环 while (nextSequence &lt;= availableSequence) &#123; event = dataProvider.get(nextSequence); eventHandler.onEvent(event, nextSequence, nextSequence == availableSequence); nextSequence++; &#125; // 事件全部被消费完了，把当前生产者的序号设置给sequence sequence.set(availableSequence); &#125; catch (final TimeoutException e) &#123; notifyTimeout(sequence.get()); &#125; catch (final AlertException ex) &#123; if (running.get() != RUNNING) &#123; break; &#125; &#125; catch (final Throwable ex) &#123; exceptionHandler.handleEventException(ex, nextSequence, event); sequence.set(nextSequence); nextSequence++; &#125; &#125;&#125; BlockingWaitStrategy中实现的waitFor1234567891011121314151617181920public long waitFor(long sequence, Sequence cursorSequence, Sequence dependentSequence, SequenceBarrier barrier) throws AlertException, InterruptedException &#123; long availableSequence; if (cursorSequence.get() &lt; sequence) &#123; //很明显使用了互斥锁 synchronized (mutex) &#123; //生产者序号小于消费者序，消费速度过快 while (cursorSequence.get() &lt; sequence) &#123; barrier.checkAlert(); mutex.wait(); &#125; &#125; &#125; while ((availableSequence = dependentSequence.get()) &lt; sequence) &#123; barrier.checkAlert(); ThreadHints.onSpinWait(); &#125; return availableSequence;&#125; 等待策略disruptor实现了多种等待策略 多生产者多消费者demoWorkPool的构造函数 123456789public WorkerPool(RingBuffer&lt;T&gt; ringBuffer, SequenceBarrier sequenceBarrier, ExceptionHandler&lt;? super T&gt; exceptionHandler, WorkHandler... workHandlers) &#123; this.ringBuffer = ringBuffer; int numWorkers = workHandlers.length; this.workProcessors = new WorkProcessor[numWorkers]; for(int i = 0; i &lt; numWorkers; ++i) &#123; this.workProcessors[i] = new WorkProcessor(ringBuffer, sequenceBarrier, workHandlers[i], exceptionHandler, this.workSequence); &#125;&#125; 使用多消费者需要使用WorkerPool启动 123456WorkerPool&lt;Order&gt; workerPool = new WorkerPool&lt;Order&gt;( ringBuffer, sequenceBarrier, new EventExceptionHandler(), //传入的消费者需要实现 WorkHandler 接口 consumers);","categories":[{"name":"并发编程","slug":"并发编程","permalink":"https://originer.github.io/Horizon.github.io/categories/并发编程/"}],"tags":[]},{"title":"Java设计模式：单例模式","slug":"设计模式：单例模式","date":"2018-09-16T15:26:54.000Z","updated":"2018-09-16T15:26:54.000Z","comments":true,"path":"2018/09/16/设计模式：单例模式/","link":"","permalink":"https://originer.github.io/Horizon.github.io/2018/09/16/设计模式：单例模式/","excerpt":"饿汉模式 12345678910111213141516public class Sigleton &#123; //饿汉模式 outInstance是私有的 private static Sigleton ourInstance = new Sigleton(); /** * 此实现是线程安全的 JVM在加载此类时，因为对于static属性的初始化只能由一个线程执行且仅执行一次 * 缺点：instance在类装载时就实例化 这时候初始化instance显然没有达到lazy loading的效果 * @return */ public static Sigleton getInstance() &#123; return ourInstance; &#125; //把构造函数声明为private 客户对象无法创建该实例 private Sigleton() &#123; &#125;&#125;","text":"饿汉模式 12345678910111213141516public class Sigleton &#123; //饿汉模式 outInstance是私有的 private static Sigleton ourInstance = new Sigleton(); /** * 此实现是线程安全的 JVM在加载此类时，因为对于static属性的初始化只能由一个线程执行且仅执行一次 * 缺点：instance在类装载时就实例化 这时候初始化instance显然没有达到lazy loading的效果 * @return */ public static Sigleton getInstance() &#123; return ourInstance; &#125; //把构造函数声明为private 客户对象无法创建该实例 private Sigleton() &#123; &#125;&#125; 懒汉模式 123456789101112131415161718192021222324252627282930313233public class Sigleton2 &#123; //懒汉模式（需要时才实例化对象） private static Sigleton2 instance; /** * 线程不安全 原因：getInstance在高并发环境下可能会被同时调用，导致if(instance==null)判断就不靠谱 * @return */// public static Sigleton2 getInstance() &#123;// if (instance == null) &#123;// instance = new Sigleton2();// &#125;// return instance;// &#125; /** * 解决方法：添加synchornized关键字 * 缺点：性能降低 * @return */ public static synchronized Sigleton2 getInstance() &#123; if (instance == null) &#123; instance = new Sigleton2(); &#125; return instance; &#125; private Sigleton2()&#123; &#125;&#125; 双重校验锁 1234567891011121314151617public class DoubleCheckSingleton &#123; //此方法需要在Java 5及以上的版本才能运行 volatile关键字在Java5引入 //防止指令重排序 public volatile static DoubleCheckSingleton instance = null; private DoubleCheckSingleton()&#123;&#125; public static DoubleCheckSingleton getInstance() &#123; if (instance == null) &#123; //检查实例是否创建 如果没有把 DoubleCheckSingleton.class设置为同步 synchronized (DoubleCheckSingleton.class) &#123; if (instance == null) &#123; //double check instance = new DoubleCheckSingleton(); &#125; &#125; &#125; return instance; &#125;&#125; 静态内部类 123456789101112public class StaticSingleton &#123; private static class SingletonHolder &#123; private static final StaticSingleton INSTANCE = new StaticSingleton(); &#125; private StaticSingleton ()&#123;&#125; //这种方式同样利用了classloder的机制来保证初始化instance时只有一个线程 public static final StaticSingleton getInstance() &#123; return SingletonHolder.INSTANCE; &#125;&#125; Singleton的序列化 如果单例类实现了Serializable接口，默认情况下，每次反序列化总会创建一个新的实例对象。解决方法：重写readResolve（）方法，直接返回单例对象 12345678910111213141516171819202122232425262728package Sigleton;import java.io.Serializable;/** * Created by Zz on 2017/5/3 0003. */public class Sigleton implements Serializable&#123; private static final long serialVersionUid = -6012841243252L; //饿汉模式 outInstance是私有的 private static Sigleton ourInstance = new Sigleton(); /** * 此实现是线程安全的 JVM在加载此类时，因为对于static属性的初始化只能由一个线程执行且仅执行一次 * 缺点：instance在类装载时就实例化 这时候初始化instance显然没有达到lazy loading的效果 * @return */ public static Sigleton getInstance() &#123; return ourInstance; &#125; //把构造函数声明为private 客户对象无法创建该实例 private Sigleton() &#123; &#125; private Object readResolve()&#123; return ourInstance; &#125;&#125; 学习Netty源代码时发现了一种非常优雅的写法： 1234public static final MqttEncoder INSTANCE = new MqttEncoder();private MqttEncoder() &#123;&#125;","categories":[{"name":"设计模式","slug":"设计模式","permalink":"https://originer.github.io/Horizon.github.io/categories/设计模式/"}],"tags":[{"name":"设计模式","slug":"设计模式","permalink":"https://originer.github.io/Horizon.github.io/tags/设计模式/"}]},{"title":"Java性能调优","slug":"性能调优手记","date":"2018-09-07T01:31:36.000Z","updated":"2018-09-07T01:31:36.000Z","comments":true,"path":"2018/09/07/性能调优手记/","link":"","permalink":"https://originer.github.io/Horizon.github.io/2018/09/07/性能调优手记/","excerpt":"","text":"1.在程序调用过程中，有一段代码是通过动态反射调用的，如果频繁创建元数据性能会比直接调用低很多。 解决方法：可以给动态反射调用添加缓存，关闭安全检查。 2.对相似独立的任务采用线程池处理 解决方法：优化线程池的配置，缓存线程池和固定线程数的效率差不多，但是缓存线程池在任务接收速度很快的情况下CPU占用会飙升，变的很卡，所以还是选择FIXED线程池，线程数可以设置为 cpu core+1。 3.多线程情况下，调用工具类的静态方法速度反而会更加慢？ 4.每处理一笔委托大约需要20ms，现在要把时间压缩到5ms左右。 5.优化点：对于需要频繁创建的大对象做静态化处理，或者把对象缓存起来 参考： https://my.oschina.net/xianggao/blog/77224","categories":[{"name":"Java","slug":"Java","permalink":"https://originer.github.io/Horizon.github.io/categories/Java/"}],"tags":[]},{"title":"Netty相关的常见问题整理","slug":"Netty相关的经典问题","date":"2018-08-26T16:58:04.000Z","updated":"2018-08-26T16:58:04.000Z","comments":true,"path":"2018/08/27/Netty相关的经典问题/","link":"","permalink":"https://originer.github.io/Horizon.github.io/2018/08/27/Netty相关的经典问题/","excerpt":"问:服务端Socket在哪里初始化?答:反射创建服务端Channel:NioServerSocketChannel默认构造方法调用newSocket()使用provider.openServerSocketChannel()创建服务端Socket。 问:在哪里accept连接?答:端口绑定:Pipeline调用fireChannelActive()传播active事件,HeadContext使用readIfIsAutoRead()重新绑定OP_ACCEPT事件,新连接接入Selector轮询到OP_ACCEPT事件将连接交给Netty处理","text":"问:服务端Socket在哪里初始化?答:反射创建服务端Channel:NioServerSocketChannel默认构造方法调用newSocket()使用provider.openServerSocketChannel()创建服务端Socket。 问:在哪里accept连接?答:端口绑定:Pipeline调用fireChannelActive()传播active事件,HeadContext使用readIfIsAutoRead()重新绑定OP_ACCEPT事件,新连接接入Selector轮询到OP_ACCEPT事件将连接交给Netty处理 问:默认情况下,Netty服务端起多少线程?何时启动?答:默认2cpu即Runtime.getRuntime().availableProcessors()2]线程,调用execute()方法判断当前是否在本线程,如果是在本线程说明线程已经启动,如果是在外部线程调用execute()方法,首先调用startThread()方法判断当前线程是否启动,未启动就启动此线程 问:Netty是如何解决JDK空轮询Bug?答:判断阻塞select操作是否阻塞timeoutMillis时间,未阻塞timeoutMillis时间表示可能触发JDK空轮询;判断触发JDK空轮询的次数是否超过阈值(默认512),超过阈值调用rebuildSelector()方法重建Selector把之前的Selector上面所有的Key重新移到新的Selector避免JDK空轮询的Bug 问:Netty如何保证异步串行无锁化?答:外部线程调用EventLoop或者Channel方法通过inEventLoop()方法判断得出是外部线程,所有操作封装成Task丢到普通任务队列MpscQueue,异步执行普通任务队列MpscQueue待执行任务 问:Netty是在哪里检测有新连接接入的?答:Boss线程通过服务端Channel绑定的Selector轮询OP_ACCEPT事件,通过JDK底层Channel的accept()方法获取JDK底层SocketChannel创建新连接 问:新连接是怎样注册到NioEventLoop线程的?答:Boss线程调用Chooser的next()方法选择获取NioEventLoop绑定到客户端Channel,使用doRegister()方法将新连接注册到NioEventLoop的Selector上面 问:Netty是如何判断ChannelHandler类型的?答:Pipeline添加ChannelHandler调用newContext()创建ChannelHandlerContext节点使用isInbound()/isOutbound()方法通过instanceOf关键词判断ChannelHandler类型为ChannelInboundHandler或者ChannelOutboundHandler,设置inbound/outbound为true标识Handler处理inbound/outBound事件 问:对于ChannelHandler的添加应该遵循什么样的顺序?答:inBound事件的传播跟添加ChannelHandler顺序正相关,outBound事件的传播跟添加ChannelHandler顺序逆相关 问:用户手动触发事件传播,不同的触发方式有什么样的区别?答:通过Channel触发事件从head节点传播即为inBound事件传播,从tail节点传播即为outBound事件传播,当前节点触发事件从当前节点开始传播,inBound事件从当前节点向后传播到最后一个ChannelInboundHandler节点,outBound事件从当前节点向前传播到第一个ChannelOutboundHandler节点 问:内存的类别有哪些?答:1.堆内[基于byte字节内存数组分配]/堆外[基于JDK的DirectByteBuffer内存分配],2.Unsafe[通过JDK的Unsafe对象基于物理内存地址进行数据读写]/非Unsafe[调用JDK的API进行读写],3.UnPooled[每次分配内存申请内存]/Pooled[预先分配好一整块内存,分配的时候用一定算法从一整块内存取出一块连续内存] 问:如何减少多线程内存分配之间的竞争?答:PooledByteBufAllocator内存分配器结构维护Arena数组,所有的内存分配都在Arena上进行,通过PoolThreadCache对象将线程和Arena进行一一绑定,默认情况一个Nio线程管理一个Arena实现多线程内存分配相互不受影响减少多线程内存分配之间的竞争 问:不同大小的内存是如何进行分配的?答:Page级别的内存分配通过完全二叉树的标记查找某一段连续内存,Page级别以下的内存分配首先查找到Page然后把此Page按照SubPage大小进行划分最后通过位图的方式进行内存分配 问:解码器抽象的解码过程?答:通过解码器ByteToMessageDecoder解码实现,ByteToMessageDecoder解码步骤:1.累加字节流:把当前读到的所有字节流累加到累加器里面,2.调用子类的decode()方法进行解析,ByteToMessageDecoder调用子类的decode()方法传参当前累加字节流和CodecOutputList,子类解码从字节流里面读取一段数据,解析出的数据包加到CodecOutputList,3.将解析到ByteBuf向下传播:CodecOutputList有解析出的数据包通过Pipeline事件传播机制往下传播 问:Netty里面有哪些拆箱即用的解码器? 答:基于固定长度解码器FixedLengthFrameDecoder[每次取固定长度的数据包,数据流长度足够截取一段数据包放到CodecOutputList],基于行解码器LineBasedFrameDecoder[\\n或者|r\\n为分隔符解码,丢弃/非丢弃模式处理和是/否找到分割符四个维度进行解码器的处理],基于分隔符解码器DelimiterBasedFrameDecoder[传参指定分隔符,找到分隔符使得本次解码出来的数据包长度最小,分隔符为\\n或者\\r\\n委托给基于行解码器LineBasedFrameDecoder],基于长度域解码器LengthFieldBasedFrameDecoder[计算需要抽取的数据包长度即本次需要从当前数据流里面截取数据长度,跳过字节逻辑处理,丢弃模式下的处理] 问:如何把对象变成字节流,最终写到Socket底层?答:BizHandler把自定义对象通过writeAndFlush()方法往前传播拆分成两个过程:1.write()方法通过Pipeline逐个ChannelHandler往前传播,传播到Encoder节点继承MessageToByteEncoder负责覆盖write()方法将自定义对象转换成ByteBuf,MessageToByteEncoder分配ByteBuffer调用encode()抽象方法由子类实现把自定义对象填充到ByteBuf继续调用write()方法将ByteBuf往前传播,默认情况无覆盖write()方法最终传播到head节点,head节点通过底层Unsafe把当前ByteBuf塞到Unsafe底层维护的outboundBuffer缓冲区对象并且计算ByteBuf超过最高水位设置当前通道不可写,write操作完成之后head节点底层维护的缓冲区里面对应ByteBuf链表;2.flush()方法从tail节点通过Pipeline逐个ChannelHandler往前传播,默认情况无覆盖flush()方法最终传播到head节点,head节点调用底层Unsafe把指针进行一系列调整通过循环不断往缓冲区里面获取ByteBuf转换成JDK底层的ByteBuffer对象使用JDK的Channel把ByteBuffer写到Socket删除节点,缓冲区里面当前可写字节小于最低水位改变Channel状态,最高水位64K/最低水位32K。","categories":[{"name":"网络编程","slug":"网络编程","permalink":"https://originer.github.io/Horizon.github.io/categories/网络编程/"}],"tags":[{"name":"Netty","slug":"Netty","permalink":"https://originer.github.io/Horizon.github.io/tags/Netty/"}]},{"title":"HashSet和HashMap源码研究","slug":"HashSet和HashMap","date":"2018-08-26T14:51:03.000Z","updated":"2018-08-26T14:51:03.000Z","comments":true,"path":"2018/08/26/HashSet和HashMap/","link":"","permalink":"https://originer.github.io/Horizon.github.io/2018/08/26/HashSet和HashMap/","excerpt":"HashSet and HashMap总体介绍原文github地址 之所以把HashSet和HashMap放在一起讲解，是因为二者在Java里有着相同的实现，前者仅仅是对后者做了一层包装，也就是说HashSet里面有一个HashMap（适配器模式）*。因此本文将重点分析HashMap*。","text":"HashSet and HashMap总体介绍原文github地址 之所以把HashSet和HashMap放在一起讲解，是因为二者在Java里有着相同的实现，前者仅仅是对后者做了一层包装，也就是说HashSet里面有一个HashMap（适配器模式）*。因此本文将重点分析HashMap*。 HashMap实现了Map接口，即允许放入key为null的元素，也允许插入value为null的元素；除该类未实现同步外，其余跟Hashtable大致相同；跟TreeMap不同，该容器不保证元素顺序，根据需要该容器可能会对元素重新哈希，元素的顺序也会被重新打散，因此不同时间迭代同一个HashMap的顺序可能会不同。根据对冲突的处理方式不同，哈希表有两种实现方式，一种开放地址方式（Open addressing），另一种是冲突链表方式（Separate chaining with linked lists）。Java HashMap采用的是冲突链表方式。 从上图容易看出，如果选择合适的哈希函数，put()和get()方法可以在常数时间内完成。但在对HashMap进行迭代时，需要遍历整个table以及后面跟的冲突链表。因此对于迭代比较频繁的场景，不宜将HashMap的初始大小设的过大。 有两个参数可以影响HashMap的性能：初始容量（inital capacity）和负载系数（load factor）。初始容量指定了初始table的大小，负载系数用来指定自动扩容的临界值。当entry的数量超过capacity*load_factor时，容器将自动扩容并重新哈希。对于插入元素较多的场景，将初始容量设大可以减少重新哈希的次数。 将对象放入到HashMap或HashSet中时，有两个方法需要特别关心：hashCode()和equals()。hashCode()方法决定了对象会被放到哪个bucket里，当多个对象的哈希值冲突时，equals()方法决定了这些对象是否是“同一个对象”。所以，如果要将自定义的对象放入到HashMap或HashSet中，需要@OverridehashCode()和equals()方法。 方法剖析get()get(Object key)方法根据指定的key值返回对应的value，该方法调用了getEntry(Object key)得到相应的entry，然后返回entry.getValue()。因此getEntry()是算法的核心。算法思想是首先通过hash()函数得到对应bucket的下标，然后依次遍历冲突链表，通过key.equals(k)方法来判断是否是要找的那个entry。上图中hash(k)&amp;(table.length-1)等价于hash(k)%table.length，原因是HashMap要求table.length必须是2的指数，因此table.length-1就是二进制低位全是1，跟hash(k)相与会将哈希值的高位全抹掉，剩下的就是余数了。 1234567891011121314//getEntry()方法final Entry&lt;K,V&gt; getEntry(Object key) &#123; ...... int hash = (key == null) ? 0 : hash(key); for (Entry&lt;K,V&gt; e = table[hash&amp;(table.length-1)];//得到冲突链表 e != null; e = e.next) &#123;//依次遍历冲突链表中的每个entry Object k; //依据equals()方法判断是否相等 if (e.hash == hash &amp;&amp; ((k = e.key) == key || (key != null &amp;&amp; key.equals(k)))) return e; &#125; return null;&#125; put()put(K key, V value)方法是将指定的key, value对添加到map里。该方法首先会对map做一次查找，看是否包含该元组，如果已经包含则直接返回，查找过程类似于getEntry()方法；如果没有找到，则会通过addEntry(int hash, K key, V value, int bucketIndex)方法插入新的entry，插入方式为头插法。 123456789101112//addEntry()void addEntry(int hash, K key, V value, int bucketIndex) &#123; if ((size &gt;= threshold) &amp;&amp; (null != table[bucketIndex])) &#123; resize(2 * table.length);//自动扩容，并重新哈希 hash = (null != key) ? hash(key) : 0; bucketIndex = hash &amp; (table.length-1);//hash%table.length &#125; //在冲突链表头部插入新的entry Entry&lt;K,V&gt; e = table[bucketIndex]; table[bucketIndex] = new Entry&lt;&gt;(hash, key, value, e); size++;&#125; remove()remove(Object key)的作用是删除key值对应的entry，该方法的具体逻辑是在removeEntryForKey(Object key)里实现的。removeEntryForKey()方法会首先找到key值对应的entry，然后删除该entry（修改链表的相应引用）。查找过程跟getEntry()过程类似。 123456789101112131415161718192021//removeEntryForKey()final Entry&lt;K,V&gt; removeEntryForKey(Object key) &#123; ...... int hash = (key == null) ? 0 : hash(key); int i = indexFor(hash, table.length);//hash&amp;(table.length-1) Entry&lt;K,V&gt; prev = table[i];//得到冲突链表 Entry&lt;K,V&gt; e = prev; while (e != null) &#123;//遍历冲突链表 Entry&lt;K,V&gt; next = e.next; Object k; if (e.hash == hash &amp;&amp; ((k = e.key) == key || (key != null &amp;&amp; key.equals(k)))) &#123;//找到要删除的entry modCount++; size--; if (prev == e) table[i] = next;//删除的是冲突链表的第一个entry else prev.next = next; return e; &#125; prev = e; e = next; &#125; return e;&#125; HashMap总结HashMap的bucket的一个数组，数据通过key的hash散列到数组上，所以如果没有Hash冲突的话，理论上我们使用get()获取数据的操作的时间复杂度是O(1),这就是HashMap高效的原因。JDK8以后对HashMap进行了优化，原先的Entry结构被替换成了Node,在一个节点链表的数据如果超过八个会被转换为红黑树。 HashSet前面已经说过HashSet是对HashMap的简单包装，对HashSet的函数调用都会转换成合适的HashMap方法，因此HashSet的实现非常简单，只有不到300行代码。这里不再赘述。 12345678910111213141516//HashSet是对HashMap的简单包装public class HashSet&lt;E&gt;&#123; ...... private transient HashMap&lt;E,Object&gt; map;//HashSet里面有一个HashMap // Dummy value to associate with an Object in the backing Map private static final Object PRESENT = new Object(); public HashSet() &#123; map = new HashMap&lt;&gt;(); &#125; ...... public boolean add(E e) &#123;//简单的方法转换 return map.put(e, PRESENT)==null; &#125; ......&#125; HashSet是如何保证数据不重复的以下代码为JDK8+的实现版本 123public boolean add(E e) &#123; return map.put(e, PRESENT)==null;&#125; 可以看出，HashSet的内部实际上就是封装了HashMap的操作。 123public V put(K key, V value) &#123; return putVal(hash(key), key, value, false, true);&#125; 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152/** * Implements Map.put and related methods * * @param hash hash for key * @param key the key * @param value the value to put * @param onlyIfAbsent if true, don't change existing value * @param evict if false, the table is in creation mode. * @return previous value, or null if none */final V putVal(int hash, K key, V value, boolean onlyIfAbsent, boolean evict) &#123; Node&lt;K,V&gt;[] tab; Node&lt;K,V&gt; p; int n, i; if ((tab = table) == null || (n = tab.length) == 0) n = (tab = resize()).length; if ((p = tab[i = (n - 1) &amp; hash]) == null) tab[i] = newNode(hash, key, value, null); else &#123; Node&lt;K,V&gt; e; K k; if (p.hash == hash &amp;&amp; ((k = p.key) == key || (key != null &amp;&amp; key.equals(k)))) e = p; else if (p instanceof TreeNode) e = ((TreeNode&lt;K,V&gt;)p).putTreeVal(this, tab, hash, key, value); else &#123; for (int binCount = 0; ; ++binCount) &#123; if ((e = p.next) == null) &#123; p.next = newNode(hash, key, value, null); if (binCount &gt;= TREEIFY_THRESHOLD - 1) // -1 for 1st treeifyBin(tab, hash); break; &#125; if (e.hash == hash &amp;&amp; ((k = e.key) == key || (key != null &amp;&amp; key.equals(k)))) break; p = e; &#125; &#125; if (e != null) &#123; // existing mapping for key V oldValue = e.value; if (!onlyIfAbsent || oldValue == null) e.value = value; afterNodeAccess(e); return oldValue; &#125; &#125; ++modCount; if (++size &gt; threshold) resize(); afterNodeInsertion(evict); return null;&#125; 12// Dummy value to associate with an Object in the backing Mapprivate static final Object PRESENT = new Object(); 重要的是下面的两个参数，onlyIfAbsent和evict，这两个参数的默认值是false和true。也就是说，在HashMap中，如果key值相同且value也相同的时候[equals和hash值都相等]，默认是不进行替换操作的。HashSet利用了HashMap的这一特性，把我们要存的值做为key，把PRESENT对象作为value，那么key值相同的话就不会进行替换操作，value值是没意义的相同对象。实现了HashSet中无重复对象的效果。 @param onlyIfAbsent if true, don’t change existing value @param evict if false, the table is in creation mode.","categories":[{"name":"Java集合框架","slug":"Java集合框架","permalink":"https://originer.github.io/Horizon.github.io/categories/Java集合框架/"}],"tags":[{"name":"Java集合框架","slug":"Java集合框架","permalink":"https://originer.github.io/Horizon.github.io/tags/Java集合框架/"}]},{"title":"总结使用 IDEA 部署web工程到 Tomcat 遇到的一些问题","slug":"IDEA部署tomcat","date":"2018-08-26T11:41:20.000Z","updated":"2018-08-26T11:41:20.000Z","comments":true,"path":"2018/08/26/IDEA部署tomcat/","link":"","permalink":"https://originer.github.io/Horizon.github.io/2018/08/26/IDEA部署tomcat/","excerpt":"war 和 war exploded的区别 war模式：将WEB工程以包的形式上传到服务器 ;war exploded模式：将WEB工程以当前文件夹的位置关系上传到服务器 ; （1）war模式这种可以称之为是发布模式，看名字也知道，这是先打成war包，再发布； （2）war exploded模式是直接把文件夹、jsp页面 、classes等等移到Tomcat 部署文件夹里面，进行加载部署。因此这种方式支持热部署，一般在开发的时候也是用这种方式。 （3）在平时开发的时候，使用热部署的话，应该对Tomcat进行相应的设置，这样的话修改的jsp界面什么的东西才可以及时的显示出来。","text":"war 和 war exploded的区别 war模式：将WEB工程以包的形式上传到服务器 ;war exploded模式：将WEB工程以当前文件夹的位置关系上传到服务器 ; （1）war模式这种可以称之为是发布模式，看名字也知道，这是先打成war包，再发布； （2）war exploded模式是直接把文件夹、jsp页面 、classes等等移到Tomcat 部署文件夹里面，进行加载部署。因此这种方式支持热部署，一般在开发的时候也是用这种方式。 （3）在平时开发的时候，使用热部署的话，应该对Tomcat进行相应的设置，这样的话修改的jsp界面什么的东西才可以及时的显示出来。 注意： String contextPath = request.getSession().getServletContext().getRealPath(“/“); war模式下获取的是Tomcat所在的位置; war exploded模式下获取的是项目target的位置; 热加载问题war 模式部署: on ‘update‘ action：当用户主动执行更新的时候更新 快捷键:Ctrl + F9 on frame deactication:在编辑窗口失去焦点的时候更新 war exploeded 模式部署:如果你的工程中没有 Update classes and resources 这个选项，在这种情况下你更新后只能更新classes文件中的变动，并不能更新静态文件中的变动。 总结：在开发模式中一般选择war exploeded模式部署,但是要注意动态获取静态资源路径的问题 为何Tomcat路径下找不到部署的war包首先，需要了解一下IDEA启动Tomcat的过程： 1234567[2018-01-13 02:20:44,325] Artifact mmall:war: Waiting for server connection to start artifact deployment...Using CATALINA_2_BASE: &quot;G:\\tomcat2&quot;Using CATALINA_2_HOME: &quot;G:\\tomcat2&quot;Using CATALINA_TMPDIR: &quot;G:\\tomcat2\\temp&quot;Using JRE_HOME: &quot;F:\\jdk1.7.0_80&quot;Using CLASSPATH: &quot;G:\\tomcat2\\bin\\bootstrap.jar;G:\\tomcat2\\bin\\tomcat-juli.jar&quot;Connected to the target VM, address: &apos;127.0.0.1:12217&apos;, transport: &apos;socket&apos; 配置 CATALINA_BASE 启动 Tomcat idea 在启动 tomcat 的时候通过 CATALINA_BASE 修改了logs、conf和work的配置，webapps没动，如果没配置子域名就会自动覆盖原有的ROOT项目 总结: CATALINA_HOME就是你的Tomcat安装的位置，CATALINA_BASE就是你的这个实例的位置，默认的话这两个值是一样的。 IDEA启动时改变了CATALINA_BASE的设置,所以跑起来的实例的位置就不在Tomcat的路径下了,但是启动的其实还是原来的Tomcat; 有些项目获取静态资源文件的路径是从tomcat的webapps下面找的，如果找不到可以自己手动配置项目的输出路径，把项目输出到tomcat的webapps下面。","categories":[{"name":"工具","slug":"工具","permalink":"https://originer.github.io/Horizon.github.io/categories/工具/"}],"tags":[]},{"title":"Java设计模式：策略模式","slug":"设计模式：策略模式","date":"2018-08-26T11:03:58.000Z","updated":"2018-08-26T11:03:58.000Z","comments":true,"path":"2018/08/26/设计模式：策略模式/","link":"","permalink":"https://originer.github.io/Horizon.github.io/2018/08/26/设计模式：策略模式/","excerpt":"策略模式是一种简单且实用的设计模式。在处理的事情的流程都差不多，只是具体细节不同的时候我们就可以使用策略模式来减少代码的耦合性。 策略模式说明策略模式属于对象的行为模式。其用意是针对一组算法，将每一个算法封装到具有共同接口的独立的类中，从而使得它们可以相互替换。策略模式使得算法可以在不影响到客户端的情况下发生变化。 策略模式涉及的主要角色● 环境(Context)角色：持有一个Strategy的引用。 ● 抽象策略(Strategy)角色：这是一个抽象角色，通常由一个接口或抽象类实现。此角色给出所有的具体策略类所需接口。 ● 具体策略(ConcreteStrategy)角色：包装了相关的算法或行为。","text":"策略模式是一种简单且实用的设计模式。在处理的事情的流程都差不多，只是具体细节不同的时候我们就可以使用策略模式来减少代码的耦合性。 策略模式说明策略模式属于对象的行为模式。其用意是针对一组算法，将每一个算法封装到具有共同接口的独立的类中，从而使得它们可以相互替换。策略模式使得算法可以在不影响到客户端的情况下发生变化。 策略模式涉及的主要角色● 环境(Context)角色：持有一个Strategy的引用。 ● 抽象策略(Strategy)角色：这是一个抽象角色，通常由一个接口或抽象类实现。此角色给出所有的具体策略类所需接口。 ● 具体策略(ConcreteStrategy)角色：包装了相关的算法或行为。 代码演示比如下面代码，我们可以通过自己的策略来选择内存缓存和redis缓存，在实际项目中，这种写代码的方式很常见。 12345678910111213141516171819202122232425262728293031public class Strategy &#123; private Cache cacheMemory = new CacheMemoryImpl(); private Cache cacheRedis = new CacheRedisImpl(); public interface Cache &#123; boolean add(String key, Object object); &#125; public class CacheMemoryImpl implements Cache &#123; @Override public boolean add(String key, Object object) &#123; // 保存到map return false; &#125; &#125; public class CacheRedisImpl implements Cache &#123; @Override public boolean add(String key, Object object) &#123; // 保存到redis return false; &#125; &#125; public Cache getCache(String key) &#123; if (key.length() &lt; 10) &#123; return cacheRedis; &#125; return cacheMemory; &#125;&#125; 在Netty中，EventExecutorChooser就是根据策略生成的： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748public final class DefaultEventExecutorChooserFactory implements EventExecutorChooserFactory &#123; public static final DefaultEventExecutorChooserFactory INSTANCE = new DefaultEventExecutorChooserFactory(); private DefaultEventExecutorChooserFactory() &#123; &#125; @SuppressWarnings(\"unchecked\") @Override public EventExecutorChooser newChooser(EventExecutor[] executors) &#123; if (isPowerOfTwo(executors.length)) &#123; return new PowerOfTowEventExecutorChooser(executors); &#125; else &#123; return new GenericEventExecutorChooser(executors); &#125; &#125; private static boolean isPowerOfTwo(int val) &#123; return (val &amp; -val) == val; &#125; private static final class PowerOfTowEventExecutorChooser implements EventExecutorChooser &#123; private final AtomicInteger idx = new AtomicInteger(); private final EventExecutor[] executors; PowerOfTowEventExecutorChooser(EventExecutor[] executors) &#123; this.executors = executors; &#125; @Override public EventExecutor next() &#123; return executors[idx.getAndIncrement() &amp; executors.length - 1]; &#125; &#125; private static final class GenericEventExecutorChooser implements EventExecutorChooser &#123; private final AtomicInteger idx = new AtomicInteger(); private final EventExecutor[] executors; GenericEventExecutorChooser(EventExecutor[] executors) &#123; this.executors = executors; &#125; @Override public EventExecutor next() &#123; return executors[Math.abs(idx.getAndIncrement() % executors.length)]; &#125; &#125;&#125; 策略模式的优点 （1）策略模式提供了管理相关的算法族的办法。策略类的等级结构定义了一个算法或行为族。恰当使用继承可以把公共的代码移到父类里面，从而避免代码重复。 （2）使用策略模式可以避免使用多重条件(if-else)语句。多重条件语句不易维护，它把采取哪一种算法或采取哪一种行为的逻辑与算法或行为的逻辑混合在一起，统统列在一个多重条件语句里面，比使用继承的办法还要原始和落后。 策略模式的缺点 （1）客户端必须知道所有的策略类，并自行决定使用哪一个策略类。这就意味着客户端必须理解这些算法的区别，以便适时选择恰当的算法类。换言之，策略模式只适用于客户端知道算法或行为的情况。 （2）由于策略模式把每个具体的策略实现都单独封装成为类，如果备选的策略很多的话，那么对象的数目就会很可观。","categories":[{"name":"策略模式","slug":"策略模式","permalink":"https://originer.github.io/Horizon.github.io/categories/策略模式/"}],"tags":[{"name":"策略模式","slug":"策略模式","permalink":"https://originer.github.io/Horizon.github.io/tags/策略模式/"}]},{"title":"Spring IOC学习笔记","slug":"Spring IoC学习笔记","date":"2018-08-03T11:11:31.000Z","updated":"2018-12-02T06:33:56.254Z","comments":true,"path":"2018/08/03/Spring IoC学习笔记/","link":"","permalink":"https://originer.github.io/Horizon.github.io/2018/08/03/Spring IoC学习笔记/","excerpt":"IOC 控制反转，又称依赖注入，是Spring框架的核心功能。通过依赖反转可以大大降低系统的耦合性。 注入方式接口注入 setter注入 构造器注入 核心类：BeanFactory、ApplicationContextBeanFactory","text":"IOC 控制反转，又称依赖注入，是Spring框架的核心功能。通过依赖反转可以大大降低系统的耦合性。 注入方式接口注入 setter注入 构造器注入 核心类：BeanFactory、ApplicationContextBeanFactory BeanFactory定义了IOC容器的基本框架，Spring的其他IOC容器基本都是继承这个类进行扩展的。 与FactoryBean的区别：BeanFactory是负责管理Bean的,FactoryBean是负责创建Bean的。 ApplicationContext 可以看出，ApplicationContext就是对BeanFactory进行了扩充，这是比较常用的一个IOC容器。 IOC容器初始化 核心方法：refresh() 在这个方法中进行容器的初始化各种准备操作 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152public void refresh() throws BeansException, IllegalStateException &#123; synchronized (this.startupShutdownMonitor) &#123; //准备此上下文以进行刷新 prepareRefresh(); // 告诉子类刷新内部bean工厂。 ConfigurableListableBeanFactory beanFactory = obtainFreshBeanFactory(); // 准备bean工厂以在此上下文中使用。 prepareBeanFactory(beanFactory); try &#123; //允许在上下文子类中对bean工厂进行后处理。 postProcessBeanFactory(beanFactory); // 在上下文中调用注册为bean的工厂处理器。 invokeBeanFactoryPostProcessors(beanFactory); // 注册拦截bean创建的bean处理器。 registerBeanPostProcessors(beanFactory); // Initialize message source for this context. initMessageSource(); // Initialize event multicaster for this context. initApplicationEventMulticaster(); // Initialize other special beans in specific context subclasses. onRefresh(); // Check for listener beans and register them. registerListeners(); // Instantiate all remaining (non-lazy-init) singletons. finishBeanFactoryInitialization(beanFactory); // Last step: publish corresponding event. finishRefresh(); &#125; catch (BeansException ex) &#123; // Destroy already created singletons to avoid dangling resources. destroyBeans(); // Reset 'active' flag. cancelRefresh(ex); // Propagate exception to caller. throw ex; &#125; &#125;&#125; 初始化过程： Resource定位 BeanDefinition加载 向IOC容器中注入BeanDefinition 初始化时一般不会进行依赖注入，依赖注入发生在第一次调用getBean()方法的时候。 在DefaultListableBeanFactory中，有一个用来保存beanDefinition的HashMap 1private final Map&lt;String, BeanDefinition&gt; beanDefinitionMap = new ConcurrentHashMap&lt;String, BeanDefinition&gt;(64); BeanFactory与ApplicationContext的区别 IOC容器的依赖注入依赖注入依赖注入由getBean()方法触发 AbstractBeanFactory： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109protected &lt;T&gt; T doGetBean(String name, Class&lt;T&gt; requiredType, final Object[] args, boolean typeCheckOnly) throws BeansException &#123; final String beanName = this.transformedBeanName(name); Object sharedInstance = this.getSingleton(beanName); Object bean; // 1. 先判断缓存中有没有，有的话从缓存中返回 if (sharedInstance != null &amp;&amp; args == null) &#123; if (this.logger.isDebugEnabled()) &#123; if (this.isSingletonCurrentlyInCreation(beanName)) &#123; this.logger.debug(\"Returning eagerly cached instance of singleton bean '\" + beanName + \"' that is not fully initialized yet - a consequence of a circular reference\"); &#125; else &#123; this.logger.debug(\"Returning cached instance of singleton bean '\" + beanName + \"'\"); &#125; &#125; bean = this.getObjectForBeanInstance(sharedInstance, name, beanName, (RootBeanDefinition)null); &#125; else &#123; //2. 判断是否在当前BeanFactory中，如果不在就顺着双亲链一直向上找 if (this.isPrototypeCurrentlyInCreation(beanName)) &#123; throw new BeanCurrentlyInCreationException(beanName); &#125; BeanFactory parentBeanFactory = this.getParentBeanFactory(); if (parentBeanFactory != null &amp;&amp; !this.containsBeanDefinition(beanName)) &#123; String nameToLookup = this.originalBeanName(name); if (args != null) &#123; return parentBeanFactory.getBean(nameToLookup, args); &#125; return parentBeanFactory.getBean(nameToLookup, requiredType); &#125; if (!typeCheckOnly) &#123; this.markBeanAsCreated(beanName); &#125; //3.根据BeanName获取这个Bean的BeanDefinition，然后获取这个Bean的所有依赖 final RootBeanDefinition mbd = this.getMergedLocalBeanDefinition(beanName); this.checkMergedBeanDefinition(mbd, beanName, args); String[] dependsOn = mbd.getDependsOn(); String scopeName; if (dependsOn != null) &#123; String[] var14 = dependsOn; int var13 = dependsOn.length; //4. 如果存在依赖的Bean就递归调用getBean() for(int var12 = 0; var12 &lt; var13; ++var12) &#123; scopeName = var14[var12]; this.getBean(scopeName); this.registerDependentBean(scopeName, beanName); &#125; &#125; //5.创建Bean的单例对象，然后设置作用域 if (mbd.isSingleton()) &#123; sharedInstance = this.getSingleton(beanName, new ObjectFactory() &#123; public Object getObject() throws BeansException &#123; try &#123; return AbstractBeanFactory.this.createBean(beanName, mbd, args); &#125; catch (BeansException var2) &#123; AbstractBeanFactory.this.destroySingleton(beanName); throw var2; &#125; &#125; &#125;); bean = this.getObjectForBeanInstance(sharedInstance, name, beanName, mbd); &#125; else if (mbd.isPrototype()) &#123; scopeName = null; Object prototypeInstance; try &#123; this.beforePrototypeCreation(beanName); prototypeInstance = this.createBean(beanName, mbd, args); &#125; finally &#123; this.afterPrototypeCreation(beanName); &#125; bean = this.getObjectForBeanInstance(prototypeInstance, name, beanName, mbd); &#125; else &#123; scopeName = mbd.getScope(); Scope scope = (Scope)this.scopes.get(scopeName); if (scope == null) &#123; throw new IllegalStateException(\"No Scope registered for scope '\" + scopeName + \"'\"); &#125; try &#123; Object scopedInstance = scope.get(beanName, new ObjectFactory() &#123; public Object getObject() throws BeansException &#123; AbstractBeanFactory.this.beforePrototypeCreation(beanName); Object var2; try &#123; var2 = AbstractBeanFactory.this.createBean(beanName, mbd, args); &#125; finally &#123; AbstractBeanFactory.this.afterPrototypeCreation(beanName); &#125; return var2; &#125; &#125;); bean = this.getObjectForBeanInstance(scopedInstance, name, beanName, mbd); &#125; catch (IllegalStateException var18) &#123; throw new BeanCreationException(beanName, \"Scope '\" + scopeName + \"' is not active for the current thread; \" + \"consider defining a scoped proxy for this bean if you intend to refer to it from a singleton\", var18); &#125; &#125; &#125;//6.对Bean进行相关的类型检查 if (requiredType != null &amp;&amp; bean != null &amp;&amp; !requiredType.isAssignableFrom(bean.getClass())) &#123; throw new BeanNotOfRequiredTypeException(name, requiredType, bean.getClass()); &#125; else &#123; return bean; &#125;&#125; Bean实例化Bean实例化 AbstractAutowireCapableBeanFactory： 123456789101112131415161718192021222324252627282930313233343536protected Object createBean(final String beanName, final RootBeanDefinition mbd, final Object[] args) throws BeanCreationException &#123; if (logger.isDebugEnabled()) &#123; logger.debug(\"Creating instance of bean '\" + beanName + \"'\"); &#125; // Make sure bean class is actually resolved at this point. resolveBeanClass(mbd, beanName); // Prepare method overrides. try &#123; mbd.prepareMethodOverrides(); &#125; catch (BeanDefinitionValidationException ex) &#123; throw new BeanDefinitionStoreException(mbd.getResourceDescription(), beanName, \"Validation of method overrides failed\", ex); &#125; try &#123; // Give BeanPostProcessors a chance to return a proxy instead of the target bean instance. Object bean = resolveBeforeInstantiation(beanName, mbd); if (bean != null) &#123; return bean; &#125; &#125; catch (Throwable ex) &#123; throw new BeanCreationException(mbd.getResourceDescription(), beanName, \"BeanPostProcessor before instantiation of bean failed\", ex); &#125; Object beanInstance = doCreateBean(beanName, mbd, args); if (logger.isDebugEnabled()) &#123; logger.debug(\"Finished creating instance of bean '\" + beanName + \"'\"); &#125; return beanInstance;&#125;","categories":[{"name":"Spring","slug":"Spring","permalink":"https://originer.github.io/Horizon.github.io/categories/Spring/"}],"tags":[{"name":"Spring","slug":"Spring","permalink":"https://originer.github.io/Horizon.github.io/tags/Spring/"}]},{"title":"记录一些Redis在分布式环境下的实践遇到的问题","slug":"redis问题","date":"2018-08-03T02:25:29.000Z","updated":"2018-08-03T02:25:29.000Z","comments":true,"path":"2018/08/03/redis问题/","link":"","permalink":"https://originer.github.io/Horizon.github.io/2018/08/03/redis问题/","excerpt":"利用redis实现分布式集群的单点登陆功能;session作为一般的登陆凭证，在集群环境下会遇到一些问题： 1、如果服务器分布在多个Tomcat服务器上，那么用户每次登陆都未必访问同一个服务器。 2、如果Tomcat服务器挂掉，用户也会受到影响。 所以就想出以下解决方案：使用一个Redis服务器用来解决用户的单点登陆问题。这样，无论用户被负载均衡到哪个Tomcat服务器都可以通过redis服务器验证身份； 但是又会产生一个新的问题，如果一个redis服务器不够用怎么办? 很自然的能够想到添加redis服务器的解决方案，但是在增加redis服务器时遇到 了一些疑惑，以下作为记录：","text":"利用redis实现分布式集群的单点登陆功能;session作为一般的登陆凭证，在集群环境下会遇到一些问题： 1、如果服务器分布在多个Tomcat服务器上，那么用户每次登陆都未必访问同一个服务器。 2、如果Tomcat服务器挂掉，用户也会受到影响。 所以就想出以下解决方案：使用一个Redis服务器用来解决用户的单点登陆问题。这样，无论用户被负载均衡到哪个Tomcat服务器都可以通过redis服务器验证身份； 但是又会产生一个新的问题，如果一个redis服务器不够用怎么办? 很自然的能够想到添加redis服务器的解决方案，但是在增加redis服务器时遇到 了一些疑惑，以下作为记录： ShardedJedisShardedJedis是通过一致性哈希来实现分布式缓存的，通过一定的策略把不同的key分配到不同的redis server上，达到横向扩展的目的； ShardedJedis的使用方法除了配置时有点区别，其他和Jedis基本类似，有一点要注意的是 ShardedJedis不支持多命令操作，像mget、mset、brpop等可以在redis命令后一次性操作多个key的命令，具体包括哪些，大家可以看Jedis下的 MultiKeyCommands 这个类，这里面就包含了所有的多命令操作。很贴心的是，Redis作者已经把这些命令从ShardedJedis过滤掉了; 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475/** * @author Zz **/public class RedisShardedPool &#123; public static ShardedJedisPool pool;//sharded jedis连接池 private static Integer maxTotal = Integer.parseInt(PropertiesUtil.getProperty(\"redis.max.total\", \"20\")); //最大连接数 private static Integer maxIdle = Integer.parseInt(PropertiesUtil.getProperty(\"redis.max.idle\", \"10\")); //在jedispool中最大的idle状态的（空闲的）jedis实例个数 private static Integer minIdle = Integer.parseInt(PropertiesUtil.getProperty(\"redis.min.idle\", \"2\")); //在jedispool中最小的idle状态的（空闲的）jedis实例个数 private static Boolean testOnBorrow = Boolean.parseBoolean(PropertiesUtil.getProperty(\"redis.test.borrow\", \"true\")); //在borrow一个jedis实例的时候，是否要进行验证操作，如果赋值true，则得到的jedis实例是可用的 private static Boolean testOnReturn = Boolean.parseBoolean(PropertiesUtil.getProperty(\"redis.test.return\", \"true\")); //在return一个jedis实例的时候，是否要进行验证操作，如果赋值true，则返回成功 private static String redis1Ip = PropertiesUtil.getProperty(\"redis1.ip\"); private static Integer redis1Port = Integer.parseInt(PropertiesUtil.getProperty(\"redis1.port\")); private static String redis2Ip = PropertiesUtil.getProperty(\"redis2.ip\"); private static Integer redis2Port = Integer.parseInt(PropertiesUtil.getProperty(\"redis2.port\")); private static void initPool() &#123; JedisPoolConfig config = new JedisPoolConfig(); config.setMaxIdle(maxTotal); config.setMaxIdle(maxIdle); config.setMinIdle(minIdle); config.setTestOnBorrow(testOnBorrow); config.setTestOnReturn(testOnReturn); config.setBlockWhenExhausted(true);//连接耗尽时是否阻塞，false会抛出异常，true阻塞直到超时// pool = new JedisPool(config, redisIp, redisPort, 1000 * 2); JedisShardInfo info1 = new JedisShardInfo(redis1Ip, redis1Port, 1000 * 2); JedisShardInfo info2 = new JedisShardInfo(redis2Ip, redis2Port, 1000 * 2); List&lt;JedisShardInfo&gt; jedisShardInfos = new ArrayList&lt;&gt;(2); jedisShardInfos.add(info1); jedisShardInfos.add(info2); pool = new ShardedJedisPool(config, jedisShardInfos, Hashing.MURMUR_HASH, Sharded.DEFAULT_KEY_TAG_PATTERN); &#125; //静态加载 static &#123; initPool(); &#125; public static ShardedJedis getJedis() &#123; return pool.getResource(); &#125; public static void returnResource(ShardedJedis jedis) &#123; pool.returnResource(jedis); &#125; public static void returnBrokeResource(ShardedJedis jedis) &#123; pool.returnBrokenResource(jedis); &#125; public static void main(String[] args) &#123; ShardedJedis shardedJedis = pool.getResource(); for (int i = 0; i &lt; 10; i++) &#123; shardedJedis.set(\"key\" + i, \"value\" + i); &#125; for (int i = 0; i &lt; 10; i++) &#123; System.out.println(shardedJedis.get(\"key\" + i)); &#125; returnResource(shardedJedis); &#125;&#125; 一致性哈希实现分布式缓存ShardedJedis通过一致性哈希实现的的分布式缓存。主要思路： 1、redis服务器节点划分：将每台服务器节点采用hash算法划分为160个虚拟节点(可以配置划分权重)，将划分虚拟节点采用TreeMap存储2、对每个redis服务器的物理连接采用LinkedHashMap存储3、对Key or KeyTag 采用同样的hash算法，然后从TreeMap获取大于等于键hash值得节点，取最邻近节点存储；当key的hash值大于虚拟节点hash值得最大值时，存入第一个虚拟节点 sharded采用的hash算法：MD5 和 MurmurHash两种；默认采用64位的MurmurHash算法； 我们追踪 shardedJedis.get() 进行分析： 1234public String get(String key) &#123;Jedis j = getShard(key);return j.get(key); &#125; 123 public R getShard(String key) &#123;return resources.get(getShardInfo(key)); &#125; 123 public S getShardInfo(String key) &#123;return getShardInfo(SafeEncoder.encode(getKeyTag(key))); &#125; 12345678910111213/** * 通过key 获取分片。对key 也使用algo hash 算法，从虚拟节点（nodes）中取键值大于等于key hash后的值。 * 如果没有大于等于key hash后的值，那么取第一个node。 * 如果有则取当前映射的第一个node **/public S getShardInfo(byte[] key) &#123; SortedMap&lt;Long, S&gt; tail = nodes.tailMap(algo.hash(key)); if (tail.isEmpty()) &#123; return nodes.get(nodes.firstKey()); &#125; return tail.get(tail.firstKey());&#125;","categories":[{"name":"redis","slug":"redis","permalink":"https://originer.github.io/Horizon.github.io/categories/redis/"}],"tags":[]},{"title":"SpringMVC完成一次Http请求的过程","slug":"SpringMVC如何完成一次Http请求","date":"2018-08-02T11:05:39.000Z","updated":"2018-12-02T06:34:33.864Z","comments":true,"path":"2018/08/02/SpringMVC如何完成一次Http请求/","link":"","permalink":"https://originer.github.io/Horizon.github.io/2018/08/02/SpringMVC如何完成一次Http请求/","excerpt":"Spring MVC 是一个十分优秀的框架，由于其易用性，甚至使用者都不需要了解它的内部工作原理就可以用来做日常开发。不过如果能从源码上了解它的工作方式，那不仅能让我们对它理解更加透彻，还能学习到它的优秀的编码思想。本篇为个人阅读源码的笔记。 SpringMVC 工作流程","text":"Spring MVC 是一个十分优秀的框架，由于其易用性，甚至使用者都不需要了解它的内部工作原理就可以用来做日常开发。不过如果能从源码上了解它的工作方式，那不仅能让我们对它理解更加透彻，还能学习到它的优秀的编码思想。本篇为个人阅读源码的笔记。 SpringMVC 工作流程 处理请求的过程SpringMVC 3.0.1 DispatcherServlet是SpringMVC框架最核心的Servlet，从它的名字中可以大概猜出它是一个负责接收并分发请求的Servlet。SpringMVC官方将它解释为中央调度器。 FrameworkServlet从图中可以看出，SpringMVC把HttpServlet封装成了一个FrameServlet，在FrameServlet中，所有的请求都被交给processRequest(request, response)方法来处理，我们可以看一下FrameServlet的源码： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970@Overrideprotected final void doGet(HttpServletRequest request, HttpServletResponse response) throws ServletException, IOException &#123; processRequest(request, response);&#125;@Overrideprotected final void doPost(HttpServletRequest request, HttpServletResponse response) throws ServletException, IOException &#123; processRequest(request, response);&#125;...//1.所有类型的请求都被转给这个方法处理protected final void processRequest(HttpServletRequest request, HttpServletResponse response) throws ServletException, IOException &#123; long startTime = System.currentTimeMillis(); Throwable failureCause = null; //2.得到与当前请求绑定的LocaleContext、ServletRequestAttributes对象，然后与request绑定构造新的对象。 LocaleContext previousLocaleContext = LocaleContextHolder.getLocaleContext(); LocaleContext localeContext = buildLocaleContext(request); RequestAttributes previousAttributes = RequestContextHolder.getRequestAttributes(); ServletRequestAttributes requestAttributes = buildRequestAttributes(request, response, previousAttributes); WebAsyncManager asyncManager = WebAsyncUtils.getAsyncManager(request); asyncManager.registerCallableInterceptor(FrameworkServlet.class.getName(), new RequestBindingInterceptor());//3.把上面构造的对象与当前线程绑定 initContextHolders(request, localeContext, requestAttributes);//4.doService是由DispatcherServlet实现的。 try &#123; doService(request, response); &#125; catch (ServletException | IOException ex) &#123; failureCause = ex; throw ex; &#125; catch (Throwable ex) &#123; failureCause = ex; throw new NestedServletException(\"Request processing failed\", ex); &#125; finally &#123; //5.doService执行完后重置LocaleContext、RequestAttributes，也就是解除绑定。 resetContextHolders(request, previousLocaleContext, previousAttributes); if (requestAttributes != null) &#123; requestAttributes.requestCompleted(); &#125; if (logger.isDebugEnabled()) &#123; if (failureCause != null) &#123; this.logger.debug(\"Could not complete request\", failureCause); &#125; else &#123; if (asyncManager.isConcurrentHandlingStarted()) &#123; logger.debug(\"Leaving response open for concurrent processing\"); &#125; else &#123; this.logger.debug(\"Successfully completed request\"); &#125; &#125; &#125; publishRequestHandledEvent(request, response, startTime, failureCause); &#125; &#125; 上面的代码大致逻辑就是创建了上下文环境，然后把请求由doService交给DispatcherServlet。 DispatcherServletDispatcherServlet中的重要方法： doService doDispatch 各种初始化方法 doService首先，请求会由FrameServlet被委托给DispatcherServlet的doService方法： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051@Overrideprotected void doService(HttpServletRequest request, HttpServletResponse response) throws Exception &#123; if (logger.isDebugEnabled()) &#123; String resumed = WebAsyncUtils.getAsyncManager(request).hasConcurrentResult() ? \" resumed\" : \"\"; logger.debug(\"DispatcherServlet with name '\" + getServletName() + \"'\" + resumed + \" processing \" + request.getMethod() + \" request for [\" + getRequestUri(request) + \"]\"); &#125; // Keep a snapshot of the request attributes in case of an include, // to be able to restore the original attributes after the include. Map&lt;String, Object&gt; attributesSnapshot = null; if (WebUtils.isIncludeRequest(request)) &#123; attributesSnapshot = new HashMap&lt;String, Object&gt;(); Enumeration&lt;?&gt; attrNames = request.getAttributeNames(); while (attrNames.hasMoreElements()) &#123; String attrName = (String) attrNames.nextElement(); if (this.cleanupAfterInclude || attrName.startsWith(\"org.springframework.web.servlet\")) &#123; attributesSnapshot.put(attrName, request.getAttribute(attrName)); &#125; &#125; &#125; // 1、提供框架对象处理程序和视图对象。(也就是Spring MVC中特殊的几个bean) request.setAttribute(WEB_APPLICATION_CONTEXT_ATTRIBUTE, getWebApplicationContext()); // 2、spring mvc支持i18n request.setAttribute(LOCALE_RESOLVER_ATTRIBUTE, this.localeResolver); // 3、spring mvc支持主题 request.setAttribute(THEME_RESOLVER_ATTRIBUTE, this.themeResolver); request.setAttribute(THEME_SOURCE_ATTRIBUTE, getThemeSource()); // 4、springn mvc支持POST/Redirect/GET模式问题 FlashMap inputFlashMap = this.flashMapManager.retrieveAndUpdate(request, response); if (inputFlashMap != null) &#123; request.setAttribute(INPUT_FLASH_MAP_ATTRIBUTE, Collections.unmodifiableMap(inputFlashMap)); &#125; request.setAttribute(OUTPUT_FLASH_MAP_ATTRIBUTE, new FlashMap()); request.setAttribute(FLASH_MAP_MANAGER_ATTRIBUTE, this.flashMapManager); try &#123; // 5、spring mvc分发前端request doDispatch(request, response); &#125; finally &#123; if (!WebAsyncUtils.getAsyncManager(request).isConcurrentHandlingStarted()) &#123; // Restore the original attribute snapshot, in case of an include. if (attributesSnapshot != null) &#123; restoreAttributesAfterInclude(request, attributesSnapshot); &#125; &#125; &#125;&#125; doDispatchdoService方法在对request进行一系列包装后使用doDispatch方法分发请求： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586protected void doDispatch(HttpServletRequest request, HttpServletResponse response) throws Exception &#123; HttpServletRequest processedRequest = request; HandlerExecutionChain mappedHandler = null; boolean multipartRequestParsed = false; WebAsyncManager asyncManager = WebAsyncUtils.getAsyncManager(request); try &#123; ModelAndView mv = null; Exception dispatchException = null; try &#123; //1.判断是不是上传文件的请求 processedRequest = checkMultipart(request); multipartRequestParsed = (processedRequest != request); //这里主要干了这几件事：获取Handler、创建执行器链，判断是不是cors跨域请求。 // Determine handler for the current request. mappedHandler = getHandler(processedRequest); if (mappedHandler == null) &#123; noHandlerFound(processedRequest, response); return; &#125; // Determine handler adapter for the current request. HandlerAdapter ha = getHandlerAdapter(mappedHandler.getHandler()); // Process last-modified header, if supported by the handler. String method = request.getMethod(); boolean isGet = \"GET\".equals(method); if (isGet || \"HEAD\".equals(method)) &#123; long lastModified = ha.getLastModified(request, mappedHandler.getHandler()); if (logger.isDebugEnabled()) &#123; logger.debug(\"Last-Modified value for [\" + getRequestUri(request) + \"] is: \" + lastModified); &#125; if (new ServletWebRequest(request, response).checkNotModified(lastModified) &amp;&amp; isGet) &#123; return; &#125; &#125; if (!mappedHandler.applyPreHandle(processedRequest, response)) &#123; return; &#125; // Actually invoke the handler. mv = ha.handle(processedRequest, response, mappedHandler.getHandler()); if (asyncManager.isConcurrentHandlingStarted()) &#123; return; &#125; applyDefaultViewName(processedRequest, mv); mappedHandler.applyPostHandle(processedRequest, response, mv); &#125; catch (Exception ex) &#123; dispatchException = ex; &#125; catch (Throwable err) &#123; // As of 4.3, we're processing Errors thrown from handler methods as well, // making them available for @ExceptionHandler methods and other scenarios. dispatchException = new NestedServletException(\"Handler dispatch failed\", err); &#125; processDispatchResult(processedRequest, response, mappedHandler, mv, dispatchException); &#125; catch (Exception ex) &#123; triggerAfterCompletion(processedRequest, response, mappedHandler, ex); &#125; catch (Throwable err) &#123; triggerAfterCompletion(processedRequest, response, mappedHandler, new NestedServletException(\"Handler processing failed\", err)); &#125; finally &#123; if (asyncManager.isConcurrentHandlingStarted()) &#123; // Instead of postHandle and afterCompletion if (mappedHandler != null) &#123; mappedHandler.applyAfterConcurrentHandlingStarted(processedRequest, response); &#125; &#125; else &#123; // Clean up any resources used by a multipart request. if (multipartRequestParsed) &#123; cleanupMultipart(processedRequest); &#125; &#125; &#125;&#125; 判断是否为上传文件的请求123456789101112131415161718192021222324252627282930protected HttpServletRequest checkMultipart(HttpServletRequest request) throws MultipartException &#123; //判断请求的方法就是 isMultipart() if (this.multipartResolver != null &amp;&amp; this.multipartResolver.isMultipart(request)) &#123; if (WebUtils.getNativeRequest(request, MultipartHttpServletRequest.class) != null) &#123; logger.debug(\"Request is already a MultipartHttpServletRequest - if not in a forward, \" + \"this typically results from an additional MultipartFilter in web.xml\"); &#125; else if (hasMultipartException(request) ) &#123; logger.debug(\"Multipart resolution failed for current request before - \" + \"skipping re-resolution for undisturbed error rendering\"); &#125; else &#123; try &#123; //把请求封装成MultipartHttpServletRequest类型 return this.multipartResolver.resolveMultipart(request); &#125; catch (MultipartException ex) &#123; if (request.getAttribute(WebUtils.ERROR_EXCEPTION_ATTRIBUTE) != null) &#123; logger.debug(\"Multipart resolution failed for error dispatch\", ex); // Keep processing error dispatch with regular request handle below &#125; else &#123; throw ex; &#125; &#125; &#125; &#125; // If not returned before: return original request. return request;&#125; 12345678910//如果不是post请求直接返回false//如果是post请求，就从请求头的ContenType中判断有没有 \"multipart/\" 字段public boolean isMultipart(HttpServletRequest request) &#123; if (!\"post\".equalsIgnoreCase(request.getMethod())) &#123; return false; &#125; else &#123; String contentType = request.getContentType(); return StringUtils.startsWithIgnoreCase(contentType, \"multipart/\"); &#125;&#125; 获取 HandlerMapping ，生成 HandlerExecuteChain；getHandlerAdapter先判断是不是get或者head请求，如果是就直接执行对应handler返回view如果不是就执行拦截器，然后执行postHandler最后执行render渲染view总结1. HttpServletBean 主要做一些初始化的工作，将web.xml中配置的参数设置到Servlet中。比如servlet标签的子标签init-param标签中配置的参数。 2. FrameworkServlet 将Servlet与Spring容器上下文关联。其实也就是初始化FrameworkServlet的属性webApplicationContext，这个属性代表SpringMVC上下文，它有个父类上下文，既web.xml中配置的ContextLoaderListener监听器初始化的容器上下文。 3. DispatcherServlet 初始化各个功能的实现类。比如异常处理、视图处理、请求映射处理等。","categories":[{"name":"Spring相关","slug":"Spring相关","permalink":"https://originer.github.io/Horizon.github.io/categories/Spring相关/"}],"tags":[{"name":"SpringMVC","slug":"SpringMVC","permalink":"https://originer.github.io/Horizon.github.io/tags/SpringMVC/"}]},{"title":"深入浅出NIO Channel和Buffer","slug":"NIO Channel和Buffer","date":"2018-07-24T11:26:59.000Z","updated":"2018-07-24T11:26:59.000Z","comments":true,"path":"2018/07/24/NIO Channel和Buffer/","link":"","permalink":"https://originer.github.io/Horizon.github.io/2018/07/24/NIO Channel和Buffer/","excerpt":"前言Java NIO 由以下几个核心部分组成： Buffer Channel Selector 传统的IO操作面向数据流，意味着每次从流中读一个或多个字节，直至完成，数据没有被缓存在任何地方。NIO操作面向缓冲区，数据从Channel读取到Buffer缓冲区，随后在Buffer中处理数据。本文着重介绍Channel和Buffer的概念以及在文件读写方面的应用和内部实现原理。","text":"前言Java NIO 由以下几个核心部分组成： Buffer Channel Selector 传统的IO操作面向数据流，意味着每次从流中读一个或多个字节，直至完成，数据没有被缓存在任何地方。NIO操作面向缓冲区，数据从Channel读取到Buffer缓冲区，随后在Buffer中处理数据。本文着重介绍Channel和Buffer的概念以及在文件读写方面的应用和内部实现原理。 Buffer A buffer is a linear, finite sequence of elements of a specific primitive type. 一块缓存区，内部使用字节数组存储数据，并维护几个特殊变量，实现数据的反复利用。 mark：初始值为-1，用于备份当前的position position：初始值为0。position表示当前可以写入或读取数据的位置。当写入或读取一个数据后， position向前移动到下一个位置。 limit：写模式下，limit表示最多能往Buffer里写多少数据，等于capacity值。读模式下，limit表示最多可以读取多少数据。 capacity：缓存数组大小 Buffer.png mark()：把当前的position赋值给mark 1234public final Buffer mark() &#123; mark = position; return this;&#125; reset()：把mark值还原给position 1234567public final Buffer reset() &#123; int m = mark; if (m &lt; 0) throw new InvalidMarkException(); position = m; return this;&#125; clear()：一旦读完Buffer中的数据，需要让Buffer准备好再次被写入，clear会恢复状态值，但不会擦除数据。 123456public final Buffer clear() &#123; position = 0; limit = capacity; mark = -1; return this;&#125; flip()：Buffer有两种模式，写模式和读模式，flip后Buffer从写模式变成读模式。 123456public final Buffer flip() &#123; limit = position; position = 0; mark = -1; return this;&#125; rewind()：重置position为0，从头读写数据。 12345public final Buffer rewind() &#123; position = 0; mark = -1; return this;&#125; 目前Buffer的实现类有以下几种： ByteBuffer CharBuffer DoubleBuffer FloatBuffer IntBuffer LongBuffer ShortBuffer MappedByteBuffer 其中MappedByteBuffer实现比较特殊，感兴趣的可以看看 深入浅出MappedByteBuffer Paste_Image.png ByteBuffer A byte buffer，extend from Buffer ByteBuffer的实现类包括HeapByteBuffer和DirectByteBuffer两种。 HeapByteBuffer 12345678public static ByteBuffer allocate(int capacity) &#123; if (capacity &lt; 0) throw new IllegalArgumentException(); return new HeapByteBuffer(capacity, capacity);&#125;HeapByteBuffer(int cap, int lim) &#123; super(-1, 0, lim, cap, new byte[cap], 0);&#125; HeapByteBuffer通过初始化字节数组hd，在虚拟机堆上申请内存空间。 DirectByteBuffer 123456789101112131415161718192021222324252627public static ByteBuffer allocateDirect(int capacity) &#123; return new DirectByteBuffer(capacity);&#125;DirectByteBuffer(int cap) &#123; super(-1, 0, cap, cap); boolean pa = VM.isDirectMemoryPageAligned(); int ps = Bits.pageSize(); long size = Math.max(1L, (long)cap + (pa ? ps : 0)); Bits.reserveMemory(size, cap); long base = 0; try &#123; base = unsafe.allocateMemory(size); &#125; catch (OutOfMemoryError x) &#123; Bits.unreserveMemory(size, cap); throw x; &#125; unsafe.setMemory(base, size, (byte) 0); if (pa &amp;&amp; (base % ps != 0)) &#123; // Round up to page boundary address = base + ps - (base &amp; (ps - 1)); &#125; else &#123; address = base; &#125; cleaner = Cleaner.create(this, new Deallocator(base, size, cap)); att = null;&#125; DirectByteBuffer通过unsafe.allocateMemory在物理内存中申请地址空间（非jvm堆内存），并在ByteBuffer的address变量中维护指向该内存的地址。unsafe.setMemory(base, size, (byte) 0)方法把新申请的内存数据清零。 Channel A channel represents an open connection to an entity such as a hardware device, a file, a network socket, or a program component that is capable of performing one or more distinct I/O operations, for example reading or writing. 又称“通道”，NIO把它支持的I/O对象抽象为Channel，类似于原I/O中的流（Stream），但有所区别： 流是单向的，通道是双向的，可读可写。 流读写是阻塞的，通道可以异步读写。 流中的数据可以选择性的先读到缓存中，通道的数据总是要先读到一个缓存中，或从缓存中写入，如下所示： Channel.png 目前已知Channel的实现类有： FileChannel DatagramChannel SocketChannel ServerSocketChannel FileChannel A channel for reading, writing, mapping, and manipulating a file.一个用来写、读、映射和操作文件的通道。 FileChannel的read、write和map通过其实现类FileChannelImpl实现。 read实现 1234567891011121314151617181920212223public int read(ByteBuffer dst) throws IOException &#123; ensureOpen(); if (!readable) throw new NonReadableChannelException(); synchronized (positionLock) &#123; int n = 0; int ti = -1; try &#123; begin(); ti = threads.add(); if (!isOpen()) return 0; do &#123; n = IOUtil.read(fd, dst, -1, nd); &#125; while ((n == IOStatus.INTERRUPTED) &amp;&amp; isOpen()); return IOStatus.normalize(n); &#125; finally &#123; threads.remove(ti); end(n &gt; 0); assert IOStatus.check(n); &#125; &#125;&#125; FileChannelImpl的read方法通过IOUtil的read实现： 12345678910111213141516171819static int read(FileDescriptor fd, ByteBuffer dst, long position, NativeDispatcher nd) IOException &#123; if (dst.isReadOnly()) throw new IllegalArgumentException(\"Read-only buffer\"); if (dst instanceof DirectBuffer) return readIntoNativeBuffer(fd, dst, position, nd); // Substitute a native buffer ByteBuffer bb = Util.getTemporaryDirectBuffer(dst.remaining()); try &#123; int n = readIntoNativeBuffer(fd, bb, position, nd); bb.flip(); if (n &gt; 0) dst.put(bb); return n; &#125; finally &#123; Util.offerFirstTemporaryDirectBuffer(bb); &#125;&#125; 通过上述实现可以看出，基于channel的文件数据读取步骤如下：1、申请一块和缓存同大小的DirectByteBuffer bb。2、读取数据到缓存bb，底层由NativeDispatcher的read实现。3、把bb的数据读取到dst（用户定义的缓存，在jvm中分配内存）。read方法导致数据复制了两次。 write实现 1234567891011121314151617181920212223public int write(ByteBuffer src) throws IOException &#123; ensureOpen(); if (!writable) throw new NonWritableChannelException(); synchronized (positionLock) &#123; int n = 0; int ti = -1; try &#123; begin(); ti = threads.add(); if (!isOpen()) return 0; do &#123; n = IOUtil.write(fd, src, -1, nd); &#125; while ((n == IOStatus.INTERRUPTED) &amp;&amp; isOpen()); return IOStatus.normalize(n); &#125; finally &#123; threads.remove(ti); end(n &gt; 0); assert IOStatus.check(n); &#125; &#125;&#125; 和read实现一样，FileChannelImpl的write方法通过IOUtil的write实现： 12345678910111213141516171819202122232425static int write(FileDescriptor fd, ByteBuffer src, long position, NativeDispatcher nd) throws IOException &#123; if (src instanceof DirectBuffer) return writeFromNativeBuffer(fd, src, position, nd); // Substitute a native buffer int pos = src.position(); int lim = src.limit(); assert (pos &lt;= lim); int rem = (pos &lt;= lim ? lim - pos : 0); ByteBuffer bb = Util.getTemporaryDirectBuffer(rem); try &#123; bb.put(src); bb.flip(); // Do not update src until we see how many bytes were written src.position(pos); int n = writeFromNativeBuffer(fd, bb, position, nd); if (n &gt; 0) &#123; // now update src src.position(pos + n); &#125; return n; &#125; finally &#123; Util.offerFirstTemporaryDirectBuffer(bb); &#125;&#125; 通过上述实现可以看出，基于channel的文件数据写入步骤如下：1、申请一块DirectByteBuffer，bb大小为byteBuffer中的limit - position。2、复制byteBuffer中的数据到bb中。3、把数据从bb中写入到文件，底层由NativeDispatcher的write实现，具体如下： 12345678910111213141516171819202122private static int writeFromNativeBuffer(FileDescriptor fd, ByteBuffer bb, long position, NativeDispatcher nd) throws IOException &#123; int pos = bb.position(); int lim = bb.limit(); assert (pos &lt;= lim); int rem = (pos &lt;= lim ? lim - pos : 0); int written = 0; if (rem == 0) return 0; if (position != -1) &#123; written = nd.pwrite(fd, ((DirectBuffer)bb).address() + pos, rem, position); &#125; else &#123; written = nd.write(fd, ((DirectBuffer)bb).address() + pos, rem); &#125; if (written &gt; 0) bb.position(pos + written); return written;&#125; write方法也导致了数据复制了两次 Channel和Buffer示例123456789101112131415File file = new RandomAccessFile(\"data.txt\", \"rw\");FileChannel channel = file.getChannel();ByteBuffer buffer = ByteBuffer.allocate(48);int bytesRead = channel.read(buffer);while (bytesRead != -1) &#123; System.out.println(\"Read \" + bytesRead); buffer.flip(); while(buffer.hasRemaining())&#123; System.out.print((char) buffer.get()); &#125; buffer.clear(); bytesRead = channel.read(buffer);&#125;file.close(); 注意buffer.flip() 的调用，首先将数据写入到buffer，然后变成读模式，再从buffer中读取数据。","categories":[{"name":"网络编程","slug":"网络编程","permalink":"https://originer.github.io/Horizon.github.io/categories/网络编程/"}],"tags":[{"name":"NIO","slug":"NIO","permalink":"https://originer.github.io/Horizon.github.io/tags/NIO/"}]},{"title":"Map的几种遍历方式","slug":"Map的几种遍历方式","date":"2018-07-23T08:37:01.000Z","updated":"2018-07-23T08:37:01.000Z","comments":true,"path":"2018/07/23/Map的几种遍历方式/","link":"","permalink":"https://originer.github.io/Horizon.github.io/2018/07/23/Map的几种遍历方式/","excerpt":"在开发过程中经常会用到Map的遍历，所以对Map的几种遍历方式做一下整理； KeySet 遍历123456Iterator it = map.keySet().iterator(); while (it.hasNext()) &#123; key = it.next(); value = map.get(key); System.out.println(key + \":\" + value); &#125;","text":"在开发过程中经常会用到Map的遍历，所以对Map的几种遍历方式做一下整理； KeySet 遍历123456Iterator it = map.keySet().iterator(); while (it.hasNext()) &#123; key = it.next(); value = map.get(key); System.out.println(key + \":\" + value); &#125; EntrySet 遍历1234567Iterator it1 = map.entrySet().iterator(); while (it1.hasNext()) &#123; Map.Entry entry = (Map.Entry) it1.next(); key = entry.getKey(); value = entry.getValue(); System.out.println(key + \"=\" + value); &#125; Java8 的 lambda 遍历123map.forEach((k, v) -&gt; &#123; System.out.println(\"key=\"+k+\":\"+\"value=\"+v); &#125;); 使用 EntrySet 效率比 KeySet 高，EntrySet 相比KeySet 少了遍历table的过程。java8 下可以配合lambda直接使用 map.foreach() 实际上还是使用entrySet的方式遍历。","categories":[],"tags":[]},{"title":"Ajax跨域解决方案","slug":"ajax跨域问题","date":"2018-07-03T12:14:40.000Z","updated":"2018-07-03T12:14:40.000Z","comments":true,"path":"2018/07/03/ajax跨域问题/","link":"","permalink":"https://originer.github.io/Horizon.github.io/2018/07/03/ajax跨域问题/","excerpt":"为什么会出现跨域跨域问题来源于JavaScript的同源策略，即只有 协议+主机名+端口号(如存在)相同，则允许相互访问。也就是说JavaScript只能访问和操作自己域下的资源，不能访问和操作其他域下的资源。跨域问题是针对JS和ajax的，html本身没有跨域问题，比如a标签、script标签、甚至form标签（可以直接跨域发送数据并接收数据）等。","text":"为什么会出现跨域跨域问题来源于JavaScript的同源策略，即只有 协议+主机名+端口号(如存在)相同，则允许相互访问。也就是说JavaScript只能访问和操作自己域下的资源，不能访问和操作其他域下的资源。跨域问题是针对JS和ajax的，html本身没有跨域问题，比如a标签、script标签、甚至form标签（可以直接跨域发送数据并接收数据）等。 说白了，产生跨域的主要原因就是浏览器的限制。 出现跨域的主要三种原因： 浏览器限制 请求是XHR请求 请求是跨域的 如何解决跨域问题解决跨域问题可以从产生跨域的源头来解决。 浏览器解除限制最简单暴力也是最不实用的一种解决方案，不可能去要求每个用户都设置浏览器。 XHR请求请求本身是XHR请求，此时可以通过JSONP的请求方式来实现跨域： JSONP是JSONwith Padding的略称。它是一个非官方的协议，它允许在服务器端集成Script tags返回至客户端，通过javascript callback的形式实现跨域访问（这仅仅是JSONP简单的实现形式）。简单的来说就是把原来要返回的JSON数据封装成一个JS请求。 弊端：只支持Get请求，需要改动后台代码。 请求本身是跨域请求本身是跨域的，关于跨域的定义可以参考上文： 添加响应头，允许跨域 addHeader(‘Access-Control-Allow-Origin:*’);//允许所有来源访问 addHeader(‘Access-Control-Allow-Method:POST,GET’);//允许访问的方式 代理的方式 服务器A的test01.html页面想访问服务器B的后台action，返回“test”字符串，此时就出现跨域请求，浏览器控制台会出现报错提示，由于跨域是浏览器的同源策略造成的，对于服务器后台不存在该问题，可以在服务器A中添加一个代理action，在该action中完成对服务器B中action数据的请求，然后在返回到test01.html页面。 JSONP解决方案JSONP的最基本的原理是：动态添加一个标签，而script标签的src属性是没有跨域的限制的。这样说来，这种跨域方式其实与ajax XmlHttpRequest协议无关了。 JSONP的优点：它不像XMLHttpRequest对象实现的Ajax请求那样受到同源策略的限制；它的兼容性更好，在更加古老的浏览器中都 可以运行，不需要XMLHttpRequest或ActiveX的支持；并且在请求完毕后可以通过调用callback的方式回传结果。 JSONP的缺点：它只支持GET请求而不支持POST等其它类型的HTTP请求；它只支持跨域HTTP请求这种情况，不能解决不同域的两个页面之间如何进行JavaScript调用的问题。 Jsonp的执行过程如下： 首先在客户端注册一个callback (如:’jsoncallback’), 然后把callback的名字(如:jsonp1236827957501)传给服务器。注意：服务端得到callback的数值后，要用jsonp1236827957501(……)把将要输出的json内容包括起来，此时，服务器生成 json 数据才能被客户端正确接收。 然后以 javascript 语法的方式，生成一个function， function 名字就是传递上来的参数 ‘jsoncallback’的值 jsonp1236827957501 . 最后将 json 数据直接以入参的方式，放置到 function 中，这样就生成了一段 js 语法的文档，返回给客户端。 客户端浏览器，解析script标签，并执行返回的 javascript 文档，此时javascript文档数据，作为参数，传入到了客户端预先定义好的 callback 函数(如上例中jquery $.ajax()方法封装的的success: function(json))里。 可以说jsonp的方式原理上和是一致的(qq空间就是大量采用这种方式来实现跨域数据交换的)。JSONP是一种脚本注入(Script Injection)行为，所以有一定的安全隐患。* 例如，我们通过jquery的ajax发送一个jsonp的请求： 123456789$.ajax(&#123; url: base +\"/get1\", dataType: \"jsonp\", jsonp: \"callback2\", cache:true, success: function(json)&#123; result = json; &#125;&#125;); 后台接收也要做一些修改： 12345678@ControllerAdvicepublic class JsonpAdvice extends AbstractJsonpResponseBodyAdvice &#123; public JsonpAdvice() &#123; // TODO Auto-generated constructor stub super(\"callback2\"); &#125;&#125; ​","categories":[{"name":"前端相关","slug":"前端相关","permalink":"https://originer.github.io/Horizon.github.io/categories/前端相关/"}],"tags":[]},{"title":"JDK代理","slug":"jdk代理","date":"2018-07-02T06:09:23.000Z","updated":"2018-07-02T06:09:23.000Z","comments":true,"path":"2018/07/02/jdk代理/","link":"","permalink":"https://originer.github.io/Horizon.github.io/2018/07/02/jdk代理/","excerpt":"Java中代理的实现一般分为三种：JDK静态代理、JDK动态代理以及CGLIB动态代理。在Spring的AOP实现中，主要应用了JDK动态代理以及CGLIB动态代理。但是本文着重介绍JDK动态代理机制，CGLIB动态代理后面会接着探究。代理一般实现的模式为JDK静态代理：创建一个接口，然后创建被代理的类实现该接口并且实现该接口中的抽象方法。之后再创建一个代理类，同时使其也实现这个接口。在代理类中持有一个被代理对象的引用，而后在代理类方法中调用该对象的方法。其实就是代理类为被代理类预处理消息、过滤消息并在此之后将消息转发给被代理类，之后还能进行消息的后置处理。代理类和被代理类通常会存在关联关系(即上面提到的持有的被带离对象的引用)，代理类本身不实现服务，而是通过调用被代理类中的方法来提供服务。","text":"Java中代理的实现一般分为三种：JDK静态代理、JDK动态代理以及CGLIB动态代理。在Spring的AOP实现中，主要应用了JDK动态代理以及CGLIB动态代理。但是本文着重介绍JDK动态代理机制，CGLIB动态代理后面会接着探究。代理一般实现的模式为JDK静态代理：创建一个接口，然后创建被代理的类实现该接口并且实现该接口中的抽象方法。之后再创建一个代理类，同时使其也实现这个接口。在代理类中持有一个被代理对象的引用，而后在代理类方法中调用该对象的方法。其实就是代理类为被代理类预处理消息、过滤消息并在此之后将消息转发给被代理类，之后还能进行消息的后置处理。代理类和被代理类通常会存在关联关系(即上面提到的持有的被带离对象的引用)，代理类本身不实现服务，而是通过调用被代理类中的方法来提供服务。 JDK一般代理jdk一般代理比较简单，我们只需要 定义一个接口 A 定义实现接口的具体类 AImpl 定义 AImpl的代理类 ProxyImplA 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061//接口public interface Star &#123; void confer(); void signComtract(); void sing();&#125;//接口的具体实现public class RealStar implements Star&#123; public void confer() &#123; System.out.println(\"RealStar confer\"); &#125; public void signComtract() &#123; System.out.println(\"RealStar signComtract\"); &#125; public void sing() &#123; System.out.println(\"RealStar sing\"); &#125;&#125;//代理类public class ProxyStar implements Star &#123; private Star star; public ProxyStar(Star real) &#123; this.star = real; &#125; public void confer() &#123; System.out.println(\"ProxyStar confer\"); &#125; public void signComtract() &#123; System.out.println(\"ProxyStar signComtract\"); &#125; public void sing() &#123; star.sing(); &#125;&#125;//测试public class Client &#123; public static void main(String[] args) &#123; Star real = new RealStar(); Star proxy = new ProxyStar(real); proxy.sing(); &#125;&#125;RealStar singProxyStar conferProxyStar signComtractProcess finished with exit code 0 这种方法一般称为JDK静态代理，比较简单，但是不实用。因为静态代理有一个很明显的缺点：由于代理只能为一个类服务，如果需要代理的类很多，那么就需要编写大量的代理类，比较繁琐。 JDK动态代理使用动态代理可以解决静态代理的缺点 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061/** * 1.通过实现InvocationHandler接口来自定义自己的InvocationHandler; * &lt;p&gt; * 2.通过Proxy.getProxyClass获得动态代理类 * &lt;p&gt; * 3.通过反射机制获得代理类的构造方法，方法签名为getConstructor(InvocationHandler.class) * &lt;p&gt; * 4.通过构造函数获得代理对象并将自定义的InvocationHandler实例对象传为参数传入 * &lt;p&gt; * 5.通过代理对象调用目标方法 */public class MyProxy &#123; public interface IHello &#123; void sayHello(); &#125; static class Hello implements IHello &#123; public void sayHello() &#123; System.out.println(\"Hello world!!\"); &#125; &#125; //自定义InvocationHandler static class HWInvocationHandler implements InvocationHandler &#123; //目标对象 private Object target; public HWInvocationHandler(Object target) &#123; this.target = target; &#125; @Override public Object invoke(Object proxy, Method method, Object[] args) throws Throwable &#123; System.out.println(\"------插入前置通知代码-------------\"); //执行相应的目标方法 Object rs = method.invoke(target, args); System.out.println(\"------插入后置处理代码-------------\"); return rs; &#125; &#125; public static void main(String[] args) throws NoSuchMethodException, IllegalAccessException, InvocationTargetException, InstantiationException &#123;// //生成$Proxy0的class文件// System.getProperties().put(\"sun.misc.ProxyGenerator.saveGeneratedFiles\", \"true\");// //获取动态代理类// Class proxyClazz = Proxy.getProxyClass(IHello.class.getClassLoader(), IHello.class);// //获得代理类的构造函数，并传入参数类型InvocationHandler.class// Constructor constructor = proxyClazz.getConstructor(InvocationHandler.class);// //通过构造函数来创建动态代理对象，将自定义的InvocationHandler实例传入// IHello iHello = (IHello) constructor.newInstance(new HWInvocationHandler(new Hello()));// //通过代理对象调用目标方法// iHello.sayHello(); //生成$Proxy0的class文件 System.getProperties().put(\"sun.misc.ProxyGenerator.saveGeneratedFiles\", \"true\"); IHello ihello = (IHello) Proxy.newProxyInstance(IHello.class.getClassLoader(), //加载接口的类加载器 new Class[]&#123;IHello.class&#125;, //一组接口 new HWInvocationHandler(new Hello())); //自定义的InvocationHandler ihello.sayHello(); &#125;&#125; JDK动态代理过程JDK静态代理是通过直接编码创建的，而JDK动态代理是利用反射机制在运行时创建代理类的。 其实在动态代理中，核心是InvocationHandler。每一个代理的实例都会有一个关联的调用处理程序(InvocationHandler)。对待代理实例进行调用时，将对方法的调用进行编码并指派到它的调用处理器(InvocationHandler)的invoke方法。所以对代理对象实例方法的调用都是通过InvocationHandler中的invoke方法来完成的，而invoke方法会根据传入的代理对象、方法名称以及参数决定调用代理的哪个方法。 123456IHello hello = new Hello();InvocationHandler handler = new HWInvocationHandler(hello);IHello ihello = (IHello) Proxy.newProxyInstance(HWInvocationHandler.getClass.getClassLoader(), hello.getClass().getInterfaces(), handler);ihello.sayHello(); 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354public static Object newProxyInstance(ClassLoader loader, Class&lt;?&gt;[] interfaces, InvocationHandler h) throws IllegalArgumentException &#123; //如果h为空将抛出异常 Objects.requireNonNull(h); final Class&lt;?&gt;[] intfs = interfaces.clone();//拷贝被代理类实现的一些接口，用于后面权限方面的一些检查 final SecurityManager sm = System.getSecurityManager(); if (sm != null) &#123; //在这里对某些安全权限进行检查，确保我们有权限对预期的被代理类进行代理 checkProxyAccess(Reflection.getCallerClass(), loader, intfs); &#125; /* * 下面这个方法将产生代理类 */ Class&lt;?&gt; cl = getProxyClass0(loader, intfs); /* * 使用指定的调用处理程序获取代理类的构造函数对象 */ try &#123; if (sm != null) &#123; checkNewProxyPermission(Reflection.getCallerClass(), cl); &#125; final Constructor&lt;?&gt; cons = cl.getConstructor(constructorParams); final InvocationHandler ih = h; //假如代理类的构造函数是private的，就使用反射来set accessible if (!Modifier.isPublic(cl.getModifiers())) &#123; AccessController.doPrivileged(new PrivilegedAction&lt;Void&gt;() &#123; public Void run() &#123; cons.setAccessible(true); return null; &#125; &#125;); &#125; //根据代理类的构造函数来生成代理类的对象并返回 return cons.newInstance(new Object[]&#123;h&#125;); &#125; catch (IllegalAccessException|InstantiationException e) &#123; throw new InternalError(e.toString(), e); &#125; catch (InvocationTargetException e) &#123; Throwable t = e.getCause(); if (t instanceof RuntimeException) &#123; throw (RuntimeException) t; &#125; else &#123; throw new InternalError(t.toString(), t); &#125; &#125; catch (NoSuchMethodException e) &#123; throw new InternalError(e.toString(), e); &#125; &#125; 然后通过 Class&lt;?&gt; cl = getProxyClass0(loader, intfs); 产生具体代理类，下面是具体过程 123456789101112131415/** * 生成一个代理类，但是在调用本方法之前必须进行权限检查 */ private static Class&lt;?&gt; getProxyClass0(ClassLoader loader, Class&lt;?&gt;... interfaces) &#123; //如果接口数量大于65535，抛出非法参数错误 if (interfaces.length &gt; 65535) &#123; throw new IllegalArgumentException(\"interface limit exceeded\"); &#125; // 如果在缓存中有对应的代理类，那么直接返回 // 否则代理类将有 ProxyClassFactory 来创建 return proxyClassCache.get(loader, interfaces); &#125; ProxyClassFactory是什么？ 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101/** * 里面有一个根据给定ClassLoader和Interface来创建代理类的工厂函数 * */ private static final class ProxyClassFactory implements BiFunction&lt;ClassLoader, Class&lt;?&gt;[], Class&lt;?&gt;&gt; &#123; // 代理类的名字的前缀统一为“$Proxy” private static final String proxyClassNamePrefix = \"$Proxy\"; // 每个代理类前缀后面都会跟着一个唯一的编号，如$Proxy0、$Proxy1、$Proxy2 private static final AtomicLong nextUniqueNumber = new AtomicLong(); @Override public Class&lt;?&gt; apply(ClassLoader loader, Class&lt;?&gt;[] interfaces) &#123; Map&lt;Class&lt;?&gt;, Boolean&gt; interfaceSet = new IdentityHashMap&lt;&gt;(interfaces.length); for (Class&lt;?&gt; intf : interfaces) &#123; /* * 验证类加载器加载接口得到对象是否与由apply函数参数传入的对象相同 */ Class&lt;?&gt; interfaceClass = null; try &#123; interfaceClass = Class.forName(intf.getName(), false, loader); &#125; catch (ClassNotFoundException e) &#123; &#125; if (interfaceClass != intf) &#123; throw new IllegalArgumentException( intf + \" is not visible from class loader\"); &#125; /* * 验证这个Class对象是不是接口 */ if (!interfaceClass.isInterface()) &#123; throw new IllegalArgumentException( interfaceClass.getName() + \" is not an interface\"); &#125; /* * 验证这个接口是否重复 */ if (interfaceSet.put(interfaceClass, Boolean.TRUE) != null) &#123; throw new IllegalArgumentException( \"repeated interface: \" + interfaceClass.getName()); &#125; &#125; String proxyPkg = null; // 声明代理类所在的package int accessFlags = Modifier.PUBLIC | Modifier.FINAL; /* * 记录一个非公共代理接口的包，以便在同一个包中定义代理类。同时验证所有非公共 * 代理接口都在同一个包中 */ for (Class&lt;?&gt; intf : interfaces) &#123; int flags = intf.getModifiers(); if (!Modifier.isPublic(flags)) &#123; accessFlags = Modifier.FINAL; String name = intf.getName(); int n = name.lastIndexOf('.'); String pkg = ((n == -1) ? \"\" : name.substring(0, n + 1)); if (proxyPkg == null) &#123; proxyPkg = pkg; &#125; else if (!pkg.equals(proxyPkg)) &#123; throw new IllegalArgumentException( \"non-public interfaces from different packages\"); &#125; &#125; &#125; if (proxyPkg == null) &#123; // 如果全是公共代理接口，那么生成的代理类就在com.sun.proxy package下 proxyPkg = ReflectUtil.PROXY_PACKAGE + \".\"; &#125; /* * 为代理类生成一个name package name + 前缀+唯一编号 * 如 com.sun.proxy.$Proxy0.class */ long num = nextUniqueNumber.getAndIncrement(); String proxyName = proxyPkg + proxyClassNamePrefix + num; /* * 生成指定代理类的字节码文件 */ byte[] proxyClassFile = ProxyGenerator.generateProxyClass( proxyName, interfaces, accessFlags); try &#123; return defineClass0(loader, proxyName, proxyClassFile, 0, proxyClassFile.length); &#125; catch (ClassFormatError e) &#123; /* * A ClassFormatError here means that (barring bugs in the * proxy class generation code) there was some other * invalid aspect of the arguments supplied to the proxy * class creation (such as virtual machine limitations * exceeded). */ throw new IllegalArgumentException(e.toString()); &#125; &#125; &#125; 由上方代码byte[] proxyClassFile = ProxyGenerator.generateProxyClass(proxyName, interfaces, accessFlags);可以看到，其实生成代理类字节码文件的工作是通过 ProxyGenerate类中的generateProxyClass方法来完成的。 12345678910111213141516171819202122232425262728293031public static byte[] generateProxyClass(final String var0, Class&lt;?&gt;[] var1, int var2) &#123; ProxyGenerator var3 = new ProxyGenerator(var0, var1, var2); // 真正用来生成代理类字节码文件的方法在这里 final byte[] var4 = var3.generateClassFile(); // 保存代理类的字节码文件 if(saveGeneratedFiles) &#123; AccessController.doPrivileged(new PrivilegedAction() &#123; public Void run() &#123; try &#123; int var1 = var0.lastIndexOf(46); Path var2; if(var1 &gt; 0) &#123; Path var3 = Paths.get(var0.substring(0, var1).replace('.', File.separatorChar), new String[0]); Files.createDirectories(var3, new FileAttribute[0]); var2 = var3.resolve(var0.substring(var1 + 1, var0.length()) + \".class\"); &#125; else &#123; var2 = Paths.get(var0 + \".class\", new String[0]); &#125; Files.write(var2, var4, new OpenOption[0]); return null; &#125; catch (IOException var4x) &#123; throw new InternalError(\"I/O exception saving generated file: \" + var4x); &#125; &#125; &#125;); &#125; return var4; &#125; 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117private byte[] generateClassFile() &#123; //下面一系列的addProxyMethod方法是将接口中的方法和Object中的方法添加到代理方法中(proxyMethod) this.addProxyMethod(hashCodeMethod, Object.class); this.addProxyMethod(equalsMethod, Object.class); this.addProxyMethod(toStringMethod, Object.class); Class[] var1 = this.interfaces; int var2 = var1.length; int var3; Class var4; //获得接口中所有方法并添加到代理方法中 for(var3 = 0; var3 &lt; var2; ++var3) &#123; var4 = var1[var3]; Method[] var5 = var4.getMethods(); int var6 = var5.length; for(int var7 = 0; var7 &lt; var6; ++var7) &#123; Method var8 = var5[var7]; this.addProxyMethod(var8, var4); &#125; &#125; Iterator var11 = this.proxyMethods.values().iterator(); //验证具有相同方法签名的方法的返回类型是否一致 List var12; while(var11.hasNext()) &#123; var12 = (List)var11.next(); checkReturnTypes(var12); &#125; //后面一系列的步骤用于写代理类Class文件 Iterator var15; try &#123; //生成代理类的构造函数 this.methods.add(this.generateConstructor()); var11 = this.proxyMethods.values().iterator(); while(var11.hasNext()) &#123; var12 = (List)var11.next(); var15 = var12.iterator(); while(var15.hasNext()) &#123; ProxyGenerator.ProxyMethod var16 = (ProxyGenerator.ProxyMethod)var15.next(); //将代理类字段声明为Method，并且字段修饰符为 private static. //因为 10 是 ACC_PRIVATE和ACC_STATIC的与运算 故代理类的字段都是 private static Method *** this.fields.add(new ProxyGenerator.FieldInfo(var16.methodFieldName, \"Ljava/lang/reflect/Method;\", 10)); //生成代理类的方法 this.methods.add(var16.generateMethod()); &#125; &#125; //为代理类生成静态代码块对某些字段进行初始化 this.methods.add(this.generateStaticInitializer()); &#125; catch (IOException var10) &#123; throw new InternalError(\"unexpected I/O Exception\", var10); &#125; if(this.methods.size() &gt; '\\uffff') &#123; //代理类中的方法数量超过65535就抛异常 throw new IllegalArgumentException(\"method limit exceeded\"); &#125; else if(this.fields.size() &gt; '\\uffff') &#123;// 代理类中字段数量超过65535也抛异常 throw new IllegalArgumentException(\"field limit exceeded\"); &#125; else &#123; // 后面是对文件进行处理的过程 this.cp.getClass(dotToSlash(this.className)); this.cp.getClass(\"java/lang/reflect/Proxy\"); var1 = this.interfaces; var2 = var1.length; for(var3 = 0; var3 &lt; var2; ++var3) &#123; var4 = var1[var3]; this.cp.getClass(dotToSlash(var4.getName())); &#125; this.cp.setReadOnly(); ByteArrayOutputStream var13 = new ByteArrayOutputStream(); DataOutputStream var14 = new DataOutputStream(var13); try &#123; var14.writeInt(-889275714); var14.writeShort(0); var14.writeShort(49); this.cp.write(var14); var14.writeShort(this.accessFlags); var14.writeShort(this.cp.getClass(dotToSlash(this.className))); var14.writeShort(this.cp.getClass(\"java/lang/reflect/Proxy\")); var14.writeShort(this.interfaces.length); Class[] var17 = this.interfaces; int var18 = var17.length; for(int var19 = 0; var19 &lt; var18; ++var19) &#123; Class var22 = var17[var19]; var14.writeShort(this.cp.getClass(dotToSlash(var22.getName()))); &#125; var14.writeShort(this.fields.size()); var15 = this.fields.iterator(); while(var15.hasNext()) &#123; ProxyGenerator.FieldInfo var20 = (ProxyGenerator.FieldInfo)var15.next(); var20.write(var14); &#125; var14.writeShort(this.methods.size()); var15 = this.methods.iterator(); while(var15.hasNext()) &#123; ProxyGenerator.MethodInfo var21 = (ProxyGenerator.MethodInfo)var15.next(); var21.write(var14); &#125; var14.writeShort(0); return var13.toByteArray(); &#125; catch (IOException var9) &#123; throw new InternalError(\"unexpected I/O Exception\", var9); &#125; &#125; &#125; 下面是将接口与Object中一些方法添加到代理类中的addProxyMethod方法： 12345678910111213141516171819202122232425262728private void addProxyMethod(Method var1, Class&lt;?&gt; var2) &#123; String var3 = var1.getName();//获得方法名称 Class[] var4 = var1.getParameterTypes();//获得方法参数类型 Class var5 = var1.getReturnType();//获得方法返回类型 Class[] var6 = var1.getExceptionTypes();//异常类型 String var7 = var3 + getParameterDescriptors(var4);//获得方法签名 Object var8 = (List)this.proxyMethods.get(var7);//根据方法前面获得proxyMethod的value if(var8 != null) &#123;//处理多个代理接口中方法重复的情况 Iterator var9 = ((List)var8).iterator(); while(var9.hasNext()) &#123; ProxyGenerator.ProxyMethod var10 = (ProxyGenerator.ProxyMethod)var9.next(); if(var5 == var10.returnType) &#123; ArrayList var11 = new ArrayList(); collectCompatibleTypes(var6, var10.exceptionTypes, var11); collectCompatibleTypes(var10.exceptionTypes, var6, var11); var10.exceptionTypes = new Class[var11.size()]; var10.exceptionTypes = (Class[])var11.toArray(var10.exceptionTypes); return; &#125; &#125; &#125; else &#123; var8 = new ArrayList(3); this.proxyMethods.put(var7, var8); &#125; ((List)var8).add(new ProxyGenerator.ProxyMethod(var3, var4, var5, var6, var2, null)); &#125;","categories":[{"name":"设计模式","slug":"设计模式","permalink":"https://originer.github.io/Horizon.github.io/categories/设计模式/"}],"tags":[{"name":"设计模式","slug":"设计模式","permalink":"https://originer.github.io/Horizon.github.io/tags/设计模式/"}]},{"title":"CGLIB动态代理","slug":"CGlib动态代理","date":"2018-06-27T05:38:58.000Z","updated":"2018-06-27T05:38:58.000Z","comments":true,"path":"2018/06/27/CGlib动态代理/","link":"","permalink":"https://originer.github.io/Horizon.github.io/2018/06/27/CGlib动态代理/","excerpt":"cglib is a powerful, high performance and quality Code Generation Library, It is used to extend JAVA classes and implements interfaces at runtime.在Spring AOP中，通常会用它来生成AopProxy对象。不仅如此，在Hibernate中PO(Persistant Object 持久化对象)字节码的生成工作也要靠它来完成。","text":"cglib is a powerful, high performance and quality Code Generation Library, It is used to extend JAVA classes and implements interfaces at runtime.在Spring AOP中，通常会用它来生成AopProxy对象。不仅如此，在Hibernate中PO(Persistant Object 持久化对象)字节码的生成工作也要靠它来完成。 CGLIB动态代理示例被代理类 123456public class HelloServiceImpl implements HelloService&#123; @Override public String hello(String name) &#123; return \"Hello! \" + name; &#125;&#125; 123456789101112131415161718192021222324252627@Slf4jpublic class CGlibTest &#123; /** * 实现MethodInterceptor接口生成方法拦截器 */ static class HelloMethodInterceptor implements MethodInterceptor &#123; @Override public Object intercept(Object o, Method method, Object[] objects, MethodProxy methodProxy) throws Throwable &#123; log.info(\"Before: &#123;&#125;\",method.getName()); Object object = methodProxy.invokeSuper(o,objects); log.info(\"After: &#123;&#125;\",method.getName()); return object; &#125; &#125; @Test public void testProxy()&#123; Enhancer enhancer = new Enhancer(); enhancer.setSuperclass(HelloServiceImpl.class); //继承被代理类 enhancer.setCallback(new HelloMethodInterceptor()); //设置回调 HelloServiceImpl helloService = (HelloServiceImpl) enhancer.create(); //生成代理类对象 String s = helloService.hello(\"123\"); System.out.println(s); &#125;&#125; JDK代理要求被代理的类必须实现接口，有很强的局限性。而CGLIB动态代理则没有此类强制性要求。简单的说，CGLIB会让生成的代理类继承被代理类，并在代理类中对代理方法进行强化处理(前置处理、后置处理等)。在CGLIB底层，其实是借助了ASM这个非常强大的Java字节码生成框架。 生成代理对象从示例中可以看出，代理类对象是由 Enhancer 类创建的，Enhancer是CGLIB的字节码增强器，可以很方便的对类进行拓展。 创建代理对象的几个步骤: 生成代理类的二进制字节码文件； 加载二进制字节码，生成Class对象( 例如使用Class.forName()方法 )； 通过反射机制获得实例构造，并创建代理类对象 对委托类进行代理生成的代理类HelloServiceImpl$$EnhancerByCGLIB$$82ef2d06继承被代理类HelloServiceImpl。在这里我们需要注意一点：如果委托类被final修饰，那么它不可被继承，即不可被代理；同样，如果委托类中存在final修饰的方法，那么该方法也不可被代理； 代理类会为委托方法生成两个方法，一个是重写的sayHello方法，另一个是CGLIB$sayHello$0方法，我们可以看到它是直接调用父类的sayHello方法； 当执行代理对象的sayHello方法时，会首先判断一下是否存在实现了MethodInterceptor接口的CGLIB$CALLBACK_0;，如果存在，则将调用MethodInterceptor中的intercept方法。","categories":[{"name":"设计模式","slug":"设计模式","permalink":"https://originer.github.io/Horizon.github.io/categories/设计模式/"}],"tags":[]},{"title":"Java设计模式：适配器模式","slug":"设计模式：适配器模式","date":"2018-06-25T12:44:43.000Z","updated":"2018-12-02T06:36:10.703Z","comments":true,"path":"2018/06/25/设计模式：适配器模式/","link":"","permalink":"https://originer.github.io/Horizon.github.io/2018/06/25/设计模式：适配器模式/","excerpt":"适配器模式 模式所涉及的角色有： ● 目标(Target)角色：这就是所期待得到的接口。注意：由于这里讨论的是类适配器模式，因此目标不可以是类。 ● 源(Adapee)角色：现在需要适配的接口。 ● 适配器(Adaper)角色：适配器类是本模式的核心。适配器把源接口转换成目标接口。显然，这一角色不可以是接口，而必须是具体类。","text":"适配器模式 模式所涉及的角色有： ● 目标(Target)角色：这就是所期待得到的接口。注意：由于这里讨论的是类适配器模式，因此目标不可以是类。 ● 源(Adapee)角色：现在需要适配的接口。 ● 适配器(Adaper)角色：适配器类是本模式的核心。适配器把源接口转换成目标接口。显然，这一角色不可以是接口，而必须是具体类。 适配器模式是一种常用的结构型模式，经常用于旧系统改造，IO流大量使用适配器模式； 适配器模式主要有两类： 1、类适配 [使用继承] 2、组合 [使用内置对象] 类适配 123456789/** * 被适配的对象 */public class Adaptee &#123; public void request() &#123; System.out.println(\"Adaptee request\"); &#125;&#125; 123456789101112/** * 适配器 * 把被适配对象与target联系起来 * 1、类适配 [使用继承] * 2、组合 [使用内置对象] */public class Adapter extends Adaptee implements Target&#123; //使用继承// public void handleReq() &#123; super.request(); &#125;&#125; 12345678910public class Client &#123; public void test(Target t) &#123; t.handleReq(); &#125; public static void main(String[] args) &#123; Client c = new Client(); c.test(new Adapter()); &#125;&#125; 组合 12345678910111213public class Adapter implements Target &#123; // 组合 private Adaptee adaptee; public Adapter(Adaptee adaptee) &#123; this.adaptee = adaptee; &#125; public void handleReq() &#123; adaptee.request(); &#125;&#125; 12345678910public class Client &#123; public void test(Target t) &#123; t.handleReq(); &#125; public static void main(String[] args) &#123; Client c = new Client(); c.test(new Adapter(new Adaptee())); &#125;&#125;","categories":[{"name":"设计模式","slug":"设计模式","permalink":"https://originer.github.io/Horizon.github.io/categories/设计模式/"}],"tags":[{"name":"设计模式","slug":"设计模式","permalink":"https://originer.github.io/Horizon.github.io/tags/设计模式/"}]},{"title":"Java设计模式：命令模式","slug":"设计模式：命令模式","date":"2018-06-25T12:44:39.000Z","updated":"2018-06-25T12:44:39.000Z","comments":true,"path":"2018/06/25/设计模式：命令模式/","link":"","permalink":"https://originer.github.io/Horizon.github.io/2018/06/25/设计模式：命令模式/","excerpt":"命令模式命令模式将“请求”封装成对象，命令模式是数据驱动设计模式，属于行为模式类别。 请求作为命令包装在一个对象下，并传递给调用器对象。 调用者对象查找可以处理此命令的适当对象，并将命令传递到执行命令的相应对象。 下面以灯泡的开关控制为例子来学习命令模式： 先定义一个Light类 12345678public class Light &#123; public void on()&#123; System.out.println(\"light on\"); &#125; public void off()&#123; System.out.println(\"light off\"); &#125;&#125;","text":"命令模式命令模式将“请求”封装成对象，命令模式是数据驱动设计模式，属于行为模式类别。 请求作为命令包装在一个对象下，并传递给调用器对象。 调用者对象查找可以处理此命令的适当对象，并将命令传递到执行命令的相应对象。 下面以灯泡的开关控制为例子来学习命令模式： 先定义一个Light类 12345678public class Light &#123; public void on()&#123; System.out.println(\"light on\"); &#125; public void off()&#123; System.out.println(\"light off\"); &#125;&#125; 声明一个Command接口，所有的命令都要实现这个接口 123public interface Command &#123; void execute();&#125; 实现一个控制灯泡开关的命令类，既然属于命令自然要实现Command接口 123456789101112public class LightOnCommand implements Command &#123; Light light; public LightOnCommand(Light light) &#123; this.light = light; &#125; @Override public void execute() &#123; light.on(); &#125;&#125; 接下来定义一个Controller类，可以理解为灯泡的遥控器 1234567891011public class SimpleRemoteController &#123; Command solot; public void setCommand(Command solot) &#123; this.solot = solot; &#125; public void pressWasPressed() &#123; solot.execute(); &#125;&#125; 对SimpleRemoteController做简单的测试 12345678public static void main(String[] args) &#123; SimpleRemoteController remoteController = new SimpleRemoteController(); Light light = new Light(); LightOnCommand lightOnCommand = new LightOnCommand(light); remoteController.setCommand(lightOnCommand); remoteController.pressWasPressed(); &#125; 可以成功打印出 light on 从上面的简单例子可以看出灯泡与遥控器通过命令来交互，这两个类互不相干，实现了解耦。","categories":[{"name":"设计模式","slug":"设计模式","permalink":"https://originer.github.io/Horizon.github.io/categories/设计模式/"}],"tags":[{"name":"设计模式","slug":"设计模式","permalink":"https://originer.github.io/Horizon.github.io/tags/设计模式/"}]},{"title":"Java的四种引用","slug":"四种引用","date":"2018-06-25T12:44:24.000Z","updated":"2018-06-25T12:44:24.000Z","comments":true,"path":"2018/06/25/四种引用/","link":"","permalink":"https://originer.github.io/Horizon.github.io/2018/06/25/四种引用/","excerpt":"首先，先贴上测试代码。","text":"首先，先贴上测试代码。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071public class ReferenceDemo &#123; static Object object = new Object(); public static void main(String[] args) &#123;// testStrongReference();// testSoftReference();// testWeakReference(); testPhantonReference(); &#125; /** * after system.gc-strongReference---obj = java.lang.Object@65b54208 * 强引用只要还存在，对象就不会被回收 */ private static void testStrongReference() &#123; Object obj = object; object = null; System.gc(); System.out.print(\"after system.gc-strongReference---obj = \" + obj); &#125; /** * after system.gc---softReference = java.lang.ref.SoftReference@65b54208 * 如果内存足够，在gc后也不会被回收，很适合用来做缓存 */ private static void testSoftReference() &#123; SoftReference&lt;Object&gt; obj = new SoftReference&lt;&gt;(object); object = null; System.gc(); System.out.print(\"after system.gc---softReference = \" + obj); &#125; /** * GC: * after system.gc---weakReference = null * after system.gc---weakReferenceStr = null * &lt;p&gt; * 在object，str设置为null后，如果发生gc，就get不到数据 * 如果不发生gc还可以get到数据 */ private static void testWeakReference() &#123; StringBuilder str = new StringBuilder(\"test\"); WeakReference&lt;Object&gt; weakReference = new WeakReference&lt;Object&gt;(object); WeakReference&lt;Object&gt; weakReferenceStr = new WeakReference&lt;Object&gt;(str); object = null;// str = null; System.gc(); System.out.println(\"after system.gc---weakReference = \" + weakReference.get()); System.out.print(\"after system.gc---weakReferenceStr = \" + weakReferenceStr.get()); &#125; /** * after system.gc---phantomReference = null * after system.gc---phantomReferenceStr = null * 无论是否发生GC get的数据都为null，可以看出，弱引用其实是没有任何效果的引用 */ private static void testPhantonReference() &#123; StringBuilder str = new StringBuilder(\"test\"); ReferenceQueue&lt;Object&gt; referenceQueue = new ReferenceQueue&lt;&gt;(); PhantomReference&lt;Object&gt; phantomReference = new PhantomReference&lt;&gt;(object, referenceQueue); PhantomReference&lt;Object&gt; phantomReferenceStr = new PhantomReference&lt;&gt;(str, referenceQueue); // object = null; // str = null; // System.gc(); System.out.println(\"after system.gc---phantomReference = \" + phantomReference.get()); System.out.print(\"after system.gc---phantomReferenceStr = \" + phantomReferenceStr.get()); &#125;&#125; 强引用最常见的一种引用，使用Object o = new Object()就会产生强引用。只要存在强引用，对象就不会被回收； 软引用只存在软引用的对象在即将发生内存泄漏时会进行回收，如果回收后内存仍不足，会发生OOM； 弱引用弱引用的对象只能生存到下一次GC前，一旦发生GC就会被回收； 虚引用不会对对象的生存时间造成影响，唯一的作用是在对象被回收时收到一个系统通知； 对于垃圾回收器回收的顺序为： 虚引用—弱引用—-软引用—强引用","categories":[{"name":"Java","slug":"Java","permalink":"https://originer.github.io/Horizon.github.io/categories/Java/"}],"tags":[]},{"title":"关于Java值传递和引用传递的思考","slug":"关于Java值传递和引用传递的思考","date":"2018-06-25T12:44:19.000Z","updated":"2018-06-25T12:44:19.000Z","comments":true,"path":"2018/06/25/关于Java值传递和引用传递的思考/","link":"","permalink":"https://originer.github.io/Horizon.github.io/2018/06/25/关于Java值传递和引用传递的思考/","excerpt":"一直以为Java方法中传递的是对象的引用，然后看了一篇文章，发现自己的理解有些偏差。 首先先写出结论： 如果参数是基本类型，传递的是基本类型的字面量值的拷贝。如果参数是引用类型，传递的是该变量所引用的对象在堆中地址值的拷贝。 基本类型和引用类型的区别在Java内存模型中把内存分为堆和栈，栈中保存的就是我们声明的变量，对象保存在堆中。栈中的引用变量指向堆中的实际对象。当一个对象没有被任何变量引用时会被垃圾回收。在jvm内存模型中，基本类型值存在变量中。引用类型的变量只是保存了那个值的引用地址，引用指向实际对象。","text":"一直以为Java方法中传递的是对象的引用，然后看了一篇文章，发现自己的理解有些偏差。 首先先写出结论： 如果参数是基本类型，传递的是基本类型的字面量值的拷贝。如果参数是引用类型，传递的是该变量所引用的对象在堆中地址值的拷贝。 基本类型和引用类型的区别在Java内存模型中把内存分为堆和栈，栈中保存的就是我们声明的变量，对象保存在堆中。栈中的引用变量指向堆中的实际对象。当一个对象没有被任何变量引用时会被垃圾回收。在jvm内存模型中，基本类型值存在变量中。引用类型的变量只是保存了那个值的引用地址，引用指向实际对象。 基本类型和引用类型在方法传参时传递了什么？1234567891011121314151617181920212223public static void main(String[] args) &#123; int num = 100; String str = \"hello\"; StringBuilder sb = new StringBuilder(\"hello\"); add(num); //1 System.out.println(num); change(str); //2 System.out.println(str); change2(sb); //3 System.out.println(sb); &#125; public static void add(int a) &#123; a = a + 1; &#125; public static void change(String a) &#123; a = a + \"tt\"; &#125; public static void change2(StringBuilder a) &#123; a = a.append(\"tt\"); &#125; 代码运行结果： 100hellohellott 由运行结果可以分析出，在方法中的参数基本类型传入的是变量的副本，也就是相当于一个新的变量，所以我们进行操作原来的变量都不会变化；引用类型传入的是‘引用的副本’，即两个引用类型的变量指向同一个堆里的对象，但是这两个引用是没有任何关系的。所以，由于String是final类型不可变对象，a=a+”tt”实际是创建了一个新对象，然后方法中的参数的引用指向了这个新变量，原来的引用指向的还是”hello”。StringBuilder是可变对象，我们可以通过引用改变引用指向的对象的值，因此原来的变量中的值也会跟着改变。但是这跟传递引用是有本质区别的。","categories":[{"name":"Java","slug":"Java","permalink":"https://originer.github.io/Horizon.github.io/categories/Java/"}],"tags":[]},{"title":"Java线程池学习总结","slug":"Java线程池学习","date":"2018-06-25T12:43:51.000Z","updated":"2018-06-25T12:43:51.000Z","comments":true,"path":"2018/06/25/Java线程池学习/","link":"","permalink":"https://originer.github.io/Horizon.github.io/2018/06/25/Java线程池学习/","excerpt":"为什么不用new Thread() 每次 new Thread() 都是新建对象，性能差； 线程缺乏统一管理，可能无限制的新建线程，相互竞争，有可能占用过多的系统资源导致死机或OOM 功能少，缺少多执行、定期执行、线程中断等功能；","text":"为什么不用new Thread() 每次 new Thread() 都是新建对象，性能差； 线程缺乏统一管理，可能无限制的新建线程，相互竞争，有可能占用过多的系统资源导致死机或OOM 功能少，缺少多执行、定期执行、线程中断等功能； 线程池的优势 重用存在的线程，减少对象的创建，消亡的开销； 可以控制最大并发线程数，提高系统资源利用率，同时可以避免过多资源竞争，避免阻塞； 提供定期执行、单线程、并发数控制等功能； 线程池 ： ThreadPoolExecutorThreadPoolExecutor有下面几个核心参数： corePoolSize：核心线程数； maximumPoolSize：线程池最大线程数； workQueue：阻塞队列，存储等待执行的任务； keepAliveTime：线程没有任务执行时最多保持的时间； 如果运行的线程小于corePoolSize，会直接创建线程执行任务，即使其他线程是空闲的；如果运行线程大于corePoolSize，小于maximumPoolSize时，只有workQueue满的时候才创建新线程；如果corePoolSize等于maximumPoolSize时创建的线程是固定的，多余的任务会被放置到workQueue中； 线程池的关闭ThreadPoolExecutor提供了两个方法，用于线程池的关闭，分别是shutdown()和shutdownNow()，其中： shutdown()：不会立即终止线程池，而是要等所有任务缓存队列中的任务都执行完后才终止，但再也不会接受新的任务 shutdownNow()：立即终止线程池，并尝试打断正在执行的任务，并且清空任务缓存队列，返回尚未执行的任务 常见的四种线程池newFixedThreadPool ：固定大小的线程池，可以指定线程池的大小，该线程池corePoolSize和maximumPoolSize相等，阻塞队列使用的是LinkedBlockingQueue，大小为整数最大值。该线程池中的线程数量始终不变，当有新任务提交时，线程池中有空闲线程则会立即执行，如果没有，则会暂存到阻塞队列。对于固定大小的线程池，不存在线程数量的变化。同时使用无界的LinkedBlockingQueue来存放执行的任务。当任务提交十分频繁的时候，LinkedBlockingQueue迅速增大，存在着耗尽系统资源的问题。而且在线程池空闲时，即线程池中没有可运行任务时，它也不会释放工作线程，还会占用一定的系统资源，需要shutdown。 newSingleThreadExecutor ：单个线程线程池，只有一个线程的线程池，阻塞队列使用的是LinkedBlockingQueue,若有多余的任务提交到线程池中，则会被暂存到阻塞队列，待空闲时再去执行。按照先入先出的顺序执行任务。 newCachedThreadPool ：缓存线程池，缓存的线程默认存活60秒。线程的核心池corePoolSize大小为0，核心池最大为Integer.MAX_VALUE,阻塞队列使用的是SynchronousQueue。是一个直接提交的阻塞队列， 他总会迫使线程池增加新的线程去执行新的任务。在没有任务执行时，当线程的空闲时间超过keepAliveTime（60秒），则工作线程将会终止被回收，当提交新任务时，如果没有空闲线程，则创建新线程执行任务，会导致一定的系统开销。如果同时又大量任务被提交，而且任务执行的时间不是特别快，那么线程池便会新增出等量的线程池处理任务，这很可能会很快耗尽系统的资源。 newScheduledThreadPool ：定时线程池，该线程池可用于周期性地去执行任务，通常用于周期性的同步数据。scheduleAtFixedRate:是以固定的频率去执行任务，周期是指每次执行任务成功执行之间的间隔。schedultWithFixedDelay:是以固定的延时去执行任务，延时是指上一次执行成功之后和下一次开始执行的之前的时间。 如何选择线程池数量线程池的大小决定着系统的性能，过大或者过小的线程池数量都无法发挥最优的系统性能。 当然线程池的大小也不需要做的太过于精确，只需要避免过大和过小的情况。一般来说，确定线程池的大小需要考虑CPU的数量，内存大小，任务是计算密集型还是IO密集型等因素 NCPU = CPU的数量 UCPU = 期望对CPU的使用率 0 ≤ UCPU ≤ 1 W/C = 等待时间与计算时间的比率 如果希望处理器达到理想的使用率，那么线程池的最优大小为： 线程池大小=NCPU *UCPU(1+W/C)","categories":[{"name":"Java并发编程","slug":"Java并发编程","permalink":"https://originer.github.io/Horizon.github.io/categories/Java并发编程/"}],"tags":[]},{"title":"Java容器","slug":"Java容器","date":"2018-06-25T12:43:48.000Z","updated":"2018-12-02T06:29:24.220Z","comments":true,"path":"2018/06/25/Java容器/","link":"","permalink":"https://originer.github.io/Horizon.github.io/2018/06/25/Java容器/","excerpt":"Java容器里只能放对象，对于基本类型（int, long, float, double等），需要将其包装成对象类型后（Integer, Long, Float, Double等）才能放到容器里。很多时候拆包装和解包装能够自动完成。这虽然会导致额外的性能和空间开销，但简化了设计和编程。","text":"Java容器里只能放对象，对于基本类型（int, long, float, double等），需要将其包装成对象类型后（Integer, Long, Float, Double等）才能放到容器里。很多时候拆包装和解包装能够自动完成。这虽然会导致额外的性能和空间开销，但简化了设计和编程。 泛型Java容器能够容纳任何类型的对象，这一点表面上是通过泛型机制完成，Java泛型不是什么神奇的东西，只是编译器为我们提供的一个“语法糖”，泛型本身并不需要Java虚拟机的支持，只需要在编译阶段做一下简单的字符串替换即可。实质上Java的单继承机制才是保证这一特性的根本，因为所有的对象都是Object的子类，容器里只要能够存放Object对象就行了。事实上，所有容器的内部存放的都是Object对象，泛型机制只是简化了编程，由编译器自动帮我们完成了强制类型转换而已。JDK 1.4以及之前版本不支持泛型，类型转换需要程序员显式完成。 123456789//JDK 1.4 or beforeArrayArrayList list = new ArrayList();list.add(new String(\"Monday\"));list.add(new String(\"Tuesday\"));list.add(new String(\"Wensday\"));for(int i = 0; i &lt; list.size(); i++)&#123; String weekday = (String)list.get(i);//显式类型转换 System.out.println(weekday.toUpperCase());&#125; 123456789//JDK 1.5 or latterArrayList&lt;String&gt; list = new ArrayList&lt;String&gt;();//参数化类型list.add(new String(\"Monday\"));list.add(new String(\"Tuesday\"));list.add(new String(\"Wensday\"));for(int i = 0; i &lt; list.size(); i++)&#123; String weekday = list.get(i);//隐式类型转换，编译器自动完成 System.out.println(weekday.toUpperCase());&#125; 内存管理跟C++复杂的内存管理机制不同，Java GC自动包揽了一切，Java程序并不需要处理令人头疼的内存问题，因此JCF并不像C++ STL那样需要专门的空间适配器（alloctor）。另外，由于Java里对象都在堆上，且对象只能通过引用（reference，跟C++中的引用不是同一个概念，可以理解成经过包装后的指针）访问，容器里放的其实是对象的引用而不是对象本身，也就不存在C++容器的复制拷贝问题。 接口和实现（Interfaces and Implementations）接口为了规范容器的行为，统一设计，JCF定义了14种容器接口（collection interfaces），它们的关系如下图所示： Map接口没有继承自Collection接口，因为Map表示的是关联式容器而不是集合。但Java为我们提供了从Map转换到Collection的方法，可以方便的将Map切换到集合视图。上图中提供了Queue接口，却没有Stack，这是因为Stack的功能已被JDK 1.6引入的Deque取代。 迭代器跟C++ STL一样，JCF的迭代器（Iterator）为我们提供了遍历容器中元素的方法。只有容器本身清楚容器里元素的组织方式，因此迭代器只能通过容器本身得到。每个容器都会通过内部类的形式实现自己的迭代器。相比STL的迭代器，JCF的迭代器更容易使用。 12345678ArrayList&lt;String&gt; list = new ArrayList&lt;String&gt;();list.add(new String(\"Monday\"));list.add(new String(\"Tuesday\"));list.add(new String(\"Wensday\"));Iterator&lt;String&gt; it = list.iterator();//得到迭代器while(it.hasNext())&#123; String weekday = it.next();//访问元素 System.out.println(weekday.toUpperCase());&#125; JDK 1.5 引入了增强的for循环，简化了迭代容器时的写法。 //使用增强for迭代 123456ArrayList&lt;String&gt; list = new ArrayList&lt;String&gt;();list.add(new String(\"Monday\"));list.add(new String(\"Tuesday\"));list.add(new String(\"Wensday\"));for(String weekday : list)&#123;//enhanced for statement System.out.println(weekday.toUpperCase());","categories":[{"name":"Java集合框架","slug":"Java集合框架","permalink":"https://originer.github.io/Horizon.github.io/categories/Java集合框架/"}],"tags":[{"name":"Java集合框架","slug":"Java集合框架","permalink":"https://originer.github.io/Horizon.github.io/tags/Java集合框架/"}]}]}